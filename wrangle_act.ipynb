{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project looks at various data sources for Tweets from the [WeRateDogs](https://twitter.com/dog_rates) Twitter account, specifically:\n",
    "\n",
    "1. the `twitter-archive-enhanced.csv` which contains the tweet text, as is the core data set\n",
    "1. the Twitter API is used to access the original tweets to retrieve missing fields such as the retweet and favorite counts\n",
    "1. an image prediction file containing the top 3 predictions for each of the (up to 4) dog pictures in the tweet\n",
    "\n",
    "Having gathered the data, we assess, clean and analyse it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a number of data assets including remote files on web servers, and JSON payloads returned by the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "WE_RATE_DOGS_TWEETS_PATH = 'data/twitter-archive-enhanced.csv'\n",
    "DOG_BREED_PREDICTIONS_SOURCE_URL = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the enhanced Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas `read_csv()` function is quite versatile when uploading data, and can be configured to handle different date formats, numeric data types, not available (NA) markers, etc. Getting this right upfront can save time, but requires the raw data in files to be eyeballed first. For this we can use command line tools like head & tail, or alternatively Excel, which allows column headings to be frozen, data to be sorted and searched, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at the raw data, we make the following observations:\n",
    "\n",
    "1. tweet Ids are large integers, we need to select an approriate integer datatype so no accuracy is lost\n",
    "1. some tweet Ids use floats, e.g.: `in_reply_to_status_id`, `in_reply_to_user_id`, with NaNs used as a Not Available marker, as mentioned above these need to be converted to integers\n",
    "1. time stamps are close to ISO 8601 format, and are GMT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actions taken to address above observations:\n",
    "\n",
    "* convert floating point tweets Ids to a 64-bit integer, retaining the Not Available representation\n",
    "* specifcally tell Pandas which columns are dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the enhanced Twitter archive, using explicit data types for fields, instead of letting Pandas infer them. The [Twitter API](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object) will define the data types for the Twitter sourced fields.\n",
    "\n",
    "To get around the fact that nullable numeric fields are interpreted by `read_csv()` as floats (thus allowing NaNs to represent null), we will map nullable tweet Ids to the Pandas nullable integer data type (Int64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_data_types = {\n",
    "    'tweet_id': np.int64,\n",
    "    'in_reply_to_status_id': 'Int64',\n",
    "    'in_reply_to_user_id': 'Int64',\n",
    "    'retweeted_status_id': 'Int64',\n",
    "    'retweeted_status_user_id': 'Int64',\n",
    "    'text': 'string',\n",
    "    'expanded_urls': 'string',\n",
    "    'rating_numerator': np.int32,\n",
    "    'rating_denominator': np.int32,\n",
    "    'name': 'string',\n",
    "    'doggo': 'string',\n",
    "    'floofer': 'string',\n",
    "    'pupper': 'string',\n",
    "    'puppo': 'string'\n",
    "}\n",
    "\n",
    "feed_date_cols = [\n",
    "    'timestamp', \n",
    "    'retweeted_status_timestamp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_tweets_df = pd.read_csv(WE_RATE_DOGS_TWEETS_PATH,\n",
    "                        index_col=['tweet_id'],\n",
    "                        dtype=feed_data_types,\n",
    "                        parse_dates=feed_date_cols)\n",
    "enhanced_tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first discrepancy we note is that, according to the project motivation document, the main \"archive contains basic tweet data for all 5000+ of their tweets\" however that is clearly not the case as, having loaded it, the number of tweets is less than half that. As this is the master data set we have been provided with, this is the data we have to go with, since it has been previously enhanced.\n",
    "\n",
    "To sanity check this row count, and make sure we have actually read in all the eprovided data, we will run a line count on the input file, which should roughly match the number of rows in the data frame. Any discrepancy on counts is due to those embeded new line (NL) characters in the tweet text, since the number of NL characters is what `wc` bases its line counts on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2518 data/twitter-archive-enhanced.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l {WE_RATE_DOGS_TWEETS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can double check the column data types, against the data type mapping provided to `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2356 entries, 892420643555336193 to 666020888022790149\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   in_reply_to_status_id       78 non-null     Int64              \n",
      " 1   in_reply_to_user_id         78 non-null     Int64              \n",
      " 2   timestamp                   2356 non-null   datetime64[ns, UTC]\n",
      " 3   source                      2356 non-null   object             \n",
      " 4   text                        2356 non-null   string             \n",
      " 5   retweeted_status_id         181 non-null    Int64              \n",
      " 6   retweeted_status_user_id    181 non-null    Int64              \n",
      " 7   retweeted_status_timestamp  181 non-null    datetime64[ns, UTC]\n",
      " 8   expanded_urls               2297 non-null   string             \n",
      " 9   rating_numerator            2356 non-null   int32              \n",
      " 10  rating_denominator          2356 non-null   int32              \n",
      " 11  name                        2356 non-null   string             \n",
      " 12  doggo                       2356 non-null   string             \n",
      " 13  floofer                     2356 non-null   string             \n",
      " 14  pupper                      2356 non-null   string             \n",
      " 15  puppo                       2356 non-null   string             \n",
      "dtypes: Int64(4), datetime64[ns, UTC](2), int32(2), object(1), string(7)\n",
      "memory usage: 303.7+ KB\n"
     ]
    }
   ],
   "source": [
    "enhanced_tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the Twitter API enrichment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to use the Twitter API to retrieve the original tweets, so that we can enrich our enhanced tweets data with the missing attributes previously idientified (`retweet_counts`, `favorite_counts`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having registered with Twitter as a developer, and obtained credentials and keys, we stored these in a private project directory and configuration file (which are excluded from our git repo, and thus won't be visible online in [github](https://github.com/benvens-udacity/wrangle-and-analyze-data/blob/main/wrangle_act.ipynb)).\n",
    "\n",
    "We now use those credentials to authenticate with Twitter for API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_creds(conf_path):\n",
    "    with open(conf_path, 'r') as cf:\n",
    "        config = yaml.load(cf, Loader=yaml.FullLoader)\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = read_creds('./config/private/creds.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = creds['consumer_api']['key']\n",
    "consumer_secret = creds['consumer_api']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = creds['access_token']['token']\n",
    "acess_secret = creds['access_token']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, acess_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the enrichment data in batches, for better performance, as API invocations are subject to significant network latency. Twitter also applies rate limiting to their APIs, so it is necessary to throttle the rate at which we make requests, and to retry any failed requests. Luckily, this can be handled automatically by the Tweepy library, by setting the `wait_on_rate_limit_notify` flag when configuring API connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    idxs = []\n",
    "    retweet_counts = []\n",
    "    favorite_counts = []\n",
    "    for status in batch:\n",
    "        tweet = status._json\n",
    "        idxs.append(tweet['id'])\n",
    "        retweet_counts.append(tweet['retweet_count'])\n",
    "        favorite_counts.append(tweet['favorite_count'])\n",
    "    return np.array(idxs, dtype=np.int64), np.array([retweet_counts, favorite_counts], dtype=np.int64).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.empty((0), dtype=np.int64)\n",
    "rows = np.empty((0, 2), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_tweets = len(enhanced_tweets_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 131 ms, total: 2.13 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for batch_start in range(0, num_tweets, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, num_tweets)\n",
    "    batch_tweet_ids = enhanced_tweets_df.iloc[batch_start:batch_end].index.to_numpy().tolist()\n",
    "    statuses = api.statuses_lookup(batch_tweet_ids, include_entities=False, map_=False)\n",
    "    b_indices, b_rows = process_batch(statuses)\n",
    "    indices = np.concatenate((indices, b_indices), axis=0)\n",
    "    rows = np.concatenate((rows, b_rows), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2331, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_counts_df = pd.DataFrame(index=indices, data=rows, \n",
    "                               columns=['retweet_counts', 'favorite_counts'], \n",
    "                               dtype='Int32').sort_index()\n",
    "tweet_counts_df.index.name = 'tweet_id'\n",
    "tweet_counts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we briefly double check on the expected column data type mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2331 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   retweet_counts   2331 non-null   Int32\n",
      " 1   favorite_counts  2331 non-null   Int32\n",
      "dtypes: Int32(2)\n",
      "memory usage: 41.0 KB\n"
     ]
    }
   ],
   "source": [
    "tweet_counts_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the breed prediction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to load the breed prediction data. We will read this data from the CloudFront URL, as opposed to the local filesystem, to ensure we get the most up-to-date version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_preds_data_types = {\n",
    "    'tweet_id': 'Int64',\n",
    "    'jpg_url': 'string',\n",
    "    'img_num': np.int32,\n",
    "    'p1': 'string',\n",
    "    'p1_conf': np.float32,\n",
    "    'p1_dog': bool,\n",
    "    'p2': 'string',\n",
    "    'p2_conf': np.float32,\n",
    "    'p2_dog': bool,\n",
    "    'p3': 'string',\n",
    "    'p3_conf': np.float32,\n",
    "    'p3_dog': bool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the TSV (not CSV) records, and tell read_csv() to use a tab as the field separator\n",
    "\n",
    "img_preds_df = pd.read_csv(DOG_BREED_PREDICTIONS_SOURCE_URL,\n",
    "                           index_col=['tweet_id'],\n",
    "                           sep='\\t', \n",
    "                           dtype=img_preds_data_types)\n",
    "img_preds_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we check for correct data type mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2075 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   jpg_url  2075 non-null   string \n",
      " 1   img_num  2075 non-null   int32  \n",
      " 2   p1       2075 non-null   string \n",
      " 3   p1_conf  2075 non-null   float32\n",
      " 4   p1_dog   2075 non-null   bool   \n",
      " 5   p2       2075 non-null   string \n",
      " 6   p2_conf  2075 non-null   float32\n",
      " 7   p2_dog   2075 non-null   bool   \n",
      " 8   p3       2075 non-null   string \n",
      " 9   p3_conf  2075 non-null   float32\n",
      " 10  p3_dog   2075 non-null   bool   \n",
      "dtypes: bool(3), float32(3), int32(1), string(4)\n",
      "memory usage: 119.6+ KB\n"
     ]
    }
   ],
   "source": [
    "img_preds_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having gathered the data we will now assess it, ideally both visually and programmatically. \n",
    "\n",
    "Some of this visual assesment has already been done against the raw data in files, to ensure we used appropriate data types when uploading the data. Therefore some data quality issues (large integers stored as floating point, with potential loss of accuracy, which invalidates their meaning as an identifier) have been addressed at upload time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will inspect the data that has been uploaded into the corresponding dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise the number of viewable rows and columns\n",
    "# Retain some kind of row counts, as very large data sets may get loaded into the browser, causing memory issues\n",
    "\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assess some tweets that include a dog stage name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>890240255349198849</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-26 15:59:51+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Cassie. She is a college pup. Studying international doggo communication and stick theory. 14/10 so elegant much sophisticate https://t.co/t1bfwz5S2A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/890240255349198849/photo/1</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>Cassie</td>\n",
       "      <td>doggo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889665388333682689</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-25 01:55:32+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>Here's a puppo that seems to be on the fence about something haha no but seriously someone help her. 13/10 https://t.co/BxvuXk0UCm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/889665388333682689/photo/1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>puppo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889531135344209921</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-24 17:02:04+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Stuart. He's sporting his favorite fanny pack. Secretly filled with bones only. 13/10 puppared puppo #BarkWeek https://t.co/y70o6h3isq</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/889531135344209921/photo/1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Stuart</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>puppo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886366144734445568</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-15 23:25:31+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Roscoe. Another pupper fallen victim to spontaneous tongue ejections. Get the BlepiPen immediate. 12/10 deep breaths Roscoe https://t.co/RGE08MIJox</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/886366144734445568/photo/1,https://twitter.com/dog_rates/status/886366144734445568/photo/1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Roscoe</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pupper</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884162670584377345</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-09 21:29:42+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>Meet Yogi. He doesn't have any important dog meetings today he just enjoys looking his best at all times. 12/10 for dangerously dapper doggo https://t.co/YSI00BzTBZ</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/884162670584377345/photo/1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Yogi</td>\n",
       "      <td>doggo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "tweet_id                                                         \n",
       "890240255349198849                   <NA>                 <NA>   \n",
       "889665388333682689                   <NA>                 <NA>   \n",
       "889531135344209921                   <NA>                 <NA>   \n",
       "886366144734445568                   <NA>                 <NA>   \n",
       "884162670584377345                   <NA>                 <NA>   \n",
       "\n",
       "                                   timestamp  \\\n",
       "tweet_id                                       \n",
       "890240255349198849 2017-07-26 15:59:51+00:00   \n",
       "889665388333682689 2017-07-25 01:55:32+00:00   \n",
       "889531135344209921 2017-07-24 17:02:04+00:00   \n",
       "886366144734445568 2017-07-15 23:25:31+00:00   \n",
       "884162670584377345 2017-07-09 21:29:42+00:00   \n",
       "\n",
       "                                                                                                source  \\\n",
       "tweet_id                                                                                                 \n",
       "890240255349198849  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "889665388333682689  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "889531135344209921  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "886366144734445568  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "884162670584377345  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "\n",
       "                                                                                                                                                                                    text  \\\n",
       "tweet_id                                                                                                                                                                                   \n",
       "890240255349198849         This is Cassie. She is a college pup. Studying international doggo communication and stick theory. 14/10 so elegant much sophisticate https://t.co/t1bfwz5S2A   \n",
       "889665388333682689                                    Here's a puppo that seems to be on the fence about something haha no but seriously someone help her. 13/10 https://t.co/BxvuXk0UCm   \n",
       "889531135344209921                        This is Stuart. He's sporting his favorite fanny pack. Secretly filled with bones only. 13/10 puppared puppo #BarkWeek https://t.co/y70o6h3isq   \n",
       "886366144734445568           This is Roscoe. Another pupper fallen victim to spontaneous tongue ejections. Get the BlepiPen immediate. 12/10 deep breaths Roscoe https://t.co/RGE08MIJox   \n",
       "884162670584377345  Meet Yogi. He doesn't have any important dog meetings today he just enjoys looking his best at all times. 12/10 for dangerously dapper doggo https://t.co/YSI00BzTBZ   \n",
       "\n",
       "                    retweeted_status_id  retweeted_status_user_id  \\\n",
       "tweet_id                                                            \n",
       "890240255349198849                 <NA>                      <NA>   \n",
       "889665388333682689                 <NA>                      <NA>   \n",
       "889531135344209921                 <NA>                      <NA>   \n",
       "886366144734445568                 <NA>                      <NA>   \n",
       "884162670584377345                 <NA>                      <NA>   \n",
       "\n",
       "                   retweeted_status_timestamp  \\\n",
       "tweet_id                                        \n",
       "890240255349198849                        NaT   \n",
       "889665388333682689                        NaT   \n",
       "889531135344209921                        NaT   \n",
       "886366144734445568                        NaT   \n",
       "884162670584377345                        NaT   \n",
       "\n",
       "                                                                                                                                      expanded_urls  \\\n",
       "tweet_id                                                                                                                                              \n",
       "890240255349198849                                                                  https://twitter.com/dog_rates/status/890240255349198849/photo/1   \n",
       "889665388333682689                                                                  https://twitter.com/dog_rates/status/889665388333682689/photo/1   \n",
       "889531135344209921                                                                  https://twitter.com/dog_rates/status/889531135344209921/photo/1   \n",
       "886366144734445568  https://twitter.com/dog_rates/status/886366144734445568/photo/1,https://twitter.com/dog_rates/status/886366144734445568/photo/1   \n",
       "884162670584377345                                                                  https://twitter.com/dog_rates/status/884162670584377345/photo/1   \n",
       "\n",
       "                    rating_numerator  rating_denominator    name  doggo  \\\n",
       "tweet_id                                                                  \n",
       "890240255349198849                14                  10  Cassie  doggo   \n",
       "889665388333682689                13                  10    None   None   \n",
       "889531135344209921                13                  10  Stuart   None   \n",
       "886366144734445568                12                  10  Roscoe   None   \n",
       "884162670584377345                12                  10    Yogi  doggo   \n",
       "\n",
       "                   floofer  pupper  puppo  \n",
       "tweet_id                                   \n",
       "890240255349198849    None    None   None  \n",
       "889665388333682689    None    None  puppo  \n",
       "889531135344209921    None    None  puppo  \n",
       "886366144734445568    None  pupper   None  \n",
       "884162670584377345    None    None   None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_tweets_df[(enhanced_tweets_df[['doggo', 'floofer', 'pupper', 'puppo']] != 'None').any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "\n",
    "1. HTML in the `source` columns, with a lot of repetition (to be verified programmatically)\n",
    "1. the varios rewteet columns frequently hold null values\n",
    "1. on occasions multiple values appearing in the `expanded_urls` column, including repeating values\n",
    "1. quite often no dog stage can be identified, and occasionally no dog name\n",
    "1. dog stages place the stage name in a column named after the stage, this is redundant information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_counts</th>\n",
       "      <th>favorite_counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666020888022790149</th>\n",
       "      <td>452</td>\n",
       "      <td>2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666029285002620928</th>\n",
       "      <td>41</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666033412701032449</th>\n",
       "      <td>39</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666044226329800704</th>\n",
       "      <td>124</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666049248165822465</th>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    retweet_counts  favorite_counts\n",
       "tweet_id                                           \n",
       "666020888022790149             452             2357\n",
       "666029285002620928              41              119\n",
       "666033412701032449              39              109\n",
       "666044226329800704             124              263\n",
       "666049248165822465              40               96"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no immediate issues observed by assessing a small sample of the tweet counts data visually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666020888022790149</th>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666029285002620928</th>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666033412701032449</th>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666044226329800704</th>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666049248165822465</th>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            jpg_url  img_num  \\\n",
       "tweet_id                                                                       \n",
       "666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg        1   \n",
       "666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg        1   \n",
       "666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg        1   \n",
       "666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg        1   \n",
       "666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg        1   \n",
       "\n",
       "                                        p1   p1_conf  p1_dog  \\\n",
       "tweet_id                                                       \n",
       "666020888022790149  Welsh_springer_spaniel  0.465074    True   \n",
       "666029285002620928                 redbone  0.506826    True   \n",
       "666033412701032449         German_shepherd  0.596461    True   \n",
       "666044226329800704     Rhodesian_ridgeback  0.408143    True   \n",
       "666049248165822465      miniature_pinscher  0.560311    True   \n",
       "\n",
       "                                    p2   p2_conf  p2_dog                   p3  \\\n",
       "tweet_id                                                                        \n",
       "666020888022790149              collie  0.156665    True    Shetland_sheepdog   \n",
       "666029285002620928  miniature_pinscher  0.074192    True  Rhodesian_ridgeback   \n",
       "666033412701032449            malinois  0.138584    True           bloodhound   \n",
       "666044226329800704             redbone  0.360687    True   miniature_pinscher   \n",
       "666049248165822465          Rottweiler  0.243682    True             Doberman   \n",
       "\n",
       "                     p3_conf  p3_dog  \n",
       "tweet_id                              \n",
       "666020888022790149  0.061428    True  \n",
       "666029285002620928  0.072010    True  \n",
       "666033412701032449  0.116197    True  \n",
       "666044226329800704  0.222752    True  \n",
       "666049248165822465  0.154629    True  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following: \n",
    "\n",
    "1. each row refers to an image\n",
    "1. each image is numbered, as it is selected as the best of up to 4 dog images that may be associated with each tweet\n",
    "1. we then have the top 3 breed predictions for that image\n",
    "\n",
    "Each prediction consists of the following information:\n",
    "\n",
    "1. a predicted label or class (e.g.: the dog breed) that describes the image\n",
    "1. a confidence estimate associated with the above prediction, in the range 0.0 -> 1.0 (0% to 100% confident)\n",
    "1. a boolean indicator confirming if the predicted label is a dog breed, or some other object\n",
    "\n",
    "Looking at the confidence estimates for predictions p1 - p3, they appear to be listed in most confident to least confident order. Therefore we will use the column name numeric suffix to generate a ranking column, which we can later sort by (to preserve this decreasing confidence order).\n",
    "\n",
    "This last attribute confirms that the image classifier used to generate these prediction was trained on a broad set of images, only a subset of which are dog images labelled with their corresponding dog breed. But on occasions the classifier may have interpreted a dog image as an object other than a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatic assesment gives us the opportunity to validate observations, and search for anomalies, across the entire dataset. This is very difficult to do visually unless the dataset is small, both in trems of the number of rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess level of repetition in the `source` column, which holds an HTML anchor node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>     2221\n",
       "<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                          91\n",
       "<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                       33\n",
       "<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>      11\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_tweets_df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above results there appear to be 4 sources corresponding to the related applications: iPhone Twitter app, Vine app, Twitter web client and TweetDeck. This data contains a lot of redundant and messy information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are tweets where more than one dog stage is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((enhanced_tweets_df[['doggo', 'floofer', 'pupper', 'puppo']] != 'None').sum(axis=1) > 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will quickly validate that all counts are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet_counts     True\n",
       "favorite_counts    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tweet_counts_df >= 0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the number of entries in the enriched tweets dataframe to the number of entries in the tweet counts dataframe, to see of we successfully retrieved counts for all tweets from the API. The small difference in counts suggests a small number of tweets can no longer be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 2331)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enhanced_tweets_df.index), len(tweet_counts_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will validate the assumption made earlier that the confidence estimates are ordered by the numeric suffix of the column name, which can be used to populate a ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((img_preds_df['p1_conf'] > img_preds_df['p2_conf']) & (img_preds_df['p2_conf'] > img_preds_df['p3_conf'])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we validate that all confidence estimates are in the range 0.0 to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img_preds_df['p1_conf'].between(0.0, 1.0) & \n",
    "img_preds_df['p2_conf'].between(0.0, 1.0) & \n",
    "img_preds_df['p3_conf'].between(0.0, 1.0)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of the visual and programmatic assessments, the following data quality have been found, which will require data content to be cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. the immediate data quality concern is that the project motivation document states that the \"archive contains basic tweet data for all 5000+ of their tweets\" but we are loading less than half that number of tweets. **However, given the enhanced tweets dataset is our master dataset, there is nothing that we can do to remedy the much smaller number of rows, beyond highlighting this observation**\n",
    "1. as previously mentioned, the issue with some tweet Id columns being treated as floating point numbers, and the fact that rounding could invalidate these, was resolved at data loading time (without impacting the fact that they are nullable columns)\n",
    "1. the format of the `timestamp` is very close to an ISO 8601 timestamp, however it is missing the 't' character as the separator between the date and time portions. There are definite advantages in following a recognised standard, as this will be understood by tools such as database import utilities, however Pandas has correctly parsed dates\n",
    "1. in the `source` column, extract the source app name from the HTML anchor string, and then map this column to a Pandas categorical\n",
    "1. it is unclear why, in the `expanded_urls` columns, the same URL get repeated, since looking at the tweet text there is only one reference to the corresponding link. Therefore we will remove duplicates\n",
    "1. convert the dog stage columns into boolean datatype, and interpret the constant value 'None' as a missing stage\n",
    "1. since the dog stage column names are the stages, storing that same name as a value is redundant information, following on from the previous observation, where the dog stage appears we will just store a boolean true value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. while the intention is to obtain retweet and favorite counts for all the tweets in the enhanced tweets dataset, we cannot guarantee that the Twitter API will always return the original Tweet, e.g.: it may subsequently have been deleted\n",
    "1. where the counts were successfully retrieved for the original tweet (the majority of cases, as proven in the programatic assesment), then there is a one-to-one relationship between the rows in the counts dataframe, and the rows in the enhanced tweets dataframe. Therefore the counts columns can be merged back into the enhanced tweets dataframe, as arguably they are part of that tweet observation. In the few cases where the counts are missing, we will store nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obvious data quality issues, beyond the prediction column names being used as variables (the numeric suffix added). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at data frame structure, column naming, and inspecting values, and then applying the [Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf) principles, the following structural issues will need to be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. the `source` column must store a category that represent the application (and possibly device) used to author the tweet\n",
    "1. the `expanded_urls` column can store multiple values per row, depending on the web links embeded in the tweet text, therefore these observations need to be stored in a separate table (however, we will first remove any duplicate values).\n",
    "1. dog stage is a multivalued categorical variable, as a tweet can reference more than one stage. Therefore we retain the existing columns but encode them in the style of one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obvious structural issues here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a variable (prediction number) is embeded in the column names of the prediction columns (predicted breed, prediction confidence, and is-a-dog flag)\n",
    "2. the prediction number ranks the predictions in the order most confident (1st prediction) to least confident (3rd prediction)\n",
    "3. the actual breed predictions should be held in a separate dataframe, and linked back to the tweet and tweet image they are associated with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now clean the issues uncovered during assesment using a _define/code/test_ framework, which will be applied to each of the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_enhanced_tweets_df = enhanced_tweets_df.copy()\n",
    "clean_enhanced_tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Extract tweet application from `source` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* parse source column which holds an HTML anchor node \n",
    "* extract anchor node content, describing the application used\n",
    "* convert the column to Pandas categorical, as a more efficient representation that can be used in models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract content from anchor node\n",
    "\n",
    "clean_enhanced_tweets_df['source'] = \\\n",
    "    clean_enhanced_tweets_df['source'].str.extract(r'[^<]*a href=\"[^\"]+\" rel=\"[^\"]+\">([^<]+)<\\/a>')\n",
    "\n",
    "# Convert column to categorical\n",
    "\n",
    "clean_enhanced_tweets_df['source'] = clean_enhanced_tweets_df['source'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that the tweet source column is now a categorical, and the number of categories is that expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert column data type is categorical\n",
    "\n",
    "assert isinstance(clean_enhanced_tweets_df['source'].dtype, pd.CategoricalDtype),'Expect categorical'\n",
    "\n",
    "# Assert the number of categories is as expected\n",
    "\n",
    "assert len(clean_enhanced_tweets_df['source'].cat.categories) == 4, 'Expect 4 application categories'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Move `expanded_urls` to a detail dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* split multi-valued string of comma separated URLs, into URL arrays\n",
    "* remove any duplicate URLs from the array\n",
    "* convert each array into list of tuples, bound to the containing `tweet_id`\n",
    "* stores these tuples as rows in a new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out rows containing one or more expanded URLs, as some rows have none\n",
    "\n",
    "expanded_urls_col = \\\n",
    "    clean_enhanced_tweets_df.loc[clean_enhanced_tweets_df['expanded_urls'].isna() == False]['expanded_urls']\n",
    "\n",
    "# Nested list comprehension to split multiple URL strings on comma separator, then create [tweet Id, URL] tuples\n",
    "\n",
    "expanded_url_tuples = [(ix, url) for ix, urls in expanded_urls_col.iteritems() for url in urls.split(',')]\n",
    "expanded_url_df = pd.DataFrame(expanded_url_tuples, columns=['tweet_id', 'expanded_url'])\n",
    "\n",
    "# Now drop duplicates and make 'tweet_id' the index for consistency with other dataframes\n",
    "\n",
    "expanded_url_df = expanded_url_df.drop_duplicates().set_index('tweet_id')\n",
    "\n",
    "# Finally drop the original expanded_urls column\n",
    "\n",
    "clean_enhanced_tweets_df = clean_enhanced_tweets_df.drop(columns='expanded_urls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will count total and unique tweet Ids in the new dataframe holding expanded URLs. The later will be lower, accounting for multiple rows (hence web links in the tweet text) associated with the same tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 2297)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the index can contain duplicate entries (whenever a tweet has more than one URL)\n",
    "# We compare duplicate and non-duplicate counts below\n",
    "\n",
    "len(expanded_url_df.index), len(expanded_url_df.index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Convert dog stage columns to boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* where the value 'None' is stored, set False, otherwise set True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dog stage columns into a boolean data type\n",
    "\n",
    "stage_cols = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "clean_enhanced_tweets_df[stage_cols] = clean_enhanced_tweets_df[stage_cols].apply(lambda c: c.to_numpy() != 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that the dog stage columns are now boolean type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2356 entries, 892420643555336193 to 666020888022790149\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   in_reply_to_status_id       78 non-null     Int64              \n",
      " 1   in_reply_to_user_id         78 non-null     Int64              \n",
      " 2   timestamp                   2356 non-null   datetime64[ns, UTC]\n",
      " 3   source                      2356 non-null   category           \n",
      " 4   text                        2356 non-null   string             \n",
      " 5   retweeted_status_id         181 non-null    Int64              \n",
      " 6   retweeted_status_user_id    181 non-null    Int64              \n",
      " 7   retweeted_status_timestamp  181 non-null    datetime64[ns, UTC]\n",
      " 8   rating_numerator            2356 non-null   int32              \n",
      " 9   rating_denominator          2356 non-null   int32              \n",
      " 10  name                        2356 non-null   string             \n",
      " 11  doggo                       2356 non-null   bool               \n",
      " 12  floofer                     2356 non-null   bool               \n",
      " 13  pupper                      2356 non-null   bool               \n",
      " 14  puppo                       2356 non-null   bool               \n",
      "dtypes: Int64(4), bool(4), category(1), datetime64[ns, UTC](2), int32(2), string(2)\n",
      "memory usage: 205.0 KB\n"
     ]
    }
   ],
   "source": [
    "clean_enhanced_tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in stage_cols:\n",
    "    assert clean_enhanced_tweets_df[col].dtype == 'bool', 'Expect boolean column'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Merge retweet and favorite counts into enhanced tweets dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* merge retweet and favorite count columns into enhanced tweets dataframe, using a left join with nulls for missing count values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_enhanced_tweets_df = clean_enhanced_tweets_df.merge(tweet_counts_df, how='left', on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate number of rows after merge, including count of rows with null retweet or favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retweet_counts     25\n",
       "favorite_counts    25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total rows (should be unchanged), and null retweet and favorite counts (tweets no longer available)\n",
    "\n",
    "print(len(clean_enhanced_tweets_df.index))\n",
    "clean_enhanced_tweets_df[['retweet_counts', 'favorite_counts']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Melt image prediction column headers into detail dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* store `jpg_url` and `img_num` columns in a clean dataframe\n",
    "* melt prediction 1 to 3 columns into temporary dataframes, with the prediction rank as a constant value, and the related `tweet_id`\n",
    "* stack the above temporary dataframes into a predictions dataframe, with repeated `tweet_id` as the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_img_preds_df = img_preds_df.copy()\n",
    "clean_img_preds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_pred_cols(df, numeric):\n",
    "    preds_df = pd.DataFrame(data={'pred_rank':       numeric,\n",
    "                                  'pred_class':      df[f'p{numeric}'],\n",
    "                                  'pred_confidence': df[f'p{numeric}_conf'],\n",
    "                                  'pred_is_dog':     df[f'p{numeric}_dog']})\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1_df = melt_pred_cols(clean_img_preds_df, 1)\n",
    "preds2_df = melt_pred_cols(clean_img_preds_df, 2)\n",
    "preds3_df = melt_pred_cols(clean_img_preds_df, 3)\n",
    "\n",
    "clean_predictions_df = pd.concat([preds1_df, \n",
    "                                  preds2_df, \n",
    "                                  preds3_df]).sort_values(by=['tweet_id', 'pred_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop melted prediction columns\n",
    "\n",
    "clean_img_preds_df = clean_img_preds_df.drop(columns=['p1', 'p1_conf', 'p1_dog', \\\n",
    "                                                      'p2', 'p2_conf', 'p2_dog', \\\n",
    "                                                      'p3', 'p3_conf', 'p3_dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate dataframe column names and structure as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2075 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   jpg_url  2075 non-null   string\n",
      " 1   img_num  2075 non-null   int32 \n",
      "dtypes: int32(1), string(1)\n",
      "memory usage: 40.5+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_img_preds_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6225 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   pred_rank        6225 non-null   int64  \n",
      " 1   pred_class       6225 non-null   string \n",
      " 2   pred_confidence  6225 non-null   float32\n",
      " 3   pred_is_dog      6225 non-null   bool   \n",
      "dtypes: bool(1), float32(1), int64(1), string(1)\n",
      "memory usage: 176.3 KB\n"
     ]
    }
   ],
   "source": [
    "clean_predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate master/detail row counts\n",
    "\n",
    "assert len(clean_img_preds_df.index) == (len(clean_predictions_df.index) / 3), 'Expect 3x number of detail rows'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we look at the data and analyse it to obtain some insights. Specifically, we are interested in:\n",
    "\n",
    "1. Finding the number of tweets with a score above 10/10, versus tweets with a score under 10/10\n",
    "2. Identify the tweets where more than one dog stage appears\n",
    "3. Finding the number of top breed predictions from the image classifier, with a predictionconfidence below 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count number of scores above and below 10/10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 905)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((clean_enhanced_tweets_df['rating_numerator'] / clean_enhanced_tweets_df['rating_denominator']) > 1.0).sum(), \\\n",
    "((clean_enhanced_tweets_df['rating_numerator'] / clean_enhanced_tweets_df['rating_denominator']) <= 1.0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show tweets with more than one dog stage in the tweet text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855851453814013952</th>\n",
       "      <td>Here's a puppo participating in the #ScienceMarch. Cleverly disguising her own doggo agenda. 13/10 would keep the planet habitable for https://t.co/cMhq16isel</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854010172552949760</th>\n",
       "      <td>At first I thought this was a shy doggo, but it's actually a Rare Canadian Floofer Owl. Amateurs would confuse the two. 11/10 only send dogs https://t.co/TXdT3tmuYk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817777686764523521</th>\n",
       "      <td>This is Dido. She's playing the lead role in \"Pupper Stops to Catch Snow Before Resuming Shadow Box with Dried Apple.\" 13/10 (IG: didodoggo) https://t.co/m7isZrOBX7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808106460588765185</th>\n",
       "      <td>Here we have Burke (pupper) and Dexter (doggo). Pupper wants to be exactly like doggo. Both 12/10 would pet at same time https://t.co/ANBpEYHaho</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802265048156610565</th>\n",
       "      <td>Like doggo, like pupper version 2. Both 11/10 https://t.co/9IxWAXFqze</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801115127852503040</th>\n",
       "      <td>This is Bones. He's being haunted by another doggo of roughly the same size. 12/10 deep breaths pupper everything's fine https://t.co/55Dqe0SJNj</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785639753186217984</th>\n",
       "      <td>This is Pinot. He's a sophisticated doggo. You can tell by the hat. Also pointier than your average pupper. Still 10/10 would pet cautiously https://t.co/f2wmLZTPHd</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781308096455073793</th>\n",
       "      <td>Pupper butt 1, Doggo 0. Both 12/10 https://t.co/WQvcPEpH2u</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775898661951791106</th>\n",
       "      <td>RT @dog_rates: Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770093767776997377</th>\n",
       "      <td>RT @dog_rates: This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759793422261743616</th>\n",
       "      <td>Meet Maggie &amp;amp; Lila. Maggie is the doggo, Lila is the pupper. They are sisters. Both 12/10 would pet at the same time https://t.co/MYwR4DQKll</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751583847268179968</th>\n",
       "      <td>Please stop sending it pictures that don't even have a doggo or pupper in them. Churlish af. 5/10 neat couch tho https://t.co/u2c9c7qSg8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741067306818797568</th>\n",
       "      <td>This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733109485275860992</th>\n",
       "      <td>Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    text  \\\n",
       "tweet_id                                                                                                                                                                                   \n",
       "855851453814013952        Here's a puppo participating in the #ScienceMarch. Cleverly disguising her own doggo agenda. 13/10 would keep the planet habitable for https://t.co/cMhq16isel   \n",
       "854010172552949760  At first I thought this was a shy doggo, but it's actually a Rare Canadian Floofer Owl. Amateurs would confuse the two. 11/10 only send dogs https://t.co/TXdT3tmuYk   \n",
       "817777686764523521  This is Dido. She's playing the lead role in \"Pupper Stops to Catch Snow Before Resuming Shadow Box with Dried Apple.\" 13/10 (IG: didodoggo) https://t.co/m7isZrOBX7   \n",
       "808106460588765185                      Here we have Burke (pupper) and Dexter (doggo). Pupper wants to be exactly like doggo. Both 12/10 would pet at same time https://t.co/ANBpEYHaho   \n",
       "802265048156610565                                                                                                 Like doggo, like pupper version 2. Both 11/10 https://t.co/9IxWAXFqze   \n",
       "801115127852503040                      This is Bones. He's being haunted by another doggo of roughly the same size. 12/10 deep breaths pupper everything's fine https://t.co/55Dqe0SJNj   \n",
       "785639753186217984  This is Pinot. He's a sophisticated doggo. You can tell by the hat. Also pointier than your average pupper. Still 10/10 would pet cautiously https://t.co/f2wmLZTPHd   \n",
       "781308096455073793                                                                                                            Pupper butt 1, Doggo 0. Both 12/10 https://t.co/WQvcPEpH2u   \n",
       "775898661951791106                                                                             RT @dog_rates: Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda   \n",
       "770093767776997377                                                            RT @dog_rates: This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC   \n",
       "759793422261743616                      Meet Maggie &amp; Lila. Maggie is the doggo, Lila is the pupper. They are sisters. Both 12/10 would pet at the same time https://t.co/MYwR4DQKll   \n",
       "751583847268179968                              Please stop sending it pictures that don't even have a doggo or pupper in them. Churlish af. 5/10 neat couch tho https://t.co/u2c9c7qSg8   \n",
       "741067306818797568                                                                           This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC   \n",
       "733109485275860992                                                                                            Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda   \n",
       "\n",
       "                    doggo  floofer  pupper  puppo  \n",
       "tweet_id                                           \n",
       "855851453814013952   True    False   False   True  \n",
       "854010172552949760   True     True   False  False  \n",
       "817777686764523521   True    False    True  False  \n",
       "808106460588765185   True    False    True  False  \n",
       "802265048156610565   True    False    True  False  \n",
       "801115127852503040   True    False    True  False  \n",
       "785639753186217984   True    False    True  False  \n",
       "781308096455073793   True    False    True  False  \n",
       "775898661951791106   True    False    True  False  \n",
       "770093767776997377   True    False    True  False  \n",
       "759793422261743616   True    False    True  False  \n",
       "751583847268179968   True    False    True  False  \n",
       "741067306818797568   True    False    True  False  \n",
       "733109485275860992   True    False    True  False  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_cols = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "clean_enhanced_tweets_df.loc[clean_enhanced_tweets_df[stage_cols].sum(axis=1) > 1][['text'] + stage_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count tweets where the top scoring breed prediction is below 0.5** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_preds = clean_predictions_df.loc[(clean_predictions_df['pred_rank'] == 1) \\\n",
    "                                     & clean_predictions_df['pred_is_dog']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dog_preds[dog_preds['pred_confidence'] < 0.5].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to generate some visualisations:\n",
    "\n",
    "1. First, based on the top image prediction, look at the frequency distribution for the top 10 breeds only, based on number of tweets\n",
    "2. Now look at the frequency distribution for the top 10 breeds only, based on aggregate number of favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breed prediction distribution by number of tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='pred_class'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dog_preds['pred_class'].value_counts(sort=True)[0:10].plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breed prediction distribution by number of favorites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='favorite_counts'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dog_preds.join(clean_enhanced_tweets_df['favorite_counts']).groupby(['pred_class']) \\\n",
    "    .sum().sort_values(by='favorite_counts', ascending=False)[0:10]['favorite_counts'].plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Predict breeds from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some research, including looking at the Udacity [Dog Identification App](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/project-dog-classification/dog_app.ipynb) (which unfortunately uses a different set of labels) we tracked down the dataset of dog breed labels that appear in the tweet images predictions dataset. It is the [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will predict dog breeds for the various dog images extracted from tweets, and compare our results to those we downloaded and cleaned earlier. We will start with a pre-trained ImageNet classifier, trained on 1000 classes, and will then use transfer learning to train a new classifier for the 120 dog breeds present in the Stanford Dogs dataset, using the training images in that dataset.\n",
    "\n",
    "Whilst we have no way to verify if out breed predictions are accurate, we can compare our top 3 predictions against the top 3 predictions downloaded earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we will source the Stanford Dogs dataset from the Kaggle [Dog Breed Identification](https://www.kaggle.com/c/dog-breed-identification/data) competition. Kaggle have already itemised the training images and labels as a CSV file, which we can easiliy load into a Pandas dataframe. Furthermore they provide an API to download the data assets, and a command line interface (CLI) to interact with this API from a Unix shell. We will now use `pip` to install the Kaggle tooling, and download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_net_data = './data/image-net-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog-breed-identification.zip: Skipping, found more recently modified local copy (use --force to force download)\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c dog-breed-identification -p \\$image_net_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dog-breed-identification.zip\r\n"
     ]
    }
   ],
   "source": [
    "!(cd \\$image_net_data;unzip -uo dog-breed-identification.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_net_labels_df = pd.read_csv(image_net_data + '/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess data coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will verify that the dog breed labels in the Stanford Dogs dataset cover all the dog breed labels used in the tweet images breed prediction dataframe. For consistency, we first convert both sets of labels to lowercase, to get around anomalies in how some breed names get capitalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_predictions_df['pred_class'] = clean_predictions_df['pred_class'].str.lower()\n",
    "image_net_labels_df['breed'] = image_net_labels_df['breed'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian',\n",
       " 'dalmatian']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[predicted_breed for predicted_breed in clean_predictions_df[clean_predictions_df['pred_is_dog']]['pred_class'] \n",
    " if not predicted_breed in list(image_net_labels_df['breed'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one missing label is 'dalmatian' which is not part of the Stanford Dogs set of breed labels (or the Kaggle set) and yet does appear in the original ImageNet dataset. \n",
    "\n",
    "So as to recognise images of Dalmations, we will need to fall back to the pretrained ImageNet classifier, the one covering 1000 classes. In any case, we need to do this to recognise images of objects other than dogs, and to be able to set the boolean flag that indicates the predicted class is not a dog breed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the models will return predictions for the samples we give it. We then compare these predictions against the labels that are part of our training data, so as to measure the accuracy of the model, and generate a loss that is used to tune model weights and improve subsequent predictions.\n",
    "\n",
    "Learning is an iterative process controlled by a number of parameters and hyper-parameters:\n",
    "\n",
    "* data transformation: the model is shown transformed images (such as mirror images, small rotations or crops of the original image), in effect the model is trained on a broader set of images, which means it should generalise better\n",
    "* model architecture: this includes the number of layers (how deep the model is), dimensions (the feature map size from the orginal image into subsequent layers, the number of channels or depth of each layer), layer parameters such as dropout probability, etc\n",
    "* optimiser parameters such as learning rate (the extent to which loss influences weights)\n",
    "* the number of epochs or iterations through the full training set, the expectation being that losses decrease (and prediction accuracy increases) in subsequent iterations\n",
    "\n",
    "The most effective way to tune all the parameters is to validate the model at each iteration. This is done by running the model against samples it has not been trained against (i.e.: which it hasn't seen before) which is more representative of a real world use case, and then measuring prediction loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we setup the Pytorch data loading classes required to load the training and validation data, with which to perform transfer learning on our modified model. Since the validation set also requires labelled data, and the Kaggle data only has label in the training dataset, we will need to split that into training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will chose an 80/20 training/validation split. The easiest approach is to apply the splits to the ImageNet labels dataframe holding the image Ids and labels, and drive the rest of the data selection process from here. The split is performed once, and used across many iterations, such that the validation split is only used for validation (not training).\n",
    "\n",
    "A naive approach is to take the first 80% of rows in the  dataframe, and use the remaining 20% for validation. But this would not be a good approach, as there is no guarantee that that 80/20 split would be reflected within each of our 120 classes. \n",
    "\n",
    "The scikit-learn library provides a stratified split functions that splits the dataset into K equal sized folds, and then preserves the class distribution between folds. By taking 5 folds, then using four for training and one for alidation, we get our 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8177,), (2045,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "train_idx, valid_idx = next(iter(skf.split(np.arange(len(image_net_labels_df.index)),\n",
    "                                           image_net_labels_df['breed'])))\n",
    "train_idx.shape, valid_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8177, 2), (2045, 2))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_df = image_net_labels_df.iloc[train_idx]\n",
    "valid_split_df = image_net_labels_df.iloc[valid_idx]\n",
    "train_split_df.shape, valid_split_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a dataset class that can read the image file from a URL (the tweet use case) or a local file (the ImageNet download case), and in both cases takes the labels from a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "class ImageDataFrameDataset:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 df,  \n",
    "                 img_col,\n",
    "                 lbl_col=None,\n",
    "                 img_dir=None, \n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: a dataframe holding class labels and, either an image Id, the image file, or an image URL\n",
    "            img_col: column holding image file name (either the name without suffix, or the full URL)\n",
    "            lbl_col: optional column holding image label\n",
    "            img_dir: an optional directory in which to find the image files (unless remote)\n",
    "            transfor: optional transform, or chain of transforms\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.img_col = img_col\n",
    "        self.lbl_col = lbl_col\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform       \n",
    "\n",
    "        if self.lbl_col is not None:\n",
    "            self.classes, self.class_to_idx = self._find_classes(self.df[self.lbl_col])\n",
    "            self.labels = [self.class_to_idx[getattr(row, self.lbl_col)] \n",
    "                           for row in self.df.itertuples()]\n",
    "                \n",
    "        if self.img_dir is None:\n",
    "            self.session = requests.Session()\n",
    "\n",
    "        self.samples = [self._read_image(getattr(row, self.img_col))\n",
    "                        for row in self.df.itertuples()]\n",
    "\n",
    "    def _read_image(self, resource):\n",
    "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "        \n",
    "        if self.img_dir is not None:\n",
    "            file_name = f'{self.img_dir}/{resource}.jpg'\n",
    "            with open(file_name, 'rb') as fd:\n",
    "                image = Image.open(fd)\n",
    "                return image.convert('RGB')\n",
    "        else:\n",
    "            response = self.session.get(resource, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                response.raw.decode_content = True\n",
    "                try:\n",
    "                    image = Image.open(response.raw)\n",
    "                    return image.convert('RGB')\n",
    "                except UnidentifiedImageError as ex:\n",
    "                    print(f'Image open failed for URL {resource}, exception {ex}')\n",
    "            return Image.new('RGB', (224, 224))\n",
    "                    \n",
    "    def _find_classes(self, series):\n",
    "        classes = series.unique()\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        image = self.samples[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            return image, self.labels[index]\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "import torch\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "\n",
    "batch_size = 128\n",
    "do_use_cuda = True\n",
    "\n",
    "if do_use_cuda:\n",
    "    compute_device = torch.device('cuda')\n",
    "    do_pin_memory = True\n",
    "\n",
    "else:\n",
    "    compute_device = torch.device('cpu')\n",
    "    do_pin_memory = False\n",
    "\n",
    "training_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "inference_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageDataFrameDataset(train_split_df, 'id',\n",
    "                                 lbl_col='breed',\n",
    "                                 img_dir='./data/image-net-data/train',\n",
    "                                 transform=training_transforms)\n",
    "\n",
    "train_dl = data.DataLoader(train_ds,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=do_pin_memory)\n",
    "\n",
    "valid_ds = ImageDataFrameDataset(valid_split_df, 'id',\n",
    "                                 lbl_col='breed',\n",
    "                                 img_dir='./data/image-net-data/train',\n",
    "                                 transform=inference_transforms)\n",
    "\n",
    "valid_dl = data.DataLoader(valid_ds,\n",
    "                           batch_size=batch_size,\n",
    "                           pin_memory=do_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 2.21 s, total: 1min 9s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_ds = ImageDataFrameDataset(clean_img_preds_df, 'jpg_url',\n",
    "                                transform=inference_transforms)\n",
    "\n",
    "test_dl = data.DataLoader(test_ds,\n",
    "                          batch_size=batch_size,\n",
    "                          pin_memory=do_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {\n",
    "    'train': train_dl,\n",
    "    'valid': valid_dl,\n",
    "    'test': test_dl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Use transfer learning to create a CNN to classify dog breeds.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20d69fccac44e52b704445e38b90e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=138223492.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "model_transfer = models.wide_resnet50_2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dog breed classes in our training set\n",
    "\n",
    "num_dog_breeds = len(train_ds.classes)\n",
    "num_dog_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_final_layers = model_transfer.fc.in_features\n",
    "num_final_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layer(layer, unfreeze=False):\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layer(model_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.fc = nn.Sequential(\n",
    "    nn.Linear(num_final_layers, num_dog_breeds),\n",
    "    nn.LogSoftmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = model_transfer.to(compute_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "criterion_transfer = nn.NLLLoss()\n",
    "# optimizer_transfer = optim.Adam([\n",
    "#     {'params': model_transfer.layer3.parameters(), 'lr': 7e-5},\n",
    "#     {'params': model_transfer.layer4.parameters(), 'lr': 5e-4},\n",
    "#     {'params': model_transfer.fc.parameters(), 'lr': 3e-3}\n",
    "# ])\n",
    "optimizer_transfer = optim.Adam(params=model_transfer.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following import is required for training to be robust to truncated images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def train(n_epochs, loaders, model, optimiser, criterion, compute_device, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to compute device\n",
    "            data, target = data.to(compute_device, non_blocking=True), target.to(compute_device, non_blocking=True)\n",
    "                \n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimiser.step()        \n",
    "            \n",
    "            train_loss = train_loss + ((loss.item() - train_loss) / (batch_idx + 1))\n",
    "            \n",
    "            del data\n",
    "            del target\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to compute device\n",
    "            data, target = data.to(compute_device, non_blocking=True), target.to(compute_device, non_blocking=True)\n",
    "               \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            valid_loss = valid_loss + ((loss.item() - valid_loss) / (batch_idx + 1))\n",
    "            \n",
    "            if loss < valid_loss_min:\n",
    "                torch.save(model.state_dict(), 'model_transfer.pt')\n",
    "                valid_loss_min = valid_loss\n",
    "            \n",
    "            del data\n",
    "            del target\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the fully connected layer for the new number of classes (i.e.: number of dog breeds, as opposed to ImageNet classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 3.316281 \tValidation Loss: 1.528238\n",
      "Epoch: 2 \tTraining Loss: 1.654156 \tValidation Loss: 0.777113\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 7\n",
    "\n",
    "# train the model\n",
    "model_transfer = train(NUM_EPOCHS, \n",
    "                       data_loaders, \n",
    "                       model_transfer, \n",
    "                       optimizer_transfer, \n",
    "                       criterion_transfer, \n",
    "                       compute_device, \n",
    "                       'model_transfer.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreeze the last layer, and train some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layer(model_transfer.layer4, unfreeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.563123 \tValidation Loss: 1.272635\n",
      "Epoch: 2 \tTraining Loss: 1.335727 \tValidation Loss: 1.294836\n",
      "Epoch: 3 \tTraining Loss: 1.238240 \tValidation Loss: 1.250127\n",
      "Epoch: 4 \tTraining Loss: 1.086193 \tValidation Loss: 1.190099\n",
      "Epoch: 5 \tTraining Loss: 1.041907 \tValidation Loss: 1.185872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "# train the model\n",
    "model_transfer = train(NUM_EPOCHS, \n",
    "                       data_loaders, \n",
    "                       model_transfer, \n",
    "                       optimizer_transfer, \n",
    "                       criterion_transfer, \n",
    "                       compute_device, \n",
    "                       'model_transfer.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreeze the penultimate layer, and train some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layer(model_transfer.layer3, unfreeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.985819 \tValidation Loss: 1.405653\n",
      "Epoch: 2 \tTraining Loss: 0.929377 \tValidation Loss: 1.390401\n",
      "Epoch: 3 \tTraining Loss: 0.854332 \tValidation Loss: 1.178199\n",
      "Epoch: 4 \tTraining Loss: 0.842138 \tValidation Loss: 1.309852\n",
      "Epoch: 5 \tTraining Loss: 0.841108 \tValidation Loss: 1.479190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "# train the model\n",
    "model_transfer = train(NUM_EPOCHS, \n",
    "                       data_loaders, \n",
    "                       model_transfer, \n",
    "                       optimizer_transfer, \n",
    "                       criterion_transfer, \n",
    "                       compute_device, \n",
    "                       'model_transfer.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "\n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `dog_detector` functions developed above.  You are __required__ to use your CNN from Step 4 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def run_app(img_path):\n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that _you_ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ (Three possible points for improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed.\n",
    "\n",
    "## suggested code, below\n",
    "for file in np.hstack((human_files[:3], dog_files[:3])):\n",
    "    run_app(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(clean_predictions_df.loc[clean_predictions_df.pred_is_dog].pred_class.unique().to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate internal report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having cleaned the data, and generated data insights, we can now generate the internal documentation from this notebook's markdown cells.\n",
    "\n",
    "(you probably want to clear all output previous to the data insights output generated in the last section, and then SAVE the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --no-input --to pdf wrangle_act.ipynb\n",
    "# !mv wrangle_act.pdf wrangle_report.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
