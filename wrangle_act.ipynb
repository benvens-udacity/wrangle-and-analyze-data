{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project looks at various data sources for Tweets from the [WeRateDogs](https://twitter.com/dog_rates) Twitter account, specifically:\n",
    "\n",
    "1. the `twitter-archive-enhanced.csv` which contains the tweet text, as is the core data set\n",
    "1. the Twitter API is used to access the original tweets to retrieve missing fields such as the retweet and favorite counts\n",
    "1. an image prediction file containing the top 3 predictions for each of the (up to 4) dog pictures in the tweet\n",
    "\n",
    "Having gathered the data, we assess, clean and analyse it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a number of data assets including remote files on web servers, and JSON payloads returned by the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "WE_RATE_DOGS_TWEETS_PATH = 'data/twitter-archive-enhanced.csv'\n",
    "DOG_BREED_PREDICTIONS_SOURCE_URL = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the enhanced Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas `read_csv()` function is quite versatile when uploading data, and can be configured to handle different date formats, numeric data types, not available (NA) markers, etc. Getting this right upfront can save time, but requires the raw data in files to be eyeballed first. For this we can use command line tools like head & tail, or alternatively Excel, which allows column headings to be frozen, data to be sorted and searched, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at the raw data, we make the following observations:\n",
    "\n",
    "1. tweet Ids are large integers, we need to select an approriate integer datatype so no accuracy is lost\n",
    "1. some tweet Ids use floats, e.g.: `in_reply_to_status_id`, `in_reply_to_user_id`, with NaNs used as a Not Available marker, as mentioned above these need to be converted to integers\n",
    "1. time stamps are close to ISO 8601 format, and are GMT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actions taken to address above observations:\n",
    "\n",
    "* convert floating point tweets Ids to a 64-bit integer, retaining the Not Available representation\n",
    "* specifcally tell Pandas which columns are dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the enhanced Twitter archive, using explicit data types for fields, instead of letting Pandas infer them. The [Twitter API](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object) will define the data types for the Twitter sourced fields.\n",
    "\n",
    "To get around the fact that nullable numeric fields are interpreted by `read_csv()` as floats (thus allowing NaNs to represent null), we will map nullable tweet Ids to the Pandas nullable integer data type (Int64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_data_types = {\n",
    "    'tweet_id': np.int64,\n",
    "    'in_reply_to_status_id': 'Int64',\n",
    "    'in_reply_to_user_id': 'Int64',\n",
    "    'retweeted_status_id': 'Int64',\n",
    "    'retweeted_status_user_id': 'Int64',\n",
    "    'text': 'string',\n",
    "    'expanded_urls': 'string',\n",
    "    'rating_numerator': np.int32,\n",
    "    'rating_denominator': np.int32,\n",
    "    'name': 'string',\n",
    "    'doggo': 'string',\n",
    "    'floofer': 'string',\n",
    "    'pupper': 'string',\n",
    "    'puppo': 'string'\n",
    "}\n",
    "\n",
    "feed_date_cols = [\n",
    "    'timestamp', \n",
    "    'retweeted_status_timestamp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_tweets_df = pd.read_csv(WE_RATE_DOGS_TWEETS_PATH,\n",
    "                        index_col=['tweet_id'],\n",
    "                        dtype=feed_data_types,\n",
    "                        parse_dates=feed_date_cols)\n",
    "enhanced_tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first discrepancy we note is that, according to the project motivation document, the main \"archive contains basic tweet data for all 5000+ of their tweets\" however that is clearly not the case as, having loaded it, the number of tweets is less than half that. As this is the master data set we have been provided with, this is the data we have to go with, since it has been previously enhanced.\n",
    "\n",
    "To sanity check this row count, and make sure we have actually read in all the eprovided data, we will run a line count on the input file, which should roughly match the number of rows in the data frame. Any discrepancy on counts is due to those embeded new line (NL) characters in the tweet text, since the number of NL characters is what `wc` bases its line counts on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2518 data/twitter-archive-enhanced.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l {WE_RATE_DOGS_TWEETS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can double check the column data types, against the data type mapping provided to `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2356 entries, 892420643555336193 to 666020888022790149\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   in_reply_to_status_id       78 non-null     Int64              \n",
      " 1   in_reply_to_user_id         78 non-null     Int64              \n",
      " 2   timestamp                   2356 non-null   datetime64[ns, UTC]\n",
      " 3   source                      2356 non-null   object             \n",
      " 4   text                        2356 non-null   string             \n",
      " 5   retweeted_status_id         181 non-null    Int64              \n",
      " 6   retweeted_status_user_id    181 non-null    Int64              \n",
      " 7   retweeted_status_timestamp  181 non-null    datetime64[ns, UTC]\n",
      " 8   expanded_urls               2297 non-null   string             \n",
      " 9   rating_numerator            2356 non-null   int32              \n",
      " 10  rating_denominator          2356 non-null   int32              \n",
      " 11  name                        2356 non-null   string             \n",
      " 12  doggo                       2356 non-null   string             \n",
      " 13  floofer                     2356 non-null   string             \n",
      " 14  pupper                      2356 non-null   string             \n",
      " 15  puppo                       2356 non-null   string             \n",
      "dtypes: Int64(4), datetime64[ns, UTC](2), int32(2), object(1), string(7)\n",
      "memory usage: 303.7+ KB\n"
     ]
    }
   ],
   "source": [
    "enhanced_tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the Twitter API enrichment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to use the Twitter API to retrieve the original tweets, so that we can enrich our enhanced tweets data with the missing attributes previously idientified (`retweet_counts`, `favorite_counts`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having registered with Twitter as a developer, and obtained credentials and keys, we stored these in a private project directory and configuration file (which are excluded from our git repo, and thus won't be visible online in [github](https://github.com/benvens-udacity/wrangle-and-analyze-data/blob/main/wrangle_act.ipynb)).\n",
    "\n",
    "We now use those credentials to authenticate with Twitter for API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_creds(conf_path):\n",
    "    with open(conf_path, 'r') as cf:\n",
    "        config = yaml.load(cf, Loader=yaml.FullLoader)\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = read_creds('./config/private/creds.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = creds['consumer_api']['key']\n",
    "consumer_secret = creds['consumer_api']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = creds['access_token']['token']\n",
    "acess_secret = creds['access_token']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, acess_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the enrichment data in batches, for better performance, as API invocations are subject to significant network latency. Twitter also applies rate limiting to their APIs, so it is necessary to throttle the rate at which we make requests, and to retry any failed requests. Luckily, this can be handled automatically by the Tweepy library, by setting the `wait_on_rate_limit_notify` flag when configuring API connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    idxs = []\n",
    "    retweet_counts = []\n",
    "    favorite_counts = []\n",
    "    for status in batch:\n",
    "        tweet = status._json\n",
    "        idxs.append(tweet['id'])\n",
    "        retweet_counts.append(tweet['retweet_count'])\n",
    "        favorite_counts.append(tweet['favorite_count'])\n",
    "    return np.array(idxs, dtype=np.int64), np.array([retweet_counts, favorite_counts], dtype=np.int64).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.empty((0), dtype=np.int64)\n",
    "rows = np.empty((0, 2), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_tweets = len(enhanced_tweets_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 102 ms, total: 2.13 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for batch_start in range(0, num_tweets, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, num_tweets)\n",
    "    batch_tweet_ids = enhanced_tweets_df.iloc[batch_start:batch_end].index.to_numpy().tolist()\n",
    "    statuses = api.statuses_lookup(batch_tweet_ids, include_entities=False, map_=False)\n",
    "    b_indices, b_rows = process_batch(statuses)\n",
    "    indices = np.concatenate((indices, b_indices), axis=0)\n",
    "    rows = np.concatenate((rows, b_rows), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2331, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_counts_df = pd.DataFrame(index=indices, data=rows, \n",
    "                               columns=['retweet_counts', 'favorite_counts'], \n",
    "                               dtype='Int32').sort_index()\n",
    "tweet_counts_df.index.name = 'tweet_id'\n",
    "tweet_counts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we briefly double check on the expected column data type mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2331 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   retweet_counts   2331 non-null   Int32\n",
      " 1   favorite_counts  2331 non-null   Int32\n",
      "dtypes: Int32(2)\n",
      "memory usage: 41.0 KB\n"
     ]
    }
   ],
   "source": [
    "tweet_counts_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the breed prediction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to gather the breed prediction data. We will read this data from the CloudFront URL, as opposed to the local filesystem, to ensure we get the most up-to-date version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_preds_data_types = {\n",
    "    'tweet_id': 'Int64',\n",
    "    'jpg_url': 'string',\n",
    "    'img_num': np.int32,\n",
    "    'p1': 'string',\n",
    "    'p1_conf': np.float32,\n",
    "    'p1_dog': bool,\n",
    "    'p2': 'string',\n",
    "    'p2_conf': np.float32,\n",
    "    'p2_dog': bool,\n",
    "    'p3': 'string',\n",
    "    'p3_conf': np.float32,\n",
    "    'p3_dog': bool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the TSV (not CSV) records, and tell read_csv() to use a tab as the field separator\n",
    "\n",
    "img_preds_df = pd.read_csv(DOG_BREED_PREDICTIONS_SOURCE_URL,\n",
    "                           index_col=['tweet_id'],\n",
    "                           sep='\\t', \n",
    "                           dtype=img_preds_data_types)\n",
    "img_preds_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we check for correct data type mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2075 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   jpg_url  2075 non-null   string \n",
      " 1   img_num  2075 non-null   int32  \n",
      " 2   p1       2075 non-null   string \n",
      " 3   p1_conf  2075 non-null   float32\n",
      " 4   p1_dog   2075 non-null   bool   \n",
      " 5   p2       2075 non-null   string \n",
      " 6   p2_conf  2075 non-null   float32\n",
      " 7   p2_dog   2075 non-null   bool   \n",
      " 8   p3       2075 non-null   string \n",
      " 9   p3_conf  2075 non-null   float32\n",
      " 10  p3_dog   2075 non-null   bool   \n",
      "dtypes: bool(3), float32(3), int32(1), string(4)\n",
      "memory usage: 119.6+ KB\n"
     ]
    }
   ],
   "source": [
    "img_preds_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having gathered the data we will now assess it, ideally both visually and programmatically. \n",
    "\n",
    "Some of this visual assesment has already been done against the raw data in files, to ensure we used appropriate data types when uploading the data. Therefore some data quality issues (large integers stored as floating point, with potential loss of accuracy, which invalidates their meaning as an identifier) have been addressed at upload time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will inspect the data that has been uploaded into the corresponding dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise the number of viewable rows and columns\n",
    "# Retain some kind of row counts, as very large data sets may get loaded into the browser, causing memory issues\n",
    "\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assess some tweets that include a dog stage name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>890240255349198849</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-26 15:59:51+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Cassie. She is a college pup. Studying international doggo communication and stick theory. 14/10 so elegant much sophisticate https://t.co/t1bfwz5S2A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/890240255349198849/photo/1</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>Cassie</td>\n",
       "      <td>doggo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889665388333682689</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-25 01:55:32+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>Here's a puppo that seems to be on the fence about something haha no but seriously someone help her. 13/10 https://t.co/BxvuXk0UCm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/889665388333682689/photo/1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>puppo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889531135344209921</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-24 17:02:04+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Stuart. He's sporting his favorite fanny pack. Secretly filled with bones only. 13/10 puppared puppo #BarkWeek https://t.co/y70o6h3isq</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/889531135344209921/photo/1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Stuart</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>puppo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886366144734445568</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-15 23:25:31+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>This is Roscoe. Another pupper fallen victim to spontaneous tongue ejections. Get the BlepiPen immediate. 12/10 deep breaths Roscoe https://t.co/RGE08MIJox</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/886366144734445568/photo/1,https://twitter.com/dog_rates/status/886366144734445568/photo/1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Roscoe</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pupper</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884162670584377345</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017-07-09 21:29:42+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;</td>\n",
       "      <td>Meet Yogi. He doesn't have any important dog meetings today he just enjoys looking his best at all times. 12/10 for dangerously dapper doggo https://t.co/YSI00BzTBZ</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://twitter.com/dog_rates/status/884162670584377345/photo/1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Yogi</td>\n",
       "      <td>doggo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "tweet_id                                                         \n",
       "890240255349198849                   <NA>                 <NA>   \n",
       "889665388333682689                   <NA>                 <NA>   \n",
       "889531135344209921                   <NA>                 <NA>   \n",
       "886366144734445568                   <NA>                 <NA>   \n",
       "884162670584377345                   <NA>                 <NA>   \n",
       "\n",
       "                                   timestamp  \\\n",
       "tweet_id                                       \n",
       "890240255349198849 2017-07-26 15:59:51+00:00   \n",
       "889665388333682689 2017-07-25 01:55:32+00:00   \n",
       "889531135344209921 2017-07-24 17:02:04+00:00   \n",
       "886366144734445568 2017-07-15 23:25:31+00:00   \n",
       "884162670584377345 2017-07-09 21:29:42+00:00   \n",
       "\n",
       "                                                                                                source  \\\n",
       "tweet_id                                                                                                 \n",
       "890240255349198849  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "889665388333682689  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "889531135344209921  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "886366144734445568  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "884162670584377345  <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>   \n",
       "\n",
       "                                                                                                                                                                                    text  \\\n",
       "tweet_id                                                                                                                                                                                   \n",
       "890240255349198849         This is Cassie. She is a college pup. Studying international doggo communication and stick theory. 14/10 so elegant much sophisticate https://t.co/t1bfwz5S2A   \n",
       "889665388333682689                                    Here's a puppo that seems to be on the fence about something haha no but seriously someone help her. 13/10 https://t.co/BxvuXk0UCm   \n",
       "889531135344209921                        This is Stuart. He's sporting his favorite fanny pack. Secretly filled with bones only. 13/10 puppared puppo #BarkWeek https://t.co/y70o6h3isq   \n",
       "886366144734445568           This is Roscoe. Another pupper fallen victim to spontaneous tongue ejections. Get the BlepiPen immediate. 12/10 deep breaths Roscoe https://t.co/RGE08MIJox   \n",
       "884162670584377345  Meet Yogi. He doesn't have any important dog meetings today he just enjoys looking his best at all times. 12/10 for dangerously dapper doggo https://t.co/YSI00BzTBZ   \n",
       "\n",
       "                    retweeted_status_id  retweeted_status_user_id  \\\n",
       "tweet_id                                                            \n",
       "890240255349198849                 <NA>                      <NA>   \n",
       "889665388333682689                 <NA>                      <NA>   \n",
       "889531135344209921                 <NA>                      <NA>   \n",
       "886366144734445568                 <NA>                      <NA>   \n",
       "884162670584377345                 <NA>                      <NA>   \n",
       "\n",
       "                   retweeted_status_timestamp  \\\n",
       "tweet_id                                        \n",
       "890240255349198849                        NaT   \n",
       "889665388333682689                        NaT   \n",
       "889531135344209921                        NaT   \n",
       "886366144734445568                        NaT   \n",
       "884162670584377345                        NaT   \n",
       "\n",
       "                                                                                                                                      expanded_urls  \\\n",
       "tweet_id                                                                                                                                              \n",
       "890240255349198849                                                                  https://twitter.com/dog_rates/status/890240255349198849/photo/1   \n",
       "889665388333682689                                                                  https://twitter.com/dog_rates/status/889665388333682689/photo/1   \n",
       "889531135344209921                                                                  https://twitter.com/dog_rates/status/889531135344209921/photo/1   \n",
       "886366144734445568  https://twitter.com/dog_rates/status/886366144734445568/photo/1,https://twitter.com/dog_rates/status/886366144734445568/photo/1   \n",
       "884162670584377345                                                                  https://twitter.com/dog_rates/status/884162670584377345/photo/1   \n",
       "\n",
       "                    rating_numerator  rating_denominator    name  doggo  \\\n",
       "tweet_id                                                                  \n",
       "890240255349198849                14                  10  Cassie  doggo   \n",
       "889665388333682689                13                  10    None   None   \n",
       "889531135344209921                13                  10  Stuart   None   \n",
       "886366144734445568                12                  10  Roscoe   None   \n",
       "884162670584377345                12                  10    Yogi  doggo   \n",
       "\n",
       "                   floofer  pupper  puppo  \n",
       "tweet_id                                   \n",
       "890240255349198849    None    None   None  \n",
       "889665388333682689    None    None  puppo  \n",
       "889531135344209921    None    None  puppo  \n",
       "886366144734445568    None  pupper   None  \n",
       "884162670584377345    None    None   None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_tweets_df[(enhanced_tweets_df[['doggo', 'floofer', 'pupper', 'puppo']] != 'None').any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "\n",
    "1. HTML in the `source` columns, with a lot of repetition (to be verified programmatically)\n",
    "1. the varios rewteet columns frequently hold null values\n",
    "1. on occasions multiple values appearing in the `expanded_urls` column, including repeating values\n",
    "1. quite often no dog stage can be identified, and occasionally no dog name\n",
    "1. dog stages place the stage name in a column named after the stage, this is redundant information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_counts</th>\n",
       "      <th>favorite_counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666020888022790149</th>\n",
       "      <td>443</td>\n",
       "      <td>2344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666029285002620928</th>\n",
       "      <td>41</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666033412701032449</th>\n",
       "      <td>39</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666044226329800704</th>\n",
       "      <td>122</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666049248165822465</th>\n",
       "      <td>38</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    retweet_counts  favorite_counts\n",
       "tweet_id                                           \n",
       "666020888022790149             443             2344\n",
       "666029285002620928              41              118\n",
       "666033412701032449              39              107\n",
       "666044226329800704             122              259\n",
       "666049248165822465              38               93"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no immediate issues observed by assessing a small sample of the tweet counts data visually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666020888022790149</th>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666029285002620928</th>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666033412701032449</th>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666044226329800704</th>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666049248165822465</th>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            jpg_url  img_num  \\\n",
       "tweet_id                                                                       \n",
       "666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg        1   \n",
       "666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg        1   \n",
       "666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg        1   \n",
       "666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg        1   \n",
       "666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg        1   \n",
       "\n",
       "                                        p1   p1_conf  p1_dog  \\\n",
       "tweet_id                                                       \n",
       "666020888022790149  Welsh_springer_spaniel  0.465074    True   \n",
       "666029285002620928                 redbone  0.506826    True   \n",
       "666033412701032449         German_shepherd  0.596461    True   \n",
       "666044226329800704     Rhodesian_ridgeback  0.408143    True   \n",
       "666049248165822465      miniature_pinscher  0.560311    True   \n",
       "\n",
       "                                    p2   p2_conf  p2_dog                   p3  \\\n",
       "tweet_id                                                                        \n",
       "666020888022790149              collie  0.156665    True    Shetland_sheepdog   \n",
       "666029285002620928  miniature_pinscher  0.074192    True  Rhodesian_ridgeback   \n",
       "666033412701032449            malinois  0.138584    True           bloodhound   \n",
       "666044226329800704             redbone  0.360687    True   miniature_pinscher   \n",
       "666049248165822465          Rottweiler  0.243682    True             Doberman   \n",
       "\n",
       "                     p3_conf  p3_dog  \n",
       "tweet_id                              \n",
       "666020888022790149  0.061428    True  \n",
       "666029285002620928  0.072010    True  \n",
       "666033412701032449  0.116197    True  \n",
       "666044226329800704  0.222752    True  \n",
       "666049248165822465  0.154629    True  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following: \n",
    "\n",
    "1. each row refers to an image\n",
    "1. each image is numbered, as it is selected as the best of up to 4 dog images that may be associated with each tweet\n",
    "1. we then have the top 3 breed predictions for that image\n",
    "\n",
    "Each prediction consists of the following information:\n",
    "\n",
    "1. a predicted label or class (e.g.: the dog breed) that describes the image\n",
    "1. a confidence score associated with the above prediction, in the range 0.0 -> 1.0 (0% to 100% confident)\n",
    "1. a boolean indicator confirming if the predicted label is a dog breed, or some other object\n",
    "\n",
    "Looking at the confidence score for predictions p1 - p3, they appear to be listed in most confident to least confident order. Therefore we will use the column name numeric suffix to generate a ranking column, which we can later sort by (to preserve this decreasing confidence order).\n",
    "\n",
    "This last attribute confirms that the image classifier used to generate these prediction was trained on a broad set of images, only a subset of which are dog images labelled with their corresponding dog breed. But on occasions the classifier may have interpreted a dog image as an object other than a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatic assesment gives us the opportunity to validate observations, and search for anomalies, across the entire dataset. This is very difficult to do visually unless the dataset is small, both in trems of the number of rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess level of repetition in the `source` column, which holds an HTML anchor node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>     2221\n",
       "<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                          91\n",
       "<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                       33\n",
       "<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>      11\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_tweets_df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above results there appear to be 4 sources corresponding to the related applications: iPhone Twitter app, Vine app, Twitter web client and TweetDeck. This data contains a lot of redundant and messy information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are tweets where more than one dog stage is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((enhanced_tweets_df[['doggo', 'floofer', 'pupper', 'puppo']] != 'None').sum(axis=1) > 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will quickly validate that all counts are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet_counts     True\n",
       "favorite_counts    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tweet_counts_df >= 0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the number of entries in the enriched tweets dataframe to the number of entries in the tweet counts dataframe, to see of we successfully retrieved counts for all tweets from the API. The small difference in counts suggests a small number of tweets can no longer be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 2331)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enhanced_tweets_df.index), len(tweet_counts_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will validate the assumption made earlier that the confidence scores are ordered by the numeric suffix of the column name, which can be used to populate a ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((img_preds_df['p1_conf'] > img_preds_df['p2_conf']) & (img_preds_df['p2_conf'] > img_preds_df['p3_conf'])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we validate that all confidence scores are in the range 0.0 to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img_preds_df['p1_conf'].between(0.0, 1.0) & \n",
    "img_preds_df['p2_conf'].between(0.0, 1.0) & \n",
    "img_preds_df['p3_conf'].between(0.0, 1.0)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of the visual and programmatic assessments, the following data quality have been found, which will require data content to be cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. the immediate data quality concern is that the project motivation document states that the \"archive contains basic tweet data for all 5000+ of their tweets\" but we are loading less than half that number of tweets. **However, given the enhanced tweets dataset is our master dataset, there is nothing that we can do to remedy the much smaller number of rows, beyond highlighting this observation**\n",
    "1. as previously mentioned, the issue with some tweet Id columns being treated as floating point numbers, and the fact that rounding could invalidate these, was resolved at data loading time (without impacting the fact that they are nullable columns)\n",
    "1. the format of the `timestamp` is very close to an ISO 8601 timestamp, however it is missing the 't' character as the separator between the date and time portions. There are definite advantages in following a recognised standard, as this will be understood by tools such as database import utilities, however Pandas has correctly parsed dates\n",
    "1. in the `source` column, extract the source app name from the HTML anchor string, and then map this column to a Pandas categorical\n",
    "1. it is unclear why, in the `expanded_urls` columns, the same URL get repeated, since looking at the tweet text there is only one reference to the corresponding link. Therefore we will remove duplicates\n",
    "1. convert the dog stage columns into boolean datatype, and interpret the constant value 'None' as a missing stage\n",
    "1. since the dog stage column names are the stages, storing that same name as a value is redundant information, following on from the previous observation, where the dog stage appears we will just store a boolean true value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. while the intention is to obtain retweet and favorite counts for all the tweets in the enhanced tweets dataset, we cannot guarantee that the Twitter API will always return the original Tweet, e.g.: it may subsequently have been deleted\n",
    "1. where the counts were successfully retrieved for the original tweet (the majority of cases, as proven in the programatic assesment), then there is a one-to-one relationship between the rows in the counts dataframe, and the rows in the enhanced tweets dataframe. Therefore the counts columns can be merged back into the enhanced tweets dataframe, as arguably they are part of that tweet observation. In the few cases where the counts are missing, we will store nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obvious data quality issues, beyond the prediction column names being used as variables (the numeric suffix added). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at data frame structure, column naming, and inspecting values, and then applying the [Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf) principles, the following structural issues will need to be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. the `source` column must store a category that represent the application (and possibly device) used to author the tweet\n",
    "1. the `expanded_urls` column can store multiple values per row, depending on the web links embeded in the tweet text, therefore these observations need to be stored in a separate table (however, we will first remove any duplicate values).\n",
    "1. dog stage is a multivalued categorical variable, as a tweet can reference more than one stage. Therefore we retain the existing columns but encode them in the style of one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retweet and favorite counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obvious structural issues here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a variable (prediction number) is embeded in the column names of the prediction columns (predicted breed, prediction confidence, and is-a-dog flag)\n",
    "2. the prediction number ranks the predictions in the order most confident (1st prediction) to least confident (3rd prediction)\n",
    "3. the actual breed predictions should be held in a separate dataframe, and linked back to the tweet and tweet image they are associated with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now clean the issues uncovered during assesment using a _define/code/test_ framework, which will be applied to each of the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_enhanced_tweets_df = enhanced_tweets_df.copy()\n",
    "clean_enhanced_tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Extract tweet application from `source` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* parse source column which holds an HTML anchor node \n",
    "* extract anchor node content, describing the application used\n",
    "* convert the column to Pandas categorical, as a more efficient representation that can be used in models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract content from anchor node\n",
    "\n",
    "clean_enhanced_tweets_df['source'] = \\\n",
    "    clean_enhanced_tweets_df['source'].str.extract(r'[^<]*a href=\"[^\"]+\" rel=\"[^\"]+\">([^<]+)<\\/a>')\n",
    "\n",
    "# Convert column to categorical\n",
    "\n",
    "clean_enhanced_tweets_df['source'] = clean_enhanced_tweets_df['source'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that the tweet source column is now a categorical, and the number of categories is that expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert column data type is categorical\n",
    "\n",
    "assert isinstance(clean_enhanced_tweets_df['source'].dtype, pd.CategoricalDtype),'Expect categorical'\n",
    "\n",
    "# Assert the number of categories is as expected\n",
    "\n",
    "assert len(clean_enhanced_tweets_df['source'].cat.categories) == 4, 'Expect 4 application categories'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Move `expanded_urls` to a detail dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* split multi-valued string of comma separated URLs, into URL arrays\n",
    "* remove any duplicate URLs from the array\n",
    "* convert each array into list of tuples, bound to the containing `tweet_id`\n",
    "* stores these tuples as rows in a new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out rows containing one or more expanded URLs, as some rows have none\n",
    "\n",
    "expanded_urls_col = \\\n",
    "    clean_enhanced_tweets_df.loc[clean_enhanced_tweets_df['expanded_urls'].isna() == False]['expanded_urls']\n",
    "\n",
    "# Nested list comprehension to split multiple URL strings on comma separator, then create [tweet Id, URL] tuples\n",
    "\n",
    "expanded_url_tuples = [(ix, url) for ix, urls in expanded_urls_col.iteritems() for url in urls.split(',')]\n",
    "expanded_url_df = pd.DataFrame(expanded_url_tuples, columns=['tweet_id', 'expanded_url'])\n",
    "\n",
    "# Now drop duplicates and make 'tweet_id' the index for consistency with other dataframes\n",
    "\n",
    "expanded_url_df = expanded_url_df.drop_duplicates().set_index('tweet_id')\n",
    "\n",
    "# Finally drop the original expanded_urls column\n",
    "\n",
    "clean_enhanced_tweets_df = clean_enhanced_tweets_df.drop(columns='expanded_urls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will count total and unique tweet Ids in the new dataframe holding expanded URLs. The later will be lower, accounting for multiple rows (hence web links in the tweet text) associated with the same tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 2297)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the index can contain duplicate entries (whenever a tweet has more than one URL)\n",
    "# We compare duplicate and non-duplicate counts below\n",
    "\n",
    "len(expanded_url_df.index), len(expanded_url_df.index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Convert dog stage columns to boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* where the value 'None' is stored, set False, otherwise set True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dog stage columns into a boolean data type\n",
    "\n",
    "stage_cols = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "clean_enhanced_tweets_df[stage_cols] = clean_enhanced_tweets_df[stage_cols].apply(lambda c: c.to_numpy() != 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that the dog stage columns are now boolean type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2356 entries, 892420643555336193 to 666020888022790149\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   in_reply_to_status_id       78 non-null     Int64              \n",
      " 1   in_reply_to_user_id         78 non-null     Int64              \n",
      " 2   timestamp                   2356 non-null   datetime64[ns, UTC]\n",
      " 3   source                      2356 non-null   category           \n",
      " 4   text                        2356 non-null   string             \n",
      " 5   retweeted_status_id         181 non-null    Int64              \n",
      " 6   retweeted_status_user_id    181 non-null    Int64              \n",
      " 7   retweeted_status_timestamp  181 non-null    datetime64[ns, UTC]\n",
      " 8   rating_numerator            2356 non-null   int32              \n",
      " 9   rating_denominator          2356 non-null   int32              \n",
      " 10  name                        2356 non-null   string             \n",
      " 11  doggo                       2356 non-null   bool               \n",
      " 12  floofer                     2356 non-null   bool               \n",
      " 13  pupper                      2356 non-null   bool               \n",
      " 14  puppo                       2356 non-null   bool               \n",
      "dtypes: Int64(4), bool(4), category(1), datetime64[ns, UTC](2), int32(2), string(2)\n",
      "memory usage: 205.0 KB\n"
     ]
    }
   ],
   "source": [
    "clean_enhanced_tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in stage_cols:\n",
    "    assert clean_enhanced_tweets_df[col].dtype == 'bool', 'Expect boolean column'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Merge retweet and favorite counts into enhanced tweets dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* merge retweet and favorite count columns into enhanced tweets dataframe, using a left join with nulls for missing count values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_enhanced_tweets_df = clean_enhanced_tweets_df.merge(tweet_counts_df, how='left', on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate number of rows after merge, including count of rows with null retweet or favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retweet_counts     25\n",
       "favorite_counts    25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total rows (should be unchanged), and null retweet and favorite counts (tweets no longer available)\n",
    "\n",
    "print(len(clean_enhanced_tweets_df.index))\n",
    "clean_enhanced_tweets_df[['retweet_counts', 'favorite_counts']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Melt image prediction column headers into detail dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define**\n",
    "\n",
    "* store `jpg_url` and `img_num` columns in a clean dataframe\n",
    "* melt prediction 1 to 3 columns into temporary dataframes, with the prediction rank as a constant value, and the related `tweet_id`\n",
    "* stack the above temporary dataframes into a predictions dataframe, with repeated `tweet_id` as the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_img_preds_df = img_preds_df.copy()\n",
    "clean_img_preds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_pred_cols(df, numeric):\n",
    "    preds_df = pd.DataFrame(data={'pred_rank':       numeric,\n",
    "                                  'pred_class':      df[f'p{numeric}'],\n",
    "                                  'pred_confidence': df[f'p{numeric}_conf'],\n",
    "                                  'pred_is_dog':     df[f'p{numeric}_dog']})\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1_df = melt_pred_cols(clean_img_preds_df, 1)\n",
    "preds2_df = melt_pred_cols(clean_img_preds_df, 2)\n",
    "preds3_df = melt_pred_cols(clean_img_preds_df, 3)\n",
    "\n",
    "clean_predictions_df = pd.concat([preds1_df, \n",
    "                                  preds2_df, \n",
    "                                  preds3_df]).sort_values(by=['tweet_id', 'pred_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop melted prediction columns\n",
    "\n",
    "clean_img_preds_df = clean_img_preds_df.drop(columns=['p1', 'p1_conf', 'p1_dog', \\\n",
    "                                                      'p2', 'p2_conf', 'p2_dog', \\\n",
    "                                                      'p3', 'p3_conf', 'p3_dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate dataframe column names and structure as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2075 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   jpg_url  2075 non-null   string\n",
      " 1   img_num  2075 non-null   int32 \n",
      "dtypes: int32(1), string(1)\n",
      "memory usage: 40.5+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_img_preds_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6225 entries, 666020888022790149 to 892420643555336193\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   pred_rank        6225 non-null   int64  \n",
      " 1   pred_class       6225 non-null   string \n",
      " 2   pred_confidence  6225 non-null   float32\n",
      " 3   pred_is_dog      6225 non-null   bool   \n",
      "dtypes: bool(1), float32(1), int64(1), string(1)\n",
      "memory usage: 176.3 KB\n"
     ]
    }
   ],
   "source": [
    "clean_predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate master/detail row counts\n",
    "\n",
    "assert len(clean_img_preds_df.index) == (len(clean_predictions_df.index) / 3), 'Expect 3x number of detail rows'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we look at the data and analyse it to obtain some insights. Specifically, we are interested in:\n",
    "\n",
    "1. Finding the number of tweets with a score above 10/10, versus tweets with a score under 10/10\n",
    "2. Identify the tweets where more than one dog stage appears\n",
    "3. Finding the number of top breed predictions from the image classifier, with a predictionconfidence below 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count number of scores above and below 10/10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 905)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((clean_enhanced_tweets_df['rating_numerator'] / clean_enhanced_tweets_df['rating_denominator']) > 1.0).sum(), \\\n",
    "((clean_enhanced_tweets_df['rating_numerator'] / clean_enhanced_tweets_df['rating_denominator']) <= 1.0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show tweets with more than one dog stage in the tweet text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855851453814013952</th>\n",
       "      <td>Here's a puppo participating in the #ScienceMarch. Cleverly disguising her own doggo agenda. 13/10 would keep the planet habitable for https://t.co/cMhq16isel</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854010172552949760</th>\n",
       "      <td>At first I thought this was a shy doggo, but it's actually a Rare Canadian Floofer Owl. Amateurs would confuse the two. 11/10 only send dogs https://t.co/TXdT3tmuYk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817777686764523521</th>\n",
       "      <td>This is Dido. She's playing the lead role in \"Pupper Stops to Catch Snow Before Resuming Shadow Box with Dried Apple.\" 13/10 (IG: didodoggo) https://t.co/m7isZrOBX7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808106460588765185</th>\n",
       "      <td>Here we have Burke (pupper) and Dexter (doggo). Pupper wants to be exactly like doggo. Both 12/10 would pet at same time https://t.co/ANBpEYHaho</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802265048156610565</th>\n",
       "      <td>Like doggo, like pupper version 2. Both 11/10 https://t.co/9IxWAXFqze</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801115127852503040</th>\n",
       "      <td>This is Bones. He's being haunted by another doggo of roughly the same size. 12/10 deep breaths pupper everything's fine https://t.co/55Dqe0SJNj</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785639753186217984</th>\n",
       "      <td>This is Pinot. He's a sophisticated doggo. You can tell by the hat. Also pointier than your average pupper. Still 10/10 would pet cautiously https://t.co/f2wmLZTPHd</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781308096455073793</th>\n",
       "      <td>Pupper butt 1, Doggo 0. Both 12/10 https://t.co/WQvcPEpH2u</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775898661951791106</th>\n",
       "      <td>RT @dog_rates: Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770093767776997377</th>\n",
       "      <td>RT @dog_rates: This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759793422261743616</th>\n",
       "      <td>Meet Maggie &amp;amp; Lila. Maggie is the doggo, Lila is the pupper. They are sisters. Both 12/10 would pet at the same time https://t.co/MYwR4DQKll</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751583847268179968</th>\n",
       "      <td>Please stop sending it pictures that don't even have a doggo or pupper in them. Churlish af. 5/10 neat couch tho https://t.co/u2c9c7qSg8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741067306818797568</th>\n",
       "      <td>This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733109485275860992</th>\n",
       "      <td>Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    text  \\\n",
       "tweet_id                                                                                                                                                                                   \n",
       "855851453814013952        Here's a puppo participating in the #ScienceMarch. Cleverly disguising her own doggo agenda. 13/10 would keep the planet habitable for https://t.co/cMhq16isel   \n",
       "854010172552949760  At first I thought this was a shy doggo, but it's actually a Rare Canadian Floofer Owl. Amateurs would confuse the two. 11/10 only send dogs https://t.co/TXdT3tmuYk   \n",
       "817777686764523521  This is Dido. She's playing the lead role in \"Pupper Stops to Catch Snow Before Resuming Shadow Box with Dried Apple.\" 13/10 (IG: didodoggo) https://t.co/m7isZrOBX7   \n",
       "808106460588765185                      Here we have Burke (pupper) and Dexter (doggo). Pupper wants to be exactly like doggo. Both 12/10 would pet at same time https://t.co/ANBpEYHaho   \n",
       "802265048156610565                                                                                                 Like doggo, like pupper version 2. Both 11/10 https://t.co/9IxWAXFqze   \n",
       "801115127852503040                      This is Bones. He's being haunted by another doggo of roughly the same size. 12/10 deep breaths pupper everything's fine https://t.co/55Dqe0SJNj   \n",
       "785639753186217984  This is Pinot. He's a sophisticated doggo. You can tell by the hat. Also pointier than your average pupper. Still 10/10 would pet cautiously https://t.co/f2wmLZTPHd   \n",
       "781308096455073793                                                                                                            Pupper butt 1, Doggo 0. Both 12/10 https://t.co/WQvcPEpH2u   \n",
       "775898661951791106                                                                             RT @dog_rates: Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda   \n",
       "770093767776997377                                                            RT @dog_rates: This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC   \n",
       "759793422261743616                      Meet Maggie &amp; Lila. Maggie is the doggo, Lila is the pupper. They are sisters. Both 12/10 would pet at the same time https://t.co/MYwR4DQKll   \n",
       "751583847268179968                              Please stop sending it pictures that don't even have a doggo or pupper in them. Churlish af. 5/10 neat couch tho https://t.co/u2c9c7qSg8   \n",
       "741067306818797568                                                                           This is just downright precious af. 12/10 for both pupper and doggo https://t.co/o5J479bZUC   \n",
       "733109485275860992                                                                                            Like father (doggo), like son (pupper). Both 12/10 https://t.co/pG2inLaOda   \n",
       "\n",
       "                    doggo  floofer  pupper  puppo  \n",
       "tweet_id                                           \n",
       "855851453814013952   True    False   False   True  \n",
       "854010172552949760   True     True   False  False  \n",
       "817777686764523521   True    False    True  False  \n",
       "808106460588765185   True    False    True  False  \n",
       "802265048156610565   True    False    True  False  \n",
       "801115127852503040   True    False    True  False  \n",
       "785639753186217984   True    False    True  False  \n",
       "781308096455073793   True    False    True  False  \n",
       "775898661951791106   True    False    True  False  \n",
       "770093767776997377   True    False    True  False  \n",
       "759793422261743616   True    False    True  False  \n",
       "751583847268179968   True    False    True  False  \n",
       "741067306818797568   True    False    True  False  \n",
       "733109485275860992   True    False    True  False  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_cols = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "clean_enhanced_tweets_df.loc[clean_enhanced_tweets_df[stage_cols].sum(axis=1) > 1][['text'] + stage_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count tweets where the top scoring breed prediction is below 0.5** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_preds = clean_predictions_df.loc[(clean_predictions_df['pred_rank'] == 1) \\\n",
    "                                     & clean_predictions_df['pred_is_dog']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dog_preds[dog_preds['pred_confidence'] < 0.5].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to generate some visualisations:\n",
    "\n",
    "1. First, based on the top image prediction, look at the frequency distribution for the top 10 breeds only, based on number of tweets\n",
    "2. Now look at the frequency distribution for the top 10 breeds only, based on aggregate number of favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breed prediction distribution by number of tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='pred_class'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAADnCAYAAABmFS8yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+qklEQVR4nO2dd3hc1bW33zWSbNmWLfde5IYl27Llig2uogYbQieVFkIgvoQESK7zpTAhN4lT4KaR6zSCISQQSAgEJxDAsdx7tyXj3ntv0khz1vfHPsJjoTIjzZwzkvb7POfRmXP22WvNSPrNrmuJqmKxWCwWCPjtgMVisSQLVhAtFovFxQqixWKxuFhBtFgsFhcriBaLxeJiBdFisVhcrCBaLBaLixVEi8VicbGCaLFYLC5WEC0Wi8XFCqLFYrG4WEG0WCwWFyuIFovF4mIF0WKxWFysIFosFouLFUSLxWJxsYJosVgsLlYQLRaLxcUKosVisbj4IogicjaGskEReSKOtu8VkV/Gq74o7E0SkSuquX+TiEz3yh+LxVI1qX47EA9EJFVVy/yqu4Yyk4CzwKIqnnsTeLPOjtbON4vFEkHSdJlF5EYRWSoiq0XkPRHpFHF7qIgsFpEtIvJ5t/wkEZkvIm8Cm9xrfxeRlSKyUUQejKj7PhH5QESWAVdGXM8SkTkisk5E3heRnu7150VkpogsBX5Uhb9BEXlRRBYCL4pIBxH5q4gsd48rRSQLeAj4ioisEZHxFeuObLFWUUdARHaKSOsI21tEpFNl5Svzrc6/HIulsaCqnh/A2UqutQHEPX8AeNo9DwJrgWZAe2AP0BXT8joH9I6oo637sxmwAWgHdAF2Ax2AJsBC4JduuX8A97jn9wN/d8+fB94CUqp5D0FgJdDMff0nYJx73hMojCj3RMRzl9QN3BvhT1V1/Ay4zz2/HHgvCpsf+mYPe9gjuiOZuszdgVdEpAtGuHZE3HtDVS8AF0TkP8Bo4CSwTFUjy31JRG5xz3sA/YHOwFxVPQIgIq8Al7llxgK3uucvcmlr8FVVDdfg85uuXwBXAwNFpPxeKxHJqOK5ququqo5XgG8DfwA+4b6uyWakbxaLJQqSSRB/ATyjqm+KyCRMK6ccrVC2/PW58gvuM1cDY1X1vIjMBdLr4M+5motcUiYAjFHV4sgCEWIVTd1V1bEY6CciHYCbgf+JwmY0/lsslgiSZgwRyAT2uef3VLj3cRFJF5F2mK7y8iqeP+GKYTYwxr2+FJgoIu1EJA24I+KZRZgWF8Cngfl18P/fwCPlL0Qkzz09A7SsSx2qqsDrwDOYbvGxGmxaLJZa4JcgNheRvRHHY5gW4asishI4WqH8OuA/wBLgu6q6v5I63wZSRaQQmOGWRVUPuHUvxowfFkY88whwn4isAz4LPFqH9/QlYKQ7QbMJM5kCZpzylvJJlVrWAaab/BkudpdrKm+xWGKkfBLDYqmcYGYqMAAzHtsWM/nVOuKo+Lo5prt+2j3OVHF+AtgKbCZ46oAXb8ViqQkriJaLBDPbA0OBIRE/BwJNE2z5NPDBy2WT3p9e9uAxYA2wZueMKUcSbNdiuYRkmlRJSkTkPj7alV6oqtP88CduBDObAhOBfCAPI35dfPKmFTCySHuWYmb+AciaPnsXMAd4D3h/54wph3zyz9JIsC3ExkQwsw9wA3A9MBnTvU0abij5/rZNmtW3miIbMOL4HlCwc8aUqLeAWizRYAWxoRPMzAFud48hPntTJaqE+pW8GAiTEm2vJQT8C/gj8I+dM6aUJM47S2PBCmJDJJjZCXgQ+CSQ47M3UXFBm2zJKXm+fy0fPwm8hhHHeTtnTLF/1JZaYQWxIRHMHAp8BSOETXz2Jia2Ol0XXR36SZVRgWJgN/AS8H87Z0zZE4f6LI0IK4j1nWBmALgRI4QTffam1vwtPK7gsdIvxtP/MuDPwI92zpiyIY71WhowVhDrK8HMlpiAFI8A1U1E1Au+Vvr5ZX8JTx6doOr/iRHGggTVb2kgWEGsbwQz2wFfBz6PWa7SIJhc8vSeHdqlR4LNLAVm7Jwx5e8JtmOpp1hBrC8EM1OAh4GnMLtDGgyqnOtd8lJzqDwSRgJYCHx554wpKzyyZ6knWEGsDwQzJwE/B3J99iQhnNX0TYNLnhvosVkFXgC+vnPGFLt10AJYQUxugpk9gZ9waYSeBsdGp9eCKaEfjPPJ/FngB8AzO2dMKa6psKVhk0zhvyzlBDPTCWY+CRTRwMUQYLXTr6ZAvIkkA/geUJg1ffaNPvphSQKsICYbwcwbMSHKgphUCA2eJc7AaONFJpIs4M2s6bN/nzV9dlWRzi0NHNtlThaCmU2AH2NiHDYqxhb/4tAB2nWquaRnbAfu3jljykK/HbF4ixXEZCCYmQX8BRjlsyee4ygn+pT8KRlnzR1Mjp1v75wxpdRvZyzeYLvMfhPMvAlYRSMUQ4BTtEjW7XUBYDqwNGv6bK9nwC0+YQXRL4KZqQQznwbeoIGtK4yF7dr1pN8+1MAwYFnW9Nk3++2IJfFYQfSDYGYPYB7wmN+u+M1K57KaC/lPC+BvWdNnf91vRyyJxQqi1wQzrwdWExEZujGzxMlp7bcPUSLA97Omz34xa/rsRKdUsPiEFUQvCWbeB7wFtPPblWRhldM/0fuX481ngP9kTZ+dTLPiljhhBdErgplfBZ4DUvx2JVkIqxw6Scv6OH46FjOu6FkEchF5XkRur+T6JBF5yys/Ktj+fzXc/6eItPbInbhgBdELgpk/wizhsERwnFb7/PahDvTEtBSH+e1IIhGR6r7AKxVEMQRU9QZVPZkYz2r0rVZYQUwgubNyZfLvB/7oWCBwn9++JCMfON3P+O1DHWkLvJc1ffbw2jwsIt8Skc0iskBE/iwiT4hInogsEZF1IvK6iHykBS0i14tIkYisAm6NuN5CRJ4TkWUislpEPu5ev1dE/iYib4vIFhGp9stZRM6KyNMishYYKyKfcetcIyK/FpEUEZkBNHOvvSQiWe57eQGTDKyHiOwUkfZunZXV8ZCI/DjC7r0i8suqylfmW20+9+qwgpggcmflCvCbo6kpX72+R9djpwKBk377lGwsc7IbwvBBrURRREYBt2HyX38MGOneegH4b1UdAqwHnqzwXDrwW0yU9BFA54jb3wDmqOpoTFbFH4tIC/deHnAXJmLSXSJS3dhtC2Cpqg4FjrnPXamqeUAY+LSqTgcuqGqeqn7afa4/8CtVHaSquyJ8zqmsDuCvwC0Rdu8CXq6m/CW+qeqCat5DrbCCmAByZ+UGgN8DDwAUBwIDruvRdd9ZkfreIoorS5yctn77ECfaYERxRAzPXAm8oarFqnoG+Afmn721qpZH9p4FTKjwXDawQ1W3qNlm9seIe9cC00VkDTAXSMd07QHeV9VTqloMbAJ6VeNbGCNWAFdhhHe5W+9VQJ8qntulqksquV5pHap6BNguImNEpJ373hbWYDPSt7hjE9Unhl8Dl3STzwUCg67v0XXtu3v292+mmlT5kP1AFV2nfbP89iOOlIviNT4GnhXgNlXdfMlFkcuByDStYar/3y9W1fIIRALMUtVo1mCeq8avqup4GbgTE9npdVVVEamufKRvcce2EONM7qzc6bgtw4qcSkkZekP3roWhS/84GyVlpOy5QNOG9sXQGvh31vTZ0aR+XQjcKCLpIpIBTMUIygkRGe+W+SxQMQ9MEZAlIuV5dD4Zce8d4BFXUBCReEz4vA/cLiId3Trbikh567JURNLqWMfrwMfd9/FyFOUTihXEOJI7K/c24PvVlTmamjJiaveua8pMVrhGyyHaHPTbhwTRBvhnTesUVXU58CawDvgXZrzwFHAPZuxvHWbc76kKzxVjcm7PdidVDkfc/i6QBqwTkY3u6zqhqpuAbwL/dn16F+ji3v6Na+ul2tahqicw4e56qeqyKGwmFBvtJk7kzsodhfk2jyqGYVaodNEb+w6MCTTSL6V3wyMKPl/6eL1NmxoFK4CJO2dMOV9VARHJUNWzItIcs5XzQVVd5ZmHlo/QKP8Z403urNwemG/7qAO67mySdsUnunZeqCa3R6NjqZMdTVerPjMSeDFr+uzqEmf9xp00WAX81Yqh/1hBrCO5s3IzMNvxOtdUtiKFTZuMv7dLx3nx9yr5WeZkd/DbBw+4Ffh2VTdV9VPuspVsVf2Bh34BICJL3XV+kUeDTGQWLbbLXAfc5TVvYAbEa8348xfm/urQkUlxcaoeoEpp/5IXKCO1obcSwfQAbt85Y8rf/HbEUjO2hVg3vksdxRBgfvNmk77Wod3cOntTTyghbXcjEUMwS06ez5o+u7ffjlhqxgpiLcmdlTsW+O941fevjBaTnmrXpuISiwbJfm13uOZSDYqWwAtZ02c3hJ05DRoriLUgd1Zuc8wWq7j+gb/aquXEZ9q0bvBjiuu1d8hvH3xgHCYlgSWJsYJYO34M9EtExX/IbDn+N5mt4r5HM5lY6uSk++2DTzwZ4/Y+i8dYQYyR3Fm51wAPJ8yAiPyiTebYP7XMWJwwGz6zzMmOeUa+gZAGvJQ1fXZD26HTYLCCGAO5s3JbY4K8Vre2rO6IpPygXZuRb2S0WJ5QOz6gyoVt2rW+RcmOJwOAn/jthKVyrCDGxs+B7p5YEkn7Zvu2ue82b9agFuuep+kuJdDY/+4ezpo+O99vJywfpbH/YUZN7qzcmzGb7b1DJP2xju0HLGiWvs5Tuwlkt3Y85rcPScJP7axz8mEFMQpyZ+U2AZ7xxbhIi4c7dcha2bRpoS/248xap1+jDmoRQS7wBb+dsFyKFcToeBjwb2GtSKv7unTstLFJky2++RAnljg5LWou1Wh4Kmv67PqYZKvBYgWxBnJn5bbChCLyFRVp+8munVpvTUvb4bcvdWGFDujmtw9JRDvgO347YbmIFcSa+RrQ3m8nAFSkw23dOqfvTk3d67cvtUGVU3u1gydx7eoRD2dNnz3QbycshpgFUUTCblSMDSLyqhvLrU6IyFwRGVlzySqfrzRnbV3JnZXbBfhKvOutC45Il4937+IcSEk54LcvsXKa5rv99iEJSQV+6rcTFkNtWojlmbYGAyHgoTj7VCki4kf+lyCQdItoy0R6Tu3R9cLRlMARv32JhR3a5aTfPiQp12RNn32l305Y6t5lng/0qyEf7N9F5F03R+t/ichjbpklIhKZde2zES3P0e7zQRF5UUQWAi+6uV/niMlZ+76I9KzokIh8120xpojIV0VkuVs+prGa3Fm5A4DP1f6jSSwhkT4f6971eH1Kb7rK6W9jzVWN3eecBNRaEN0W28cwuSCqywc7GBMocxTwPeC8qg4DFgN3R1TZ3M3B+kXMbpByBgJXq+ongV9gsnENAV7CLJSO9OnHQAdMxrurMHliR2NyU4wQkYopHavje8Q5eEO8qW/pTRc7A1v57UMSMyVr+uzBfjvR2KmNIDZzw56vAHZj8g9Xlw/2P6p6xs3BegqTfxaMkGZF1PtnAFWdB7QSkdbu9TdV9YJ7Phb4k3v+IiaCSDnfAjJV9SE3X+217rEaE6I9GyOQNZI7K7cfRsSTHje96fYLIlXm7kgWVjr9G/OWvZoQzASexUfqMoaYp6qPqGqIi/lgy6/3VNXyhcSRKTediNcOl+aGrdidKn9dVa7XiizHtALLu+EC/CDCp36q+vso6/oSid6vHEfqQ3rTsMqR42S289uPJOeTWdNnf2QYyOId8Vp2E498sHe5z44DTqnqqUrKLAI+4Z5/GjOGWc7bwAxMesaWrk/3uzlvEZFu5Xleq8Ndd3hvLfz3laOpKSOm9ui6NlnTm56gZb1cKuQxqcATfjvRmImXIMYjH2yxiKwGZlL1ZMYjwH1urtbPAo9G3lTVV4HfYjLgzcd0rxeLyHrgNUzk4pq4P8pySceB1NTRt3Trsswxre+kYovTvV6McyYBn8uaPtu2pH3CJpmqQO6s3ELMeGO9JbsktOAv+w9eKUnU7f952c0Lnim7c1zNJS3AIztnTPml3040RuxOlQhyZ+WOp56LIUBR0ybj7unScX7NJb1jqTPQ7tmNnrtrLmJJBFYQL+UBvx2IF6vT0yc83KnDXL/9AFBF1zh97WRB9IzKmj57gN9ONEasILq40bDv8NuPeLKgebNJX+3QzvdMfmEC+8/RrF6Oy/qIbSX6gBXEi3wcaOa3E/Hm7YwWE/1Ob3qE1vv9tF9P+XTW9NlJMwbcWLCCeJEb/XYgUfid3rTQ6Zn0i8aTkF5ALDurLHHACiKQOys3DbOrpcHiZ3rTZU52mh92GwDepqywWEF0mUg9XXsYNW5605daeZ/edKmTkxTxJOshN9pus7dYQTRM9dsBTxBJmdG2zci/Z7RY5pVJVcIbNauXV/YaGB2BIX470ZjwVRBFJCAiyRABZYrfDniGSNq32rcd6lV60xCpu0OkNfXCVgPlGr8daEx4Logi8icRaeWGB9sAbBKRr3rtRzlu3MN+ftn3BZGmXqU3PahtDyXaRgPnar8daEz40UIcqKqngZuBf2Gy2fk5eNw4ussVcdObrkhvuimRZjZo76SNwFNPmJA1fbZtYXuEH4KYJiJpGEF8U1VL+WjoLy+5wUfb/iLS6v7OHbtsSGB606VOjv1nrhvNAJtewCP8EMRfAzuBFsA8EekFnPbBD3Jn5QomonajRUXafCqB6U2XOdmdElFvI8OOI3qE54Koqj9X1W6qeoMadmHSDvhBPyDDJ9tJQ6LSm6pS8oF2t3uY6854vx1oLPgxqfKoO6kiIvJ7EVkF5Hvth8tQn+wmHYlIb3qBJrscAkmdl6aekOu3A40FP7rM97uTKtcCbTATKjN88ANM8imLS7zTm+7VDkfjUY+FVlnTZ9u1nB7ghyCWr7y/AXhRVTfiXyDTPJ/sJi1uetMT8UhvutbpWxoHlywG20r0AD8EcaWI/BsjiO+4+U/8Cnlvu8yVUBwIXBaP9KZLNad5vHyy2B0rXuCHIH4Ok5R7lKqeB5pg8ih7Su6s3HZAd6/t1hfOBQKDrqtjetNlTnaXePrUyLEtRA/wY5bZAXYAl7mJ4wcBrb32A9tdrpHTKSlDP1bL9KaqnNmtnewXTvywLUQP8GOW+QFgHiZN6Hfcn0Gv/cB+40bFsVqmNz1Ds12J8qmRclnW9Nk2jFqC8aPL/CgwCtilqpOBYcBJH/yw3bkoOZCaOvrm7rGlN92pnU8k0qdGSCpgF7knGD8EsVhViwFEpKmqFgF+JNTp4IPNesuutLQr7uraeZFGuc1yldPf5reNPx39dqCh44cg7hWR1sDfgXdF5A3Aj+6VFcQYiSW96RJnYMMOuOsPtoWYYPyYVLlFVU+qahD4FvB7TKAHr7GCWAuiTW+60unfwwN3GhtWEBOMZ4IoIm0rHsB6YAH+7Ce2Ye1riZvedG5V9x2Vo0doYz/f+GO7zAkm1UNbKzHjT5G7UspfK9DHQ1/AthDrxNsZLSZlOE7Bk8dOTKx47yQZe7FfOInAthATjGeCqKq9vbJVE7mzcpsAyZC6oF7zWquWEzMcnff4iZOXpMvcql19CefWCLAtxATjxzrEW0QkM+J1axG52WM3bOswTjyf2XL8r1tfmt50hTPAZopLDG39dqCh48cs85Oqeqr8haqeBJ702Af7hxUvROSXrTPH/rFVyw/Tmy5xclr76FFDxsshrkaJH4JYmU2vf9E2Rl88EUn5YdvWH6Y3Xe30s0FhE4MVxATjxwe8QkSeAZ51X0/DTLh4iV/RdRoubnrTMidt7pniFpP8dqeBYgUxwfjxAT+CWX/4CmZ2+V2MKHpJ/d5FoappYUKp5ihNC1OWVvbhT/fQsiZlhJuUEU4zP51LjlLVtDK0iTlIK4O0cPlPlbQyJDXsHg6B1DCBFIdASpiUFIeUgJIScEgNKCkBJVWUNJSUdUM/ceSTNy/625r2vVpulCGdQ9K0m98fV4NBqXXkIUt0eC6IqnoOE/6rUkTkF6r6SILdqLSFmBrW0tQwoVQjLuYo+1Bswk3KtCztUpExQlOKY4RFnY+IzEWhkbSwkhomkGaEJpASJpDqEEhxSAk4rtAYsUl1RSZVlDRRUsWESUsDmojp8jd1j6RhxfAn5h2VFR2uWjchrXfW3+Xxvj/stY/uJ97n2p3LGJtxkjaDEEn32896i2A/uwSTjE3whKdc/PXPy0oyz3NElDQuikz5uY0oUgtW5X254HSr3hOdE28V9S3rqOv3jjix8kTXk3nD/nnuntTnJt7Dc5TQ9PxSHbv8P1xzYRv9eocl1e5miY2w3w40dJJREBNOm3MUY5fexI3VQ/6r4GTr/hPVKT4FpZedKz25eGpgxICXZH5gyeK7ugwaPKegdesDE5pKSfMJzB01gbkA7NZe29/juj3LubzVaTIHIdLE33eS9BT77UBDx49Z5mTAjsXEiXWDvzD3RNuciQDh0m0fAIFjJfvLmtGk/ciyPoWqgbQN66+e+MHmK1eocizy2Z7s6nM/v5n4f3xu2O/4TOgB/dWyvrplfkDD+315M8nPcb8daOgkYwvRi0W9VhDjwIaB9xccbT9kUvlrJ7T5HMDh4t0ZfVvlkRfufeXG1L0rLkho5OHDfUadPNnp4PARs9ekpZXkVayrGcUZk3l/9GTeB2C79tn6HtfvW8mozLO0HISIHcqwgphwkrGF+LNEG8gpKiymFmHxLRfZlP3ZuYc7jrhkH7NTtr8DwNHifR/OLN8YGtEZ5RxAKNSi85LFdww5crjXXNXqx8P6sL3fg/xq4q+5L++33H3hPv3Nkt66bYFo+GAi3k89wQpigvGshSgi/6Ca5S6qepP783mPXNoD9PPIVoOiqP8nCg52HjMp8ppq6CyEBgCcD5/urKqnRCSzlTbvPjDcvWBT6l5XPCVQVDRhUtvDe9cOHDS3o4jWGLm8OedbXc07Y67mHQC2av/N73HdwVWMbHOOjEGINJaF9lYQE4yXXeafuD9vBToDf3RffxI45KEf5ezCCmLMbOl7W8H+buM/EuHGKd2+GRhR/rrUKdndJCU9F2Bs2WXjt6Qc2Fgq4UHl948f7z50yeLbjw8fPntZ0/Tzo2PxoR9bBvRjywCAc7Q4NV8nbirgKmcPPS9TCTTkyTIriAnGy2g3BQAi8rSqjoy49Q8RWeGVHxHYJEgxsq33TfP3dJ88obJ74VDRJTmcz5QeP9kupSsAggRuCA1v8kaT5aXIxWVNZWXpbZctu210335LC7p0+WCsCDHPMrfgXOb1/HPs9fwTBd2sOUXvcd2htQxve57mgxBJxmGh2uJHw6FR4cekSgsR6aOq2wFEpDfQwgc/rCDGwI5eH1uwq+e14xCpdNLLKdt3ScCMoyX7tF161w9fd9BW/bOcDnN3phyZVPHZbVsvn3jkcFZh7pD3mgcCTq/a+igg2RRmZ1OYDXCalsfn6eSi+UzWfXTPVgm0q23dScKORBsQkSzgLVUdnGhb8UJEbgIGquqMasrcC4xU1f+qri4/BPErwFwR2Y6ZUe4FfMEHP6wgRsmuHlcv3JE15YqqxFC19AJakh157XDx7lYDMkddUm5y6eArXggUbAuL07diHadPd8pZsvjOM3nD/rmoefPTV8TD71acaTuVN6+Yyps4iFOogza+x3VH1pHXsZhmOVW9nyQlDOz224nqEJFUVY0pXW08UNU3gTfjUZcfW/feFpH+QPk/UJGq+jHjawUxCvZ0m7h4W5+bx1TX9XRKd24G8iKvHS3e95GINykEmlxTOuT822lrHOSjKxzC4bSWK1d8/IqevdYs6Nlz/XARmsfjPQAE0MAgNgwaxAYATpF5tEDzN89jkhygWw4ibeJlK0HsPjg5LyqxEZG7gScwk5jrMLEDnsNEMT8C3Kequ0WkEzCTi9HqHwb2R9TTB/gr8CBm/PJZzIaG88DnVbVIRJ7HLBgfBiwEHqvEn4lcXD2iwATMePNTwBnMWP5/gC+qqiMi/4dJVdwMeE1Vn3Tr2QnMAm7E7Ci7w/XhXtzWn4h0cN9T+d/fl1V1YTSfG/ggiCLSHPOh9VLVz4tIfxEZoKpveeyKFcQa2NflyqVb+t0xqqZZ3HCo6GTFayHnQltV57BI4JIoz92ddrmdNLPgkJz6yMRMObt35Y07drTntqF5bzspKeH+tX4D1ZDJqfY38Xr7m3gdh0B4g+ZueI/rjm1gSMcS0rOTsPW4OZpCIjII+CZwhaoedXMXzQJmqeosEbkf+DkmsdvPgQJVvUXM7zgDaOPWMwB4GbhXVdeKyPvAQ6q6RUQuB34F5Ltmu7v2qlpK9QQwTVUXikgGF3fcjAYGYv4X38ZMuL4GfENVj7s+vS8iQ1R1nfvMUVUdLiJfdOt9oIKtnwH/q6oLRKQn8A6QE81nB/50mf+ACfc11n29D3gV8FoQ9wJlJOfidN850Ony5Zsv++QwRGr8fJyyPa0ru17iXNibntLiI2Hvrw/ljXih6bx9KlplJJxz59r2XbL4zgu5Q96d16rV0UoncuJFACdlCGsHD2EtACdoc/g/evUHC5iYcojOA4mI8O4jUQkiRqReVdWjAK6wjMWIDcCLwI8iyt7tlgsDp8S0lDsAbwC3quomV8SuAF6N+J6IDCzyajViCKbl+IyIvAT8TVX3uvUsi5hL+DMwDiOId4rIg5j/zS4Y0SwXxL+5P1dGvKdIrgYGRvjZyvU/KvwQg76qepeIfBJAVc+LD9/GOUWFpYXZORuo0NWzwKEOI1YWZn92SDR7i1XLStDi7MrunQodPZPe7KPzZWmkZkwszSma22RTtaHBHCe12do1H5vQtWvR4j59lw8UwRNhasOJjrfyasdbeZUwgbJ1mrf2fa47uZHcLiFpepkXPlTCBg9tncKMV44DNmE2cJxU1bwqyp+rrjJVnSEis4EbgIUicl35rYpF3UnWJ4BRqnrC7ZJHRvkpH14LU7l+BYAxqnrJvu9oJcaPJQkhEWmG+2GISF/82zWyuOYijYsj7Yes3jjwvoGIRBVazCnbvRkqD0t1tHhvlV3tfk6Xka2d5ouisbF/f/bYFSs+frqsLG1jNOXjSQpO6jBWDX2CH0z8A5+67Gf6hQM366sLOuihpaieqbmGuLEsynJzgDtEpB2Y9L/AIuAT7v1PA/Pd8/cx44aISEpErqMQcAtwt4h8SlVPAztE5A63rIjI0GgdF5G+qrpeVX8ILOfi/MFoEektZnz6LkxK4lYYgT3ljnF+LFo7Lv/GxFwtt50Xy8O+5FTBjBf0cJvQ7wNf88EPgCU+2U1KjrUduG79oAcvw3xhRUU4VFTlYuHDxburnaiYEhoxgAoBH6qi+EKrHksW33nZieNdClT9C/DbnqNd7uDlcT/li5fP4q70r+gPV+fq6oI0DW1NoNlzQFRfBqq6EfgeUCAia4FnMAJxn4isAz4LPOoWfxSYLCLrMV3QgRH1nAOmAl9xl7V8GvicW+dG4OMx+P9lEdng2i8F/uVeXw78EijELCl6XVXXAquBIuBPmO52LHwJGCki60RkE/BQLA+Lqnd/W+43we0YERyDWXazpHy8w2sKs3P6Ax/4YTvZON56wIY1Qx/phUjLWJ4rPjlzJXp+RGX3UiXt7K29vtKiuiGRtSm7Fi5P2xpTDMwOHbevGDBgYZZIcuV+PkzHfe9z7fbFjGt6jPaDEInX+tp5ByfnVTkJVR8RkUnAE6o61WdXLsFTQQQQkRUVdqr4SmF2zlGgvi/YrRMnM/sWrsr7StdYJw9UnbKSkz8toZqF9XdkPbE3ICndq6vnT00XLD8vJaOqK1ORJk3OHxo2/K39TZqUDIvlOa8oJbVkJaM3zuGaM5vJ6VkmaXXJS/7jg5Pz/OpFJQQriOUGRWYARzE5VT4cjFVVX/ZpFmbnvAVM8cN2MnCqZdbmlcOf6IRI61ifDZfu2lh69q+DqitzY4+HlzdPbVWt2J2WC/v+0mRRJkLUs4EGdQZkL5jXocPO8SLJnUnxAF13v881O5dwZbMTtB0cy7AEcMfByXmvJcy5OCEi93GxO17OQlX1OmdSrfFDEHdQSdQbVe1TSfGEU5id8w3gf/yw7TdnMnpsXT7ia22o5Za20nPvzA2HNk6qrsz4TrcVdG3er8bu3uLUDwo2pu6pVbewTdu9awdFGTknGQiRVrycyzfO4dpzW7isV1jSatqu2PXg5LwDnjjXyPFDEJsBX8RM6Stmxmumql7w1BGXwuycfHCjkjYizrboumPZyK9nUIfoMMUnf7McPVtt6y87c/SioW0n17gVT1HnxabzNoakLLc2vqSmFp8YNnz2lvQYI+ckA3vpvut9rtu1lLEtTtF6cIUZ/vUHJ+cN8c25RoYfgvgX4DTwknvpU0Cmqt7pqSMuhdk5TTHbmWKaTKjPnGveadfSUd9sigQ617YOVSdccvKn5zDLJKqkbdMuH1zT9e6o1u4dlTPb/t5kWQ9qEfWmnL59l83r0nXzmNpEzkkGSmh6filjN84xibj6OJL68sHJeV/126/Ggh+CuElVB9Z0zUsKs3P+zMV1Wg2a88067F0y+lsBJKVrzaWrxindWxQ6+5dKF2RHEiCl5Pasx1Mkih0vAO+nrS/YkXK4TjOqrVodLswd8m6dIuckC8dpO/mO/OVz/fajseDHOsRVIjKm/IW7L9KPeIiR/NVn+55wIb3t/qWjvkVdxRAgXLo5qth8DuGmDuGoo7RMKh00NkUDdVrTd/p0x5wli+9se/5cZqxr2JKNk205vsBvJxoTfgjiCGCRiOx0o1csBkaJyHp34aYf/AvwZQzTK4qbtj64ZPSTpRqofglMtIRLd0SdNP182ZnD0ZZNIdDk2tKhxShO7TwzhMNpLVeuvOnKXTuHLFCtt0nF3r4qf5vn4bQaM34I4vVAb2Cie/R2r03FhPXxnJyiwnOY3TMNkpImrY4svjx4QQOpcelCqqrinI56T++JkoMxbc3s5rQd3MVpPb/mkjWze/fQcatXTT0YDqdsiUd9HvOG3w40NjwXRFXdVd3htT8RNMhucygt49jiy79zSgN1Whh8CRo+uBU3TFQ0HCneE9W+6EiuLR06UlT2xvpcZZw716bP4sV39jh9un1cRNYjThOnoKeW6GlI+SbqyluYTe0NhtLUFicWjXnqqJPSJK7JtMKhzTElkj9SvKdTrDbSSG0xqXRg3FKOqpOavnbNx8Zv3TpqsSqn4lVvAnnlqvxt9bWrX2+xguiSU1R4CnjPbz/iRWlKs1OLxjx10ElpOiDedTul22Ja0nK69FjPiuGYoqGv03lkG6dFXCdGDuzPHrti+cfP+BE5J0Z+77cDjREriJfyvN8OxIOylKZnFo397t5wanrUkYJjQZ1TMbU4FU0Ja2mthkNuCA3PQYlr8I/i4lbdFy+6c8Dx413n+hk5pxo2XpW/banfTjRGrCBeyutE5JSoj4QDTc4tGvM/O8KpzardY1xbnLLD2zERlWPiXNmpWolaM5q0vbysXwIiEgVSN264atLmonErVTkS//rrhG0d+oQVxAhyigrLgN/47UdtCQfSLiwa890tZWnNE7bVKxzaXKuJjmMlB2q9fCQ33OuKFtp0eW2fr44jR3qPXLb0NicUaro6EfXXghAmzL/FB6ISRBHpLCIvi8g2EVkpIv8UkQdFpNI8KCLyOxEZ6J6fjYejIpIlIl6EUf8NJohlvcKR1JLFY57aVNokIy+hdkq31SrtxJHi3XXKoDc1NKIbSkIiVIdCzTstXXLH0MOHswpUqS43iBe8eVX+Nl/ig1qiEEQ3uOfrwFxV7auqI4CvA1XOHKrqA6q6KX5uekdOUeEBTGiyeoMjKaHFY76zLtSkVaWBWuOJOidqFZXoSPG+Ou2OaanNuuaGeyawFSeBzUXjJ27ckL9RVfwcNvm5j7YbPdG0ECcDpao6s/yCG+Z7PpAhIq+JSJGIvFQeGVlE5orIh0FgReR7IrJWRJa4eRIQkedF5PaIMmfdnxki8r6IrHJ3r0SGKk8Rkd+KyEYR+bcbOecSeyLS3t0BU96qnO/WtUpEok2A/pMoy/mOI4HSJZc/ubqkaeuYAqzWylb42G7QWgWEOFd2spubm6PWjC7rN76JpiZ0N9OJE92GLFl8e7Pi4hZ+TGosuCp/W31aK9ngiEYQB2PyLVTGMODLmFwMfYDKQsG3wKQJGArMAz5fg71i4BZVHY4R46cjQtD3B55V1UHASeC2Guo6DFzj1nUXUX775hQVrqUeLMFRJLx09LdXFKe3u9wLe+HQ5jotnC91SqLe01wZgsiU0PAMNLFJycrK0tssX3br5fv2Zc/TBNuqwA88tGWphLpOqixT1b2q6gBrgKxKyoS4mHN5ZRVlIhHg++6+5veAblzsnu9Q1TUx1JUG/NZNovMqEUl0ouBHNRfxD0WcpaO+ufRCsw5jay4dH5zSrXVKF3um7MSJuvrQTlv26et08iRb4vZtoyasXXvdDscJ7PTA3Jqr8rf9s6ZCIhIWkTVu0qZXRaROY7OJRkSiyqyYLEQjiBsxARkqI/Lbs6o8qaV6McZYZJmycvtu8qnyxb6fxizrGOHmgT3ExTSXVdn7sC4uTYn5Fff5ocDICBs1klNU+C5JGjhWQZePnL7ofIvO0Q4BxMdu+FhWXZ4/VrwvLmv+JpYOvDJFA57sTT5zumP2ksV3tj+X+Mg5T0ZZ7oKq5qnqYExjI6ascrUl2vBtFVFVT/9G60o0gjgHaCoiD5ZfEJEhwPg62t7JRaG9CdOaA8gEDqtqqYhMBqIJSBBZ1+0R1zOBA24L9rMQc96Nx6FuUVfijYKuGP61BWczuo/z0q4TPrkPtE6Rcg4X7642mGy0BAikXR/KK61rRJxoCYfTMlatvOnKnTuHLlCtPil7LVl+Vf622uxbng/0E5G2IvJ3N/XmEvf/ExEJisgsdxx9l4jcKiI/csfm3xaRNLfcCBEpcFeQvCMiXdzrc0XkpyKyAnhURG4UkaUislpE3ouYDwiKyHNu+e0i8qVyB2uaG3DH+QsrmxvwgxoF0W3d3QJc7S672YgZ66jrPtPfAhPF5Hkdy8WEUy9h8qquB+7G5GetiZ8AD4vIargkNeWvgHtcG9kRNqLCHUt8IZZnEs2qYY/NP9OqV12/jGLGCW3eWdc6jpXsj0voMYAu2mZgV6eNpxMQe3YPGbd61dRD4XBKvBeKR9s6/BC3xfYxYD3wHWC1qg4B/h+X/s32BfIxjY4/Av9R1VxMuLsprij+ArjdXUHyHCavczlNVHWkqj6NSSQ/RlWHAS9zaT71bOA6YDTwZLnYRhDPuYGE4XnE7PpGYXZON0zuZt/HalYP/VLBiTYDfMnPW3L6j/M1fLjOQnxn1teOikhc8imXEj7/QtOCYyraIx71RYsEyoqH5L63rFXmkQlxqO6dq/K3XR+1bZEwRgTBtBAfB5YCt6nqdrfMHmAQ8BhmyOp77rDUBSBdVVVEngKOY8bpFwHb3TpTML2qa0VkLvCkqha49eYCTwNdMMNPO1T1ehEJlttxyxViJjP3ishZVc1wBfJ/gQmYXtcATOi/dOBdVe3vPvvfQJqq+pL4ze5UqYGcosJ9wDN++7E29+G5fokhgIaP9oxHPSXOhbiE9AJII6X55NJBUQefjRfqpKavXXv9hK1bRi+pY+ScEuC/YnymfAwxT1UfUdWaIjSVALjDRpHj+Q5mDF6AjRF15qrqtRHPR/aqfgH80m1hfoFLx+trmk+ozdyA51hBjI4fUvchglqzftADc4+1GzzJL/vqnDkI8clPcjp0tE5rESvSx+k0oq2T4UuqgAMHBoxZsfzmM2VlaetrLl0pP7wqf1ud0iW4zMcITnkC+KMxrPncDHQQkbHu82kiUtU++Exgn3t+T4w+1mZuwHOsIEZBTlHhWWoxzhMPNubcM/dIh2GT/LBdTjj0wfaaS0XH0ZJ9dVq6Uxk3hIYNxKcADcXFLbsvXnRnzvFj3QpijJyznfitOwwCI9ylajOIQazcFubtwA/dsfY1QFUzw0HgVRFZCTFHIKrN3IDn2DHEKCnMzgkABZh80p5QdNmnCvZ3vdK3bnI5Jaf/PE/DB+IxXkanZlkbJnW+a3A86opkQ8ruxUvStni2JrMy2nfYuTI7e35PkaiiAd1wVf62fyXcKUtM2BZilOQUFTqYb964BKuoiQ/63ZEUYgig4cPd4lXX8eL9cRmLrMjgcM+xLTR9WSLqjpajR7JGLFt6m4ZC6atqKPq6FcPkxApiDOQUFW7HzNwllK19bp63t/uk5BBD59xRCPeNV32lGmrlqJOQ4Ak3lozogRLXMcpYCYWad1y65Pa8Q4d6z1WlspBnpzHbXS1JiBXEGMkpKvwtF7cixp3tWTfM393jas/XGVZFOLQlHoP+l1AcPpcQQcwgvcuQcK81iag7NiTwweZxkzZuyN+kKvsq3Jx2Vf62Ou3ptiQOK4i14wFiH1SukZ09r124s9cNV3JxwarvhEs3xz24wanQkUTs9gBgVFnf8U01dW2i6o8FEznnjhYRkXP+dFX+tj/66pSlWqwg1oKcosJDmHVYcWN398mLtve+aQxmAW3SoGWHusS7ziPFexK2zsxExBnRCiXmpFaJoKysaWs3cs7rwBf99sdSPUn1z1efyCkq/Btx2ta3t+v4JVv73jYakVj3WicUdS6chLL+8a73SPGedvGuM5K2mtG7n9M5mZI0hbZvG/X9q/K31Yf0p40aK4h144uYdVu15kDnMcs+6H/XCGoZTSSRhEu3foDZyRBXjocOZrk7JxLGhNKcK1M1sDmRNmLgsWAwuMJvJyw1YwWxDuQUFZ4DbgQO1Ob5Qx1HrCgc8JmhfHQjfFLghDZfSEi9Gk53CCd0YiFAIPX60DAH/3OkvBIMBp/12QdLlFhBrCM5RYV7MZFEzsfy3OH2eas25tw3GJGmifGs7jhlBzomqu4LZWcPJarucjpr65xuTtsFibZTDYuB+3y0b4kRK4hxIKeocAVmO1JU236Othu8dsOgB7IRSa+5tD+olpyG0ssSVf+J0CFPJj2uKR0yOqBSp9QHteQD4MZgMJiQVrYlMVhBjBM5RYV/Bb5ZU7ljbXLWrxv8UF+SPPS7E9r+AbEH1I2aI8V7oo5eXhdSSWk2uXTwMS9sRXAIuD4YDHpt11JHrCDGkZyiwu9Tzczzicz+m9YOmdYLkQwP3aoV4VBRQrcoHinek7DueEV6Ox2Ht3NaehVM9ixwQzAY3OGRPUscsYIYfz5PJRn7TrbqXbQ679GuiMQljH6iccL74hLEtSpOhY70iiKWX9y4ITRsiCiJjp1YBtweDAZr2stsSVKsIMaZnKLCEGaS5cMEVadb9tyyatjjHRFp7ZtjMaAaOoeGBiTUBpoa1jLPxvaakpY5puyyuIUxqwQFHggGg+8k0IYlwVhBTAA5RYUXMMtx5pxp0W3biuFfbY1IW7/9ihandOdmLib9Shjnyk55Gu16ULjHmAwnPRELth2MGM5KQN0WD7GCmCDKRXHVsMfWIIFo4uMlDeFQkScRY46XHKgsGkxCmRoa0Yu6hf2vSBi4OxgMPhfHOi0+YQUxgeQUFZ4Pp6Z/GviH377EglO2t40Xdo4U7/F8pj2D9M554ax1caouBHwiGAy+FKf6LD5jBTHBTJuZXwLcSpKlM60K1bJitDjbC1tHivfGPXBENIwo6zOuqaatqWM1ZzCzya/FwSVLkmAF0QOmzcwvmzYz/x7g20S5eNsvnNJdRYAnu2fOlp3opqqeRCCPRBCZGhreug4RcQ4Dk4PB4Ps1lrTUK6wgesi0mfnfBT7FpWkXk4pwqPCkh+akTEN+7CKhjWZk9Q93WVKLR9cCY4PB4MrqColIaxFJ+nBfIhIUkSfc8+dF5Ha/ffITK4geM21m/stAPviTJa4mnLI9mV7aO1N64oSX9iIZX5Y9LlUDsWR/exEjhtEs32mNjX9Y77CC6APTZuYvAkYBtWmhJAzVcCl6wZPxw3KOlez3LRpNgEDqx0LDoPLcJ5GEgC8Gg8G7Y9ibPAPoKyJrROTH7rFBRNaLyF0AIvKCiNxc/oCIvCQiH6+sMhG5V0TeEJG5IrJFRJ6MuPeYW/cGEflyFNe/ISIfiMgCoNL1piIyQkQKRGSliLwjIr6M93qNFUSfmDYzfxcwAfgJSTKu6JTtKQKaeWnzSPHull7aq0gnbZ3d3WlXXUScvcCEYDD4fzFWPR3Ypqp5mC++PGAocDXwY1dgfg/cCyAimZh8yLOrqXM0cBswBLhDREaKyAhMRJ3LgTHA50VkWA3XP+H6cwPmi/kSxISj+wVwu6qOAJ4Dvhfj+6+XJF1Q0sbEtJn5pcBXn31ozlxgFpDQSNI1EQ4VeR6M4Gjxvu5e26zI1aW5l78QKNjliPaqcGsOZllNXYc3xgF/VtUwcEhECoBRqvqmiPxKRDpghO6vqlpda/VdVT0GICJ/c+tV4HVVPRdxfTwmsG9l1wPu9fPu9TcrsTMAGAy866b3SaGWMT/rG7aFmARMm5k/G9N6+I+ffjiluzwPOnEhfLajqh732m4kqaQ0u6o09wT6YUu9GPgacG0cxLAmXgA+g2nN1bS4u2JPIlE9CwE2qmqee+Sq6rUJspVUWEFMEqbNzN8HXIUJDuF57g1VJ4ye83T8sJyQU7zHD7uR9HI65LXXlgsw3dthwWDwx8FgsC7jm2eA8uGA+cBdIpLitgYnAMvce8/j5mlW1U011HmNiLQVkWbAzcBCt+6bRaS5iLQAbnGvVXV9nnu9mYi0xGwxrchmoIOIjAXThRaRQbF+APURK4hJxLSZ+TptZv7vgBzgdS9ta9m+zYAvYclOlx5LhuRLZ68NDf0LMC4YDMYy81wpbtd2oYhsAMYC6zBLduYAX1PVg265Q0Ah8Icoql0G/NWt66+qukJVV2FEdRmwFPidqq6u4forri//ApZX4nsIuB34oYisxeQNuqIWH0O9Q1STYjzfUgnPPjTnduBnQNdE2yo9925BOLR+YqLtVMbQNpPmZ7e+fLwftl3+Bjzafcb4vV4bFhMoeD0wXFWr/GIQkXuBkar6X1751hixLcQkZtrM/NeAy4D/ARIaij5cusPT2eVIDhfv9nTtYwSFwI3dZ4y/zScxvNr14RfViaHFO2wLsZ7w7ENzegBPYXK3xPWLTFWdkpP/ewbwRZiaBNJP3tLr0dYemtwCfAf4c/cZ4xOaDjVWROQ64IcVLu9Q1Vv88KexYQWxnvHsQ3MGY/6ZbyFOOZOdsv2bQ2deTmhA2Jq4I+urBwMS6JxgMzswXyovdp8x3u/0pJYkxApiPeXZh+ZkY5aGfIY6BnMtPT+nIFyyxpfxw3Ju6jFtZbPUjBEJqn43ZmHxH7rPGF+aIBuWBoAVxHrOsw/N6Q48jlmu06I2dZSc+t0SdU6PiatjMTKx810FnZtlxVuUCzE7Ln7ffcZ4z/K3WOovVhAbCM8+NCcT+DTwADAs2udUVUtO/u9xfN4lM6j1FQsGtxk/Lg5VhTBLlv6v+4zxBXGoz9KIsILYAHn2oTkjMML4KaDaLH9O2aGtoTMv9fPEsWrokN5jU36XTw2sQxVrMdsfX+o+Y7ynuVosDQcriHFGRLKAt4GVwHBgI2ZmeBNmHdlRERkJ/ERVJ7k7F/6EWWu4GLgGGKGqR+vqy7MPzWkGXI+ZgJkKfCQ1QOn5gnnhkpUT6mqrrqRI6vnbej3WTNzNs1GyBXgTeKH7jPHxSgtgacTY4A6JYQDwOVVdKCLPUX1cvCeBOar6AxG5HvhcvJyYNjP/Aqb7+PqzD81JBSZhxPFGoAeAU7ot4dn1oiGsZc0VZ7eQ0rOaYqcxOz3eAd7pPmO8TQZviStWEBPDHlVd6J7/EfhSNWXHYUQKVX1bRBISMHXazPwy4D33mPbsQ3P6A/nqnB+OaZ1WjPTiORfCZw+2SM2MFETFtLTfcY/F3WeM9zxTn6XxYAUxMVQWlaSMiwuq071156NMm5m/BdhignfD03dN7YrZrzoaszumH9AH7+Ijnj1yYc/mFi0z12P2zq4G1nafMb7OOVdE5BuY8dQwJofyF1Q1EfmZ64SIBIGzqvoTv31prFhBTAw9RWSsqi7G/CMuwEQ+GYHZUH9bRNmFwJ2YjfTXUsk4nxc8/spb+4HX3AOAp++aKpjWY1+MQJb/7IHZ1dISM2mTgYmZVxEHOAkcB064R+T5fkxklaLHX3krIVvn3IgtUzF7hUtEpD3QJBG2LPUfO6kSZyImVVZgBHAT8Fn3/PeYcbC5mAmWSSLSEfgz0AkzqTIVyFLVpE1EVRlP3zU1FfMFm+b+dIDTj7/ylq9/YCJyK3Cfqt5Y4fq3MWOpzYBFmFajishcTOt0PGZd593A14Fc4BVV/ab7/GPA/W51v1PVn4rIU8BxVf2pW+Z7wGFV/ZmIfBXzxdcUE6D1SbfMN4B7MJn89gArbQvRR1TVHnE8gCxgQwzlmwKp7vlYYI3f76EhHZjW6xrgA+BXwET3etuIMi8CN7rnc4EfuuePYlqxXdzf017Mes0RmAg1Ldz6N2LWfmYBq9xnA8A2t/y1wG8wWy0DwFuYmIjl9TTHtLS3Ak/4/Zk15sN2mf2nJ/AXEQlgFhV/3md/GhSqetbNIzIemAy8IiLTgTMi8jWMGLXFiNo/3MfKw+qvx0SOPgAgItsxwwXjqCQ8v6r+XESOicgwTIt/taoec4dCrsW0PMGIaH/MkMPrWn04f4uHWEGMM6q6E5OPItryW4hhZ4kldtTkMpkLzBWR9cAXMImaRqrqHncyI3Kiq3y4wuHSHNoONf/P/A6TOKozF1MCCPADVf11ZMHITHiW5MDGQ7Q0aERkgIj0j7iUh5nIATgqIhmY6NCxUFV4fjDrPq/HZLN7x732DnC/awsR6eaOHUcTzt/iIbaF2AgRkeeBt1T1tZrKNgAygF+ISGvM0qetwIOY2e8NwEEqCaNfHaq6yv0My/Oi/E5VV7v3QiLyH+Ck2zJFVf8tIjnAYncjzlngM2495eH8D8fqhyX+2FnmRkgjE0RPcceCVwF3uMMhlnqE7TI3AkTkbhFZJyJrReRF9/IEEVkkIttF5Ha3nIjIj0Vkg4isF5G73OvPishN7vnr7nZEROR+d2mJBRCRgZgW6PtWDOsntsvcwHHTR34TuEJNYIm2wDOYpSTjgGzMrOprwK2YMbahQHtguYjMw4yPjXfLdXOfxb32smdvJslRk0a0j99+WGqPbSE2fPKBV9WNnqMXk8L/XVUd95+4k3ttHPBnVQ2rSY9ZgJkcmA+Md1tAm4BDItIFs25ykYfvxWJJKLaF2HiJXE5SbcgtVd3nTkpcj5kZbYvZdXFWVc8kzEOLxWNsC7HhMwe4Q0TaAbhd5qqYD9wlIilunMYJXJxJXQJ8GSOI84EnuLjUxGJpENgWYgNHVTe6Ex8FIhLm4m6Jyngd0w1ei4nQ8zVVPejemw9cq6pbRWQXppVoBdHSoLDLbiwWi8XFdpktFovFxQqixWKxuFhBtFgsFhcriBaLxeJiBdFisVhcrCBaLBaLixVEi8VicbGCaLFYLC5WEC0Wi8XFCqLFYrG4WEG0WCwWFyuIFovF4mIF0WKxWFysIFosFouLFUSLxWJx+f9cePDsa+uNqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dog_preds['pred_class'].value_counts(sort=True)[0:10].plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breed prediction distribution by number of favorites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='favorite_counts'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAADnCAYAAABovFFdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABCTElEQVR4nO2deXzU1dX/32eyQgJhXwOEnQCBIIuA7Fg33PfWLtZu9vGx+rj0SX992qZPN54u1tpqbW1VbNVaa63W1NYqsu8Q9gQRCMq+GEIIWWfO74/7HRlClplkZr6TzH2/XvPK5Dv3e++ZyTefOd97zz1HVBWLxWKJNzxuG2CxWCxuYMXPYrHEJVb8LBZLXGLFz2KxxCVW/CwWS1xixc9iscQlVvwsFktcYsXPYrHEJVb8LBZLXGLFz2KxxCVW/CwWS1xixc9iscQlVvwsFktcYsXPYrHEJVb8LBZLXGLFz2KxxCVW/CwWS1xixc9iscQlVvwsFktcYsXPYrHEJVb8LBZLXGLFz2KxxCVW/CwWS1xixc9iscQlVvwsFktcYsXPYrHEJS0WPxE5E0LbfBF5qKVjNdDfnSLyq3D1F8R4c0RkehOvXysiedGyx2KxtJ5Etw3wIyKJqlrnVt/NtJkDnAFWNXLe68DrrTa0ZbZFj/yMBCATGAwMcX4Odo51AJKBFCDlmGbsn1L96+GA13n4gHLgKHDEeQQ+PwIcKlm44HQ035Ilfgmr+InINcD/YP4JTgJ3qOpR5+XxIrIa6AH8WFWfEpE5wPeAUmAUMEJE/gYMAFKBX6jqb52+Pw98AzgFbAGqneNZwNNOv8eBz6vqByLyLFAFTABWAg80YG8+MBTzj/yBiHwNeBIY6DS5HzgI3A14ReTTwL3AFwL7FpGtwCRV/U8R6dlAH6uBvUCuqp5yxt4NzMCIwnntVXVlfduATzbx0YeX/IwuwCxgNOeL3EAgKZgukqk7gxHFkMjKK/gA2OQ8CoFNJQsXHAq1H4ulOcLt+a0ApqqqisgXga8DDzqvjQOmAmlAoYgUOMcvAsaq6j7n97tU9SMR6QCsF5FXMGL6XWAiUAa8i/nHAPglsEhVF4nIXcBjwPXOa5nAdFX1NmHzaGCGqlaKyAvAz1V1hYgMBP6lqtki8iRwRlV/CiAiXwjsW0TuDOjvF4308RpwA/CMiFwM7FfVow2NCWTXt63JT7215Gd0BGYC84D5GFFv1XywoNLCUwc6j+v9B7LyCo7iCCGwFFhSsnBBTWvss1jCLX6ZwEsi0hcjWPsCXnvN+SeuFJF3gSkYL25dgPABfE1EbnCeDwCGA32AJap6HEBEXgJGOG2mATc6z/8A/Digr5ebET6A1wPE5VJgtMjH/7edRSS9kfMa67uxPl4Cvg08A9zu/N7cmK9HRPjyM5IxX0R+sZuC+XuFjZYqXyP0Bq5wHv8PKM/KK/g38AZQULJwwbHwDmeJB8Itfr8EHlHV151b2vyA17ReW//vFf4DzjmXAtNU9ayILMHc/raUiuabnNfGg/FcqwIbBAhTMH031sdqYJhzW3w98P0gxgzG/uDIz0gBbgI+g7ml7Ri2vhtA0EhGEnTCfOHdCGhWXsE6jBC+UbJwweYIjmtpR4T7As3AzJEBfK7ea9eJSKqIdMcsIKxv5PxSR/hGYbwTgLXAbBHpLiJJwC0B56zCeFIAdwDLW2H/W5g5PQBEJNd5Wo75h2txH6qqwKvAI0CRqp5sZszwkJ8xhvyMR4FDwPMY7ymiwhdlBLgYM3dcmJVXsDsrr+AbWXkFfVy2yxLjtMbz6ygiBwJ+fwTj6b0sIqXAYswkuZ+tmLm6HsD3VPWQiIzgfP4J3C0iRcAuYA2Aqh52FgBWY26VNweccy9mHu1hnAWPVrynrwGPOwsYicAyzGLH34G/iMh1BAhViH2AudVdD9wZZPuWYebwbgO+hJkWiDqtmPNrLcOAHwL/m5VX8A/MYtI/SxYuqH/nYYlzxDgklnZBfsZFGMH7FNDZTVMqNLVoTPXT2c23jAq7gV8Bz5QsXFDutjGW2MCKX3sgP+NqzGLKZLdN8VOhKUVjqp+JFfHzUw78GlhYsnBBqdvGWNwlLsTPiRG8r97hlap6jxv2hI38jPmYhZOpzTWNNmc1Zdfo6mdGum1HI5wCfgI8WrJwwVmXbbG4RFyIX7sjP+Ni4EfAXLdNaYyzmrxrdPWzsSp+fo5gvjx+W7JwQa3bxliiixW/tkR+Ribwf5jdHm4tKARFpSbvzq5+drjbdgTJXuA7wAslCxf43DbGEh1sVpe2QH5GB/IzvoNZAf8UMS58AHJBWGdMMwQTIL8pK69gktvGWKKD9fxinfyMBZhJ+gFumxIKVZq0Z1T1oqFu29ECvMBPge+ULFxQ7bYxlshhPb9YJT8jlfyMX2J2LrQp4YM24Jo2TgLw35iA6YvdNsYSOaznF4vkZ4wBXgRy3DalpVRr4r6R1c8Nbr5lTOPFBO9/u2ThgqrmGlvaFtbzizXyM+4BNtCGhQ/atOcXSALwMLA5K68g6jtlRORZEbm5geNzROSNaNvjjP3/mnn9HyLSJUrmtAorfrFCfkYP8jNex+xEaE0yhxghookNos1IYEVWXkHYspHHMiKS0MTLDYqfGDyqepU/Z2UkaMa2kGhPF2jbJT/jUsze52vcNiVctBPPLxAP8JOsvILnsvIKWvzlJCLfEpFdIrJCRF4UkYdEJFdE1ojIVhF5VUS6NnDeFSJSLCKbOJfCDRFJE5GnRWSdiBQ6+8/9pR7+KiL/FJHdIvLj+n3W6/+MiPxMRLYA00Tk006fm0XkNyKSICILgQ7OsedFJMt5L88B24EBIlIiIj2cPhvq424R+UnAuB+XpGiofUO2tfSzr48VPzfJz/CQn/F/mMwufd02J8y012vrM8CyrLyCfqGeKCKTMWnFxgNXAv6wmueA/1bVccA2TMxh4HmpwFOYL8eJmPyWfr4JLFbVKZig95+ISJrzWi4mwUUOcJuINLVwlgasVdXxmCzstwGXqGouZu7zDlXNAypVNVdV73DOGw48oapjVHV/gM3ZDfUBvIJJ6uvnNuBPTbQ/zzZVXdHEewiJ9nqBxj4moehLmGzX7dBRapfvyc9kYENWXkGo2wovwST1rVLVcky2oDSgi6ouddoswuRbDGQUsE9Vdzup0f4Y8NplQJ6IbAaWYKZM/CUR3lHVMidX5E5gUBO2eTHCBCbB7URMJvXNzu9DGjlvv6quaeB4g304CYn3ishUJ73dKEyZiabGDLQtbMRMAaO4Ij8jDZPb7xNumxIp2liQc0voCyzJyiu4u2ThgmddtEOAm1R113kHTamEwDhFL03/v1cFZCYXTGmIbwQxfmMJd5vq40/ArUAx8KpT9qKp9oG2hQ3r+UWb/IxuwDu0Y+FziIdrKwV4JiuvoMn5tABWAtc4SX3Tgasx4lEqIjOdNp/B1CkJpBjIEhF/0HhgMat/Afc64oGITGjB+6jPO8DNItLL6bObiPi9xlonoXBr+ngVuM55H38Kon1EiIcLNHbIz+iHSVYaD8Gz7fm2tz4PZ+UV/Dorr6DJ96yq6zElTrcCb2Lm98owWc9/4iS0zQX+t955VcCXgQJnwSOwZsn3MBX1torIDuf3VqGqOzFVGN9ybPo35+akf+uM9XxL+1DVUqAIGKSq64IYMyLYIOdokZ8xDPMHzXLZkqjgVc+RodV/jLdU8s8Bd5UsXNDoLZqIpKvqGRHpiPki/LKqboqahZaPsZ5fNMjPyMWU9cxy15Bo4loaezf5LPB8Vl5BU7Fov3Um9DcBr1jhcw/r+UWa/IwZmP25GW6bEk28KseHVj/f0207XOKPwOdiMT2WiKzFzFUG8hlV3eaGPW5ixS+S5GeMw0xyN1b7t93iUzk+JH7FD+Bp4Iu2cFLsYm97I0V+Rm9MHFfcCZ9DvF9bdwG/cNsIS+PE+wUaGfIzUoHXOBdsGo/E45xffe7Nyiv4qttGWBrGil+4yc8Q4FniI5ylCdpVYoPW8FhWXkHM1lqJZ+wFGn7yMXsU4xqxnp+fROAvWXkFbTGrdbvGil84yc/4FKZ+rsWKXyDdgNez8gpcLSRvOR8rfuEiP2MaZoXPYrDidz6jgRey8grs/1yMYP8Q4SA/YxDwNy6Mn4pnrPhdyAJgodtGWAxW/FpLfkYS8Fegl9umxBj22mqYh7PyCtpN0tq2jL1AW8+3gIvcNiIGsZ5f4/wmK6+gm9tGxDtW/FpDfsYkIJicZ/GIvbYapy/wS7eNiHfsBdpSTCDzc9iEsI1hPb+m+VRWXsH1bhsRz1jxayErOqQ+BGS7bUcMY6+t5nkyK6+gu9tGxCv2Am0BOYtyJny1T6/v3Nqvz/Iyj5S5bU+MYj2/5ukNPO62EfGKFb8QyVmU48Fks00sSkmeOWtgZtXLndLWum1XDGKvreC4LSuv4ILC5JbIYy/Q0LmHcyUH8Yn0/t8e3S++OrPv6hMJnuMu2hVTiFjPLwR+lZVXEK/Zf1zDil8I5CzK6Qd8v6HX9iclTZs3oH/C7zM6r4yyWTGMTWUXJL2BB9w2It6w4hca+UCj+zNVpNuj3bpcMn9Av/UHExMORc+s2ETQmMtkHMM8lJVXEM/JX6OOFb8gyVmUMwi4M5i2xxITJ1+R2a/TI127LNM4dn882DThIdAJU73MEiWs+AXPNzAlAoNDpNMzXTrPmjmw/5a9SYn7I2dW7GI9v5C5OyuvYLDbRsQLVvyCIGdRzgDg8y05tywhIfe6/n17fadHt6VeCHvV+VhG4tjrbSHJhKHuriU4rPgFxzcwF2bLEOnw107psy8ZlLlre3Ly7vCZFdt48FnxC51PZeUV5LptRDxgxa8ZchblZAJfCEdfFR7P6E/26531QK8eS2ugJhx9xjL2trdFCPBDt42IB6z4NU/rvL76iCT9O63j7OmDMj9Yl5qyI2z9xiB2waPFXJmVV5DjthHtHdfET0SGikiK83yOiHxNRLq4ZU9D5CzK6U+YvL76VHs8w77Qp1f2l/r0WlopcjYSY7iN9fxaxX1uG9DecdPzewXwisgwzHaxAcALLtrTEHlEMjuziGdNh9TZ0wdlHn+nY4fCiI3jEmI9v9ZwR1ZeQQ+3jWjPuCl+PlWtA24AfqmqD2PynMUEOYty0mjhCm+o1IkMur9Xj9xP9uu9vFzkdDTGjAbW82sVqcBX3DaiPeOm+NWKyCeBzwFvOMeCj6OLPNcDaVEbTUS2p6TMnDEos+Jv6WnrojZuBPHYSJfW8iVb8ChyuPnBfh6YBvxAVfeJyGDgDy7aU59PuzGoT6Tvt3p2n3Jt/76rPvJ4TrphQ7iwnl+rGQRc5rYR7RU3xe8Tqvo1VX0RQFX3AVUu2vMxOYtyegGfcNOGfclJ0+cM7K+LOnda5aYdrcGu9oaFL7ttQHvFTfH7XAPH7oy2EY3wSSDBbSNUpMdPu3ed/okB/dYdSUg44rY9oWI9v7BwTVZeQW+3jWiPRF38ROSTIvJ3YLCIvB7weBf4KNr2NIIrt7yNcSQxcconBvTr8FjXjOVu2xIKdrU3LCQC17ltRHvEjeI7q4DDQA/gZwHHy4GtLthzHjmLckYRkKw0ZhDJeKpLxsy/dEovfO7Q0e5ZdXUD3TapOTxYxy9MXIsJB7OEkah7fqq6X1WXqOo0VV0a8NjkhL64TUx5ffUpTUiYcE1m3x7f7951qY/YVhdPjNvXhpiflVfQ0W0j2htu7vC4UUR2i0iZiJwWkXJxOcYtZ1GOAJ9y04agEOn4UudOsy8ZlLmzKDlpj9vmNIZNbBA2UnF5Aa494uaCx4+Ba1U1Q1U7q2onVW00S3KUmAS0mXxqZzyesbf26zPg6z27L6mFWrftqY+d8wsr17ptQHvDTfE7qqpFLo7fELPdNiBkRJLfTE+bM31Q5r4NqSk73TYnEI9Y8QsjV9uA5/DixoKHnw0i8hLwN6Daf1BV/+qaRTDDxbFbRZXHM+LzfXp5L6msWvqLY8cvTlFS3bbJhrqElV7AxcBqtw1pL7j5TdIZOIuJYL/GeVztoj0Al7g8fusQSVjZscPsaYMGHFnWIXWL2+bY1d6wc43bBrQnXPP8VDUqSQOCxQlxaRdZNGpFsu7p3VPHV9cse/LIsQnpqp3csMN6fmFnptsGtCfcXO19RkServ9wyx7a8C1vg4jIltSUWTMGZZ4uSOu4wQ0TbGKDsDPBzvuFDzc/yDeAAufxDuY2+IyL9rQv8XPwivTP69Vj0o39+6w85fGURnNsj/X8wk0aMMptI9oLromfqr4S8HgeuBV3d1a0S/Hzszs5+ZJZA/vXPd85PWoT5jbOLyJMdNuA9kIsudDDMStaUSdnUU4fYKgbY0cTFem5sHu3aVdk9ltzLCHhWKTHs6UrI4IVvzDh5pxfeb2dHX8H/tslc9q111efg0mJUy8d0C/51106r4jkODbIOSJY8QsTzYqfiHhFZLOIbBeRl0Wk1XsMRWQJMDdwZ4eqjlDVV4I8/1kRubm1dgQQdxeUinR5omuXGXMH9N/4YWLigUiMYUNdIoJd9AgTwXyIlaqaq6pjMbVm7w7X4CJyrYj81HlcXe+1aIbhtPtb3sY4kZgw8arMvl0WdusS9kQJdsEjIqQBI902oj0Q6jfIcmCYiKQ5oSnrRKRQRK4DEJE7ReRvIvJvESkRkf8UkQecNmtEpFtAX78GngduByqB+0RkuYj8QURWAn8QkSwRWSwiW0XkHRG5II2TiHzP8QQTRORhEVnvtP9uCO9rSIifQ/tCJP35jM6zZwzM3L4rKWlvuLq1oS4RY6zbBrQHghY/xxO7EtgGfBNYrKpTgLnAT0TEX+xnLHAjMBn4AXBWVSdgtuV8NqDLIUAGJovKDcAVwAhgNHCpqn4S+CWwSFXHYYTysXo2/QToiakHMh+zaDIFyAUmisisIN9e3Hp+gZQneMbd3L9P///Xo9uSOmh1ejEb5Bwx+rttQHsgGPHrICKbgQ3AB8DvMVvS8pzjSzApd/xe2buqWq6qx4EyzEIGGNHMCuj3FNBFVZdhYvwGOMdfV9VK5/k0ztXy/QPnL0x8C8hQ1btVVR2bLgMKgU2YeKjhzb25nEU5XYEuzbWLG0RS/t4pfc70QZnvb05J3tWaruycX8SImRKvbZlg5tUqVTU38ICICHCTqu6qd/xiApIUYOaQqgOeB473AlDopK/vhhHRZUBFkLavx3h33VT1I0CAH6nqb4I838+gENvHBZUez6jP9O1dN7uycukjR09MTW5B8XY75xcxrPiFgZauGv0LuNcRQURkQgv66AlMBYqAE87zHfXarMLMCQLcgZlz9PNPYCFQICKdHJvuEpF0x6b+IhJM3KC9kBpDJHFpx46zp2UNOLiyQ+q2UE+3nl/E6Oe2Ae2Blq6ofg94FNgqIh5gH6FnZOmPEbAEzO6OKsytauA+1HuBZ0TkYeA4Zm7vY1T1ZUf4XgeuwniTqx1NPoNJSd9cMG+fEO2OO2pEhtzdu6dvYlX10ieOHp/UUTWoYu42zi9i2C/sMCDq0vUpIpsbuJ0udBZHokbOopxvAD+M5phtmQTVAwuPnzx6RcXZZmMjP1nzzR2rfWPGRMOuOKO0ZOGCbs03szSFm8GSDY3tRoot6/mFgFck8+FePSbe0q/PijKPlDXV1hYtjxhds/IKXE9W29ZxU/w2iMgjIjLUeTwCbHTBji4ujNnmKU5JnjFrYGbVnzulr2msjZ3ziyj21reVuCl+92J2jLwE/Akz53ePC3aIC2O2C3wivb/Xo9vUqzL7rjme4Dle/3Ub5xdRbCnLVuJmSqsKVc1T1UmqOllV/5+qfhzmIiK/jJYpURqn3fJhUtLU+QP6Jz6V0Xll4HG7wyOiJLltQFsnljdIt+16GnGGinR9rFuXS+YN6LfhYGLCIbC3vRHGzeJj7YJYFr9oYd2TMHI8MXHSFZn9Ov20W5dl4U6UYDkPK36txH6AlrDi8al3+k7dNXjLgNrUGYk7vJO2HShMntDlhKfXMCDZbfvaDXX2O7u1xLL4RWshwl5FYWDEAS2+bZnv6JgPNNujTFp18dfW9CrZOOBSb7/aq8f8yNux+/GUtTLjvcVcWlPCkGE+SbCrla0hSaxX3UpcFz8R6aiqZxt46RdRN8YSEt3L9PAtK3y7Ltmp/VPqGIVTXOfDzLmrK1O7TTl1aof3lqorP3ple/Veb+cPTswc93b63MS3xwC8r8Pfe5vLD29ictcK0sYgkuDqm2l7eN02oK3jmviJyHTgd0A6MFBExgNfUdX/AFDVZ6NkivX8QiC1Rs9cuV43X7XBl9b5LOOlXrxZTVL6yd1DbxyOVpwAep+oOrDrBply8QvlNbtXr7ptzNCh65f17bdr4jDZPWIYu0cAnCH91DKdu3Mp8/QgmaNUPN1deXNtiyq3DWjruLm9bS1wMyaF1QTn2HYnY3TUyFmU8zT19gxbzsfjU+/UYt1800pfVeYJJkgTMWZrJn9r1dm0PtN9tQd21pz58+heqYN2zO17+5hKak6+mLLijE90UGpq+YFx4/91JCWl8oJqfT7EV8SYon9z5YmtjO9VTeoonM3alvPod2Ru7mG3jWjLuHrbq6of1ruu3XDlK5tvEp8MO6jv3bbMdzhnv47yaPN1Tg71nb72bFqf6QA+X+kZgGNV+8f41PthB0kecH3NlNN/TV5bWlXVKXPd2pszMzO3r8oaXDhShI89PQ/qGcP2MWPYDkApXY+9q5e+t4LZCUfpMwaRzhF6u22Nj9w2oK3jpvh96Nz6qogkAfdh0ltFm4gU72mrdDutR29e4SueuUP7ptQxApNdu1lqEzuUFY/4ZJb/d/WWfnxbdqRy395+HYcN6Kbpgy+rHb/lraQtaQjJBw6MnX706LCTOePeWpmWVtZgXGdXSnvdyMu9buRl6kio3aIXbXmby0uLGDOgVpLjNQP32SNzc6ubb2ZpCjfF727MokZ/4CDwFvAfLtjxgQtjxhQpNVpxxUbdfNV6X2qXCnIFZofaR+H4+7chno8zbauv9OP5lB2lq/r26zgMgIG+HuMn1w1duT5pzyUAtbWp3TdtvPaSnj33bRgxcmUfj0czGxsjEW/SRNaPn8h6AI5onwPvcNneNVzS4SO6j0WkQ6h2t1Gs1xcG3BS/kap6R+ABEbkEWNlI+0ixP8rjxQSi6nPm8SoHHGe8tGJHzdFeEzec6ZR5Xu1j9Z3+ePX2o5rDI7y+uj0JnsShAOO9WZec8JQv2ZdwbI6/zfHjgyedPJlZMWbsu0szMo7OFGk+AL8PRzLv4LnMO3iOGpKq1unUDYu5rOJ9RgzxSuKA5s5vw1jxCwNuit8vgYuCOBZp4srzG3JYd9++1Hcwp0RHJmjrP+u6hJTynaM+d0HMnvoqzvPCDpx978NB6aM/vk2dX5sz5xVZs7LUU/Gx6Pp8SWnbtl42OyPjyI4xYxcnJyR4m63B4ieZ2tQZLJ80w0n2/YEO2vc2l3+wnqmdT9N5LGZqpb3QXIJewNTcxtTOScRMKX2ukbCymEBEVqnq9KiNF+3VXhGZBkwH7gd+HvBSZ+AGVR0fTXtyFuUkYOqMtNs4s67leuymlb6iWdu1T2pteGu+bpjw4PLTGUNm1j9eVfrYbqj7WLw6J3UvuTLzi1mBbbz4al5IWbGzWmpz658v4qsdMWLVqp699k0VCb1+SCCVdChfycyd73JpzX4Gj1Dx9G5NfzHAU0fm5n65uUYickZV/WUdngc2quojkTZORBJVtdXV/yKNG55fMia2LxHoFHD8NCb0Japs+9w2b86inIOcqz7XLkiu1bOXb9TCq9e1fB6vOY73GFd4uvPgGQ2/Wtcj8LfTtSezan01RUme5Gz/sQQ8ybdUT8t6IWX5Pp/o4MD2qp6kXbtmzP7wwzH7xo1/63RSUk2LvxQ7UNnpUt66+FLeQkF368hdb3PF4UIm9jhLx9GYUgxtiZbUVl4OjHNqZz+NKR17Fviyqm4VkXxgsHN8IPBfmLo6V2Lm5K9R1VoRmQg8gvkfPgHcqaqHRWQJsBlTYfFFEXkP+B/M//tJ4A5VPeqMMzBgnEdV9TE4J9ZOHZ7XgK6Y7DX/o6qviUgW8CawAuNAHQSuC6j2GBJuxvkNUtWYmG/LWZSznPPLYrZJRNU3+T3dcvMK39lBxxgn53+5hBWvJ/nsshk/OaGexAu+NFTrqqpPPXZBpuFJ3S9fOrRz7gUifEoqPvhL8po0AkJe6veYlVW4InPAjnEiZITDfj+n6fTRUuYVL2cuh+g/SsXTFtLD33pkbu7LzTUKEJNE4BVMzZzRwAlV/a6IzAMeUdVcR5QuxdThHo2ps32Tqr4pIq8Ci4ACYClGcI6LyG3A5ap6lyN+O/2bFESkK3BKVVVEvghkq+qDzjiXOeN0AnYBfRxhDbS3o6qeFpEewBpMGdpBwPvAJFXdLCJ/xsQJ/7ElH2LUPT8ReVRV7wd+JSIXKK+qXhttm2jj835ZR3TP7ct8B8bv1REJSlRqoGzJ+eoG9SQ2WBRefaeP0YAnvbNszfAhncarv+qfny6aNvCK2txt/0zanIbQQHp2kZKSi2YeOjTyyPjcfxWnplZcHKa3QWfKu13Da9Ov4TV8iG+7jtv+Npef3M743tWSOipc44SZYOsp+2tug/H8fg+sBW4CUNXFItJdzsVOvumI0DbMNNA/neP+mtsjgbHAv50/YQIQGGj9UsDzTOAlEemL8f72BbxWoKrVQLWIHAN6c37ImQA/FJFZmMxA/Z02APtU1f+eNnJ+LfCQcOO29w/Oz5+6MHZjxIQHGgpdzujxG1f6ds7Zpr1Sa8kGohbzdrJr9rZTXYY36imr79QpGhC/s3Vl/Wp8VVtTEjqMq/9apq97ztS64avXJO6eijSc1KKmJq3P+nU39unbd9eaocPWDxbRsM7deVDPOLaMHccWAE5q9yPvcunuFcxOPk6v0ZhKgW7jA3YH2bahmttNta8GUFWfiNTqudtCf81tAXao6rRGzg+suf1LjFf5uojMAfLrj+Pg5UIdugNT2naiI8Yl8PGXYv1zWxzeFHXxU9WNYjaxf7l+qIuLBPtN6irJtVr5iUItvHqtL6nbGSZEYh6vObyexKqtOV9Jb2qeTL1md0dD7Duz7dSojCkNvjbWO3DaSU/50t0JR5p8X4cPj5x6/HhW2dicd5anp5+cIY2IZWvpzsk+N/NSn5t5iToSagt1UuHbXH66mOwBdZI8JBJjBsG+I3NzW7MraTlGXL7niNIJ5/YymHN3AT1FZJqqrnY2J4xQ1fr1tgEyMHNyAJ8L0cYM4JgjfHMxt7thx5VQF1X1isggEUlW1Ro3bKhHtGMLg0dVJ+3WLTev8JUPPsp4MRO9rrF9zJfWqiepSXFSb2ltY68Vn1o7emTnyXXOvM4FzK4dM7tUKpaf8JRfsIIcSF1dSsbmwqtmduv+4ebs7GVdPB5fVlBvoIUk4k2azNoJk1kLwGHt98HbXFaylks6ltJ1LCLRqqa2rpXn5wNPi8hWzIJH0MKkqjUicjPwmIhkYPTjUaAh8csHXhaRUmAxZjElWJ4H/u7cfm8AikM4N2jcXPB4DsjGFBz/2F2OxlJ8Q+QsyjlMDJWxHHhM996+1PfhhD06LEHp77Y9AKUZw3YW5t4/srn0UzXlf1nqq/ugUYG8dsA9Gzskpje6V9iHr+6FlBVbq6Q2qDhE8dRVZWcvW9Ot28EZItH/Qq8muXIt07cv5hOVexg+xCcJje5SCQP3H5mba9O9hQE3g5z3OA8PEVyVDIHlwC1uGpBRoSduWOXbOXer9uhQw2hMOEBM4BNP7ZZx9yQFk3dPfeVNBhS/X15YmdO1ccfOgyfxluppQ19IWfG+V3zDmh8vMXXnjnlzOnU6vmtsztvexMS60c2dE05SqOkwiyWTZ7EEgBIdvOffXHFgA1MyztBpLI14uS1kbRj7imtc8/w+NsDE9KCqjc4TRYOcRTn3Ao9Fe9ykOq26tFALr1nrS+hezkUSAwlmG2L76C8sPdbroqDmGKtOPbEFrWo0Li/Jk1J2w8D7UkWkyeDl03L2wMvJq5NV6BW8pT7vsGHrV/Tp+95kEffLO1bQsWwls3e+y3zvhwwaoeIJ4b1cQA3Q2SY1CA9u3vaOxaz8+uOqTgCfbWTyNOLkLMqZAGyKymCqetH7uvWWFb7yIUfIEcIbuxZuTncauHvDRV/PCnaLWFXpox+Ar8mg8aszv7I2LalLsyErh6V0Z0HypixCFLLUDqc/HD/+X8eSk6uaTcUVLRR0F9nF/+aKY1u4qEclHbJDDLBef2RubsOrRZaQcdPL+C3wgKq+C+CsPD2FexP6WzC7TCKWLy7zuO67fanvg4v26NBEH1HdxtdSFPEWjr+vLrS9sb6ezbV47/RG34Tu85vtqa92HT2jbtTaFYnFkwki2YGfqsrOA9auuWXAgAHbVg7K2pwtguvBywIyiqLsURRlA5SRcWKpztu1jLlymH6jEenSTBerIm9l/OCm57el/j7eho5Fk5xFOW8CV4Szz05n9aMbVvm2z9ui3TvWMCacfUeDnaM+s+RIn6lzgm2vvsqy6rJfN+vJJkji2ZsGPaAikhZMvysSi5cWJx5sUWhPUlLliXHj33qvY8fTrq6UN4UPj3cr43e+zeUndzCuX42kNJRHccGRubn/iLpx7RQ3Pb+9IvItzgU9f5qW7VkMJ8sJg/gl1mn1/M266dq1voQep5kg0OBOiFjnTFq/vUd6X9xYQGuDqO/0CYK4jfdqXcfy2pOrOif3CEqQZtSNmv2R58yyY56ykD/L2toOPTZuuK5Hr157148YuaqfiMbE6nkgHnwJuRTm5FIIwHHteXgxn3h/FTNTTtBztON5L3HVyHaGm55fV+C7nNtTuwz4rqqWumIQkLMoZ6ZjR4vI3ePbeutyX9nQw4yL9Xm85lDEt3zGj3fUJXbMCeU8b82ujbUVBUHNsw1Oz1k3pedVQc9h+VDvn1JWbjor1ZNDsSmQhITaM2PGLN7UOePYjGByBsYCdSTWFDLxhbx5L9haM2HETc9vsKp+zcXxG2INUIrJJhEU/U/o/tuW+fZN2q1DEn1csG2rrfLe8FuX1yV2DPk2MzB9fXPsP7Mjd3KPK09J83NdAHiQhFuqp2Y/n7J8V534WpSay+tNSt+69fJZXboc3j56zLupCQneZkNp3CaRuuTJrI3OYlwc4eY3389EpEhEvues/LrOts9tqwVeba5d+lkt/fQ73mXPPFK3/edPeQdN3aVzEn3tJyVWRYfe+w/2m9ki78rna3x3xwVt8SWX1hzdFkr/SSSm31w9rbMorapcdupU37GrV90+6PixQUtVaQuhI6+7bUB7wzXxU9W5mLQ2x4HfiMg2Efkft+wJ4KWGDiZ6teYTm3xrf/VE3drf/8Kbdu06nZVWTUyIdjhR0E0THihFpEUxcuotC+maKjq1Jj3UMdJJ7Xt1zaTTKK2KDVX1JBUXz5pduGnBgdra5K2t6SvCFM6ft6fNJd+IddwuXXkEs0/wXeDrwLeB77tpE/AORpB7Aozb69t+63LfR8MPkSMQtlRKscqeIdevqE1Ob3JfbZPomZCyLh88+944Vd9xEU+z4TGB9NaMkbNqR69flrTzIqR1WbgrKroNXbP6Vh08eNOy/pk7c0UiF+7UQp5z24D2iGviJyLZwG2Y3GInMR7Xg27Z42fb57Z5r/m/sU9fv9p38ZT3dHCir/15d41Rmdr94AcDLs1tTR/qqwppq6KiCSeqDxb1TB0QkvgBjPD1nfyRt3zZ9sQPw7CaLrJv38RZhw6NPDxu/FvFqakVsRJMXAe84LYR7RE35/yexiwuXK6qc1T116oaVGGWSPPjZ7x/m16scxJ9kUmlE6tsnPDg4dbnrKsNerHIz45Tq0I+x8/UuhGz+nq7Lm3p+fWprk7vu37djVP2vD95jSrHw9VvK3hz/rw9MfF/0d5wc85vmqr+QlUPuWVDY2QXF60hQml0YpV9g65cUZOSMak1faiqDzTkvatHK0vG+tTb4uLxV9VOmJmuqWHd8H/o0Kipa1bfmnSmvNuKcPbbAha5PH67xTXxE5HhIvIXEdkpInv9D7fsaYBn3DYgWlQldzm6L2tBSPF8DaJnjtOyKnhytLLk/ZYOK4jnpuqpOUmasLOlfTREXV1Kl8LCBTN27phd6PN53FhwKAX+7sK4cYGbt73PAL/GzGnMxUzqtqgQSYR4Bgg6Zq0ts/GiB/djklO2CvWWtbiY9o5Tqy6o/RsKSSR0vLl6Wg9ROdh869A4eXLghNWrbuv10Uf9lqoSzZKMz82ftycWkv22S9wUvw6q+g5ml8l+Vc0HFrhoz3lkFxcdJw5uOfYPmL+qOrVbWCb3fb7S8paee7L60Eiv1u1rvmXjpJHS69qaSWdRTremn4bw+RI77Ng+f/aWLZe/7/UmFoW7/4aGxIUUa/GEm+JXLSadz24R+U8RuQFTCzSW+BnmImyXVCd1Or5nyA1hq1AWyu6Ohjh09v1WV9HrqZ2Hz6sdu5sIeWjlp3uNWrXythFHDg9bqkpramk0x2vz5+2JpWmgdkfUxU9E/IkM/gZ0BL4GTAQ+Q+iFTiJKdnHRboyd7ZJNEx54H1PEOiyo71SrNorvKF0Zll0yQ3y9J+Z6s1aHo6+G8STs3j1t9sYN1x6rqUmN1LaziFc3FJEsEdke6XHCiYhcKyJ5zbS5U0R+1Vxfbnh+E0WkH6aCVBKmiMqDwBeB91ywpzl+4rYBkeBAv5lrKjv2CiljS3Oo73Srrqey2hOD63w1YVlln1Q3dOYAb/cl4eirMSorMwatXXPLRftLxq1QJZwJOVbMn7cnpnP3NVaAKtKo6uuqujAcfbkhfk9idlGMwhQd3oip0OT/GVM4YS9uhzuEldrEtNL3ht8a9vog6qtoddr4DyqKjobDFoDLasfP7uzrEEEP0PDBB+NnrF17U93Zs53DJVhB/3OLyGdFZKuIbBGRPzje3GLn2DsiMtBp11tEXnXabRGR6fX6GSIihSIyWUSGisg/RWSjiCwXkVFOm2dF5EkRWQv8uBF7ZovIZudRKCKdRGSOiCwTkQIR2eX04XHa/1pENojIDhH5bkA/JSLyXRHZ5Gx99dvwsVcnIj1F5BURWe88LgnlQ466+KnqY6qaDTytqkNUdXDgz2jbEyQ/dNuAcLIp976dtK6WRMNodau3he08tXqYhinPmiByY83FE5I0IeK3drU1HXtu3HDd9Pd2TVunKq1JurB6/rw9BcE0FJExwP8A85wkwPdhioUvUtVxmBKQ/kWTx4ClTruLCCg3KSIjgVeAO1V1PSbL+r2qOhF4CHgiYNhMYLqqPtCIWQ8B9zjF0mfCx/OiU4B7gdHAUOBG5/g3VXUSMA6YLSKBmZFOqOpFmKiQhxoY6xfAz1V1Mman2O8asalB3Axy/qpbY4dKdnHRm5jao22ew72nrK9I7x/SN2Tw1PVobQ8VdWX9a33VYROrRBJSb62e3sej0urFlGA4enTYlNWrbksvK+u5TJWWiPjXQ2g7D3hZVU8AqOpHwDTObYf7A+fyZc7DiAiq6lXVMud4T+A14A5V3eIUFJuOqbm7GfgNEBiG9LKqepuwaSXwiIh8Deiiqv6Fp3Wqutc598UAu24VkU1AITAGI45+/ur83AhkNTDWpcCvHDtfBzr7C6IFQ5tI5hgjPEgbX/mtS0g9XTTq0xGpKataV0UIeRCbYt+ZbS2OF2yIDiT3uK5mch3KqXD22xheb1KnrVuumLV9+/ztPp9nTwinvjZ/3p5oT7GUAR9wTow8wClVzQ14ZAe0r7ighwCc+bgvAh2Alf7bVbjgi0BFZDDGo5vveKoFQGDxd3+qMS8N5yHwAFMD7OwfShVIK35Bkl1ctJk2nl2jcPy9W5CEVgUTN4b6TodtH2xx2drRzXgXIdNdOw35RO24EpSoBQ2fKu2Xs2rl7QOOHx+0VJsf1wt8I8QhFgO3iEh3ADEr96uA253X78CUZgAzz/5Vp12CnAtqrwFuAD4rIp9S1dPAPhG5xWkrIhJ0XR0RGaqq21T1/4D1mLl9gCkiMtiZ67sNM4/eGSOmZSLSG7gyxPf/FuZW2j92bignW/ELjW9iVqfbHMd65G4q75zV8lRVzaC+srCtdlZ5K3pW+85uCVd/fgb5euZOqhuyLtz9NoVqQnJx0azZhZsWfFhXl9RU4tan58/bE1LwtFPm9QfAUhHZAjyCEYPPi8hWTPjYfU7z+4C5IrINcxs5OqCfCuBq4L9E5FqMaH7B6XMHcF0IZt0vItud8WuBN53j64FfAUXAPuBVVd2Cud0txtyqrwzl/WPC5CY5izs7gbtDOdn1ouVtjaJR2d/F5B1sM3g9yRXLZvy0VD0JEbnlBair2rS6rnJJ2EJnxnaZsWJM10tmNN8ydN5O2rq0JOF4iyrBtQ71DRmycUW//kUTRAjMnnMaGDV/3p5WZaeOVcSUpX1IVa922ZTzsJ5f6PwYaHEGEjfYPO6ejZEUPgD1lYb1dnLX6fU5qhqRW9RLa8fN7uJLC9XLCAPi2bt30qz1624or67uuD7ghW+2V+GLZaz4hUh2cVEF8CW37QiWk91Gby3LGBqx210/6j0V1v5qfdUZZ72nN4e10wBuqJkyOUUTw35rHQzV1en91q29afLePRNXe70J/+b8UJI2gYh8PiCez/94vKG2qrok1rw+sOLXIrKLi/4J/N5tO5rD60mq3Dr2K50RkUiPpb7ypHD3ubtsY8QyqCTgSb6letpAj0qrkim0hoMHR09atfJTD82ft6fNRRGo6jP1VoRzVfUet+0KBSt+LecB4EO3jWiKbWO/vE49iVnRGEv1bKt3d9Tn/fLN41U1YgtMqSR3vbHmYg/KyUiN0Qw/ys/Pj+XCSe0aK34tJLu46DQmnikmKe0yfMdHXbMjsmDQIFoTlhi/QLxam1ZeV7o53P0G0kXTBl1em3uQ6Jev3Ir7xbriGit+rSC7uOgt4Cm37aiPTxJqtuT8RwoirapqFuKoIRcgCoZdZesivoF+gK/7uIvrhm+kZTsyWsIZ4Nb8/Pygaxxbwo8Vv9bzINDiFOyRYPvou1b7EpKHRWs89VWdxqQnCzsl5dvHB2zFihg53oHTh/r6LIv0OA535+fn74rSWJZGsOLXSrKLi8oxm6ojmdgyaMo6D951osf4CO3dbZhw7u6ojw9vyqmaY00FB4eNubVjZnf3pUd6e9nv8/Pzn4/wGJYgsOIXBrKLi7YC/+G2HT7x1BWOv1eJcq419ZVG1DMrKlvTIZL9B3JdzeSLUzUpUglKtxOwHcviLlb8wkR2cdGzOFkz3KJo1GdW+BJSwpaWPljUWxrRLX8HKnbl+jOXRBoPnqRbqqcNTdCQEhIEwxnglvz8/Ji4Q7BEQfxEpI+I/ElE9jjJEf8hIl8WkTcaaf87ERntPA86Q0MzNkQrXfd9QNgKaIdCeXrmnqO9Jk9vvmX48flKw5qEoD6KJpysPhjWspRNkUJSxo01F6cQvqLlPuD2/Pz8uKoFHetEVPzEBNe+CixR1aFOcsRvAL0bO0dVv6iqUbvQw0l2cVEtcAtQEs1xFfFuyr2/CpHkaI778fjesogHUe88tbpLpMcIJEM7Zl5VO+EY4SlS9GB+fn5QCUot0SPSnt9coFZVn/QfcDI5LAfSxRQtLxaR5x2hRESWiMgkf3sR+YGTdnuNk/bGn0775oA2Z5yf6WJSd/tTXwdmo0gQkaecdNlviUiH+uOJSA8RKXGeZ4lJ4b3JeQTlVTklLy8DjrXg82oRu0bcvsKb2GFMtMa7AD2TEukhDlfuzfGp71Ckxwmkn6/bmOl1I7e0MgTmV/n5+Y+GyyZL+Ii0+I3FpM9piAnA/ZjUOkOAhlYo04A1TurtZTS/p7YKuMFJfT0X+JlfVIHhwOOqOgY4hVmhbYpjwCecvm4jhBqqTtW3yzGJIiNKRcc+JYf6XhKWurstRX1V0Sg5Kkcr9++OwjjnMdqbOXWkt19LQ2D+yrmUUpYYw80Fj3WqekBVfcBmGk5TXQP45wYbS2UdiAA/dHKJvQ3059wt9j5V3RxCX0nAU07+s5c5P712szjJT68mgiEwCrpxwgNlOF6se9SGrfxlU+w8tarR6ZJIMrMue3YvX+dQBXAJcEd+fn6b27cbL0Ra/HZgavI2ROB2osbSVNcGFLMJbFOHY7uTGdY/13UHpibBRKeAylHOpcVubLyP++L8FNr/5Zw/HpgUMEbQZBcXrcB4mBGJ5H9/6E3L65LSgs6yGwnMl5dGZHdHfU5UHxjlVW9JNMaqz9U1ky7pqMnBVhd8F1iQn5/fqiLulsgSafFbDKSIyJf9B5zqTK1NsVTCOVG9FuOlAWQAx1S1VkTmAoNC7OvmgOMZwGHHM/0M0KKtYk7xo08T5vofZzv0OPBh5tyLwtlni9CKEzT8xRURDp19f3+0xgrEgyTcXD1tZIJ6mqstvRi4Oj8/P6jwH2du2T/vXeTMg3d0Sjf2cNpMEpElzvOeIvJvZ+76dyKy39/OEhoRFT/Ha7sBuNQJddkB/Ag40squn8KUuduCqVblL6ryPCat9Tbgs5j02M3xU+CrIlIIBF5ETwCfc8YYRTOFW5oiu7joz8CtEL7N8xsnPHiMECpVRQr1ngprsaHm2HlqVUSTsjZFMomdbq6e2km00es3JOELYCTwhFMo6DRNB8x/B1jszF3/BRgY4lgWB5vGPooUjcqeB/wNzkthHjJ7s65eUZJ1ZfQytjRBXfX2dXVn34rqgstNgx54L9GTNCKaYwZyRE4VvZG8cSBCWsDhd4BrQg1iFpEsYJmq+ouLz8PUpsgFJqnqCSca4aeqOscp03iDqu5z2n8EjIhWEHh7wu7wiCLZxUWLgTm0IgymKqXr4ZJBV+SEzahWot6Pop0Kig8riqMa8lKfPtole1Zd9g7046mMP2Pm+Fq6uHVBWUcan4u2hAkrflEmu7hoE6ZGaklLzt844cEDnCs76DrqOxXR3R0NsfPUqqhlrGmMEd5+U8Z4ByzHVEy7PT8/vzVfAgNFxF/86VOYso4lnJuLDgzLWomZQkFELiNMtZLjEXvb6xJFo7L7YcJ4JgR7TsnAy1buHXJdVDO2NEf16T+uUO+xqN+C3zDovu3JntSx0R43gDrg3syFM59stmUTOLe9/wQ2YMRuJ2aBbSKmVMJpTNjMJOe2txfwIiaEazUmnCpLVaPugbd1opr9w3KO7OKiQ0WjsqdjFlY+31z76uTOx/cOvjakWMNooL4KV27J9pfv+Gh4RmNRVBGnFLglc+HMd8LUX52qfrreseVAQ/OaZcDlqlrneIuTrfC1DHvb6yLZxUVV2cVFdwFfppmV4I0THtyDSOzd4mi1K7fgRWVrRjphSNFmB3BxGIUvVAYC650ohMdoQ5UEYw0rfjFAdnHRU5h5wAZj2D7sP3tNVYceU6NrVbDUdXdj1Ervmd7VvspoF//5FTApc+HMsG2zU9USVQ369l1Vd6vqBFUdr6qTVXV982dZGsKKX4yQXVzkn/P5Z+DxmqS0j3YPu3moO1Y1jWpdNRCVrW0Nsbd8c3mUhjoKXJW5cOa9mQtn2l0b7QQrfjFEdnHRSeAq4B6coOpNuf9VjHiisn0sVNRXHrH09cGwq2z9WFWNdBGgN4CczIUz34zwOJYoY8UvxsguLtLs4qIngPGH+k5/7mxaX1cSlAaD+qK7u6M+Nb6qrpXe8s0R6v4s8NXMhTOvyVw401WRt0QGK34xSnZx0Z7ikXfcCXwFk4Ir5lBvaYu3/IWL3ac3RcLzWwpMbG0YiyW2sXF+bYDH717cB3gUk1cwZqg9+85Sb/WW2W7akChJZ24c9F8JEp60XoeAhzIXznwxDH1ZYhzr+bUB7nly3pF7npx3O2Y+cIfb9vhR7ym3TaBOa9PP1J3a0spuqoEfA6Os8MUPVvzaEPc8Oe9NIAfjAUajIFOTqK88JoLkd5Wta+mpitktMTJz4cz/zlw4M1qrx5YYwN72tlEev3uxYPZ8fhsjiFGn6tQTW9AqV5OpAngkoermQQ/WiEjnIE9R4B/AdzMXzrRxcnGKFb82jiOCN2JEcFw0x64qfbQEfFnRHLMxLu//+ZVdkns1t++5Bvgj8LPMhTPbZIVAS/iw4tdOcETwBowIRsUbqyp9pALOy2nnGgPTRm+Y1uuaSY28fApTUP6XmQtnHm7NOCLyLPCGqv6lNf1Y3MeKXzvDEcHLMMkSrgciUlZSfVVl1WVPxExqLUHqbsl6uExEArfblWBWyX+fuXDmmbCMY8Wv3WDFrx3z+N2LuwKfxAhhY15Ri/DVHdtTU/7HmNp2N7/vp5f1SO2fi0nv/gdgaebCma26wEXks8BDmHnCrZjiV6cxn2cf4Ouq+henROqPgSudtt9X1ZdE5HHgX6r6uoi8CpSq6l0ichcwVFW/2Rr7LC3Hil+c8Pjdi0cBtziPVi+QeGveK6yteCPoXIQRpgL4R6/UQc/P7Xv7W5kLZ4alXKiIjAFeBaY76eS7YZKXpmFW3EcBr6vqMBG5CbgbuAJTC2Y9cDEwG1NN8GERWQf4VHWqiDwD/ElV/xUOWy2hExOhCpbIc8+T84qB7wHfCxDCKzDJFEK+NY6B3R2HMXUzXgH+9eBLb0SiPvI84GV/fQxV/cg4ePzNSae1U0T8tYRnAC+qqhc4KiJLgcmYvHz3i8hoTKLSriLSF1N462sRsNkSJFb84pB6QpiMEcDpAY8+zfXh85VGM329F9gGrPI/HnzpjX1RHL8+gbkXpamGqnpQRLpgvmiWYbLg3AqcUVUbV+giVvzinHuenFeDSYe+GvgZwON3Lx7M+WI4lnrXivrKImnWUWAz58Ru7YMvveGGUCwGXhWRR1T1pHPb2xjLga+IyCKMwM0CHnZeWwPcj/Eku2PmJO2CictY8QsSEfkmpriMF1OA/CuqutZdqy5ERPIxXsVPW9rHPU/O2wfsw9RB5vG7FycAmZgi8FlAFupLwaRU7xXwSMN8NtrEz1pM9brDAY+DwF7/48GX3nD7lhoAVd0hIj8AloqIFyhsovmrmFvZLZj3+XVV9df3XQ5cpqrvi8h+jDguj6DpliCwCx5B4NRKeASYo6rVItIDSFZVV0soNkQ4xM9iiQfs3t7g6Auc8BeKUdUTqnpIRL4tIutFZLuI/NYJd0BElojIz0Vkg4gUichkEfmriOwWke/7OxWRB5xzt4vI/c6x//U/d37/gYjc5zx/2Blvq4h8N6DNN0XkPRFZAYyMxgdisbR1rPgFx1vAAEdgnhARfxqnXzl1FMYCHTBlBP3UqOok4EngNUx25rHAnSLSXUQmYuLvLgamAl8SkQnA08BnAUTEA9wO/NGp0TocmALkAhNFZJbTz+3OsaswK4wWi6UZ7JxfEKjqGUdkZgJzgZdEJA8oF5GvAx0x8zg7gL87p73u/NwG7FDVwwAishcYgAmNeFVVK5zjfwVmqupjInLSEcLeQKEz2X4ZZueGf94pHSOGnZx+zjr9+Me1WCxNYD2/IFFVr6ouUdXvAP8J3IGpuXuzquYATwGBNWz94RA+zg+N8NH8l87vgDsxnuHTzjEBfqSquc5jmKr+vjXvKdYQEa+IbA54ZEVonDki8kYI7Uuced5g22eJyPbmxgq1X0t4seIXBCIyUkSGBxzKBXY5z0+ISDpwc4jdLgeuF5GOIpKGSUrgXwF8FRMXNhnw7wD4F3CXMxYi0l9EemFix64XkQ4i0gm4JkQ7YonKAHHPVdUS/wtisNerJWzY297gSAd+6QSr1gHvYwqNn8IkFT2C2c4UNKq6ydkk78/E+TtVLXReqxGRd4FTzo4BVPUtEckGVjvrKmeATzv9vIQJsTgWqh2xjOP5/QtYiwnEvkpEbsUECadgbve/47R7E1iBiUs8CFynqpUiMgwz79oTE6Z0i9N9uoj8BTMPuxHzWTYV+vB1EbkSqAQ+5YStPEtAkgMROaOq6U28n+6Y5Kn9MXGVEvDaA8Bdzq+/U9VHnePfAj4NHAc+BDbalfwwoar2EWMPjEe+GRjuti1Rft9e531vxni/WZhpgqnO65cBv8WIhgdTVnKW064OyHXa/RkjZmCE8wbneSpmfnYOJkYx0+lnNTCjCbtKgG86zz+LETyAZzHTHv52Z5yfWcB25/mcgPaPAd92ni/AxAP2wAj7NkycZDpm7ngCxvPf7NjdCdgNPOT236m9PKznF2M4e0DfwHg1u922J8pUqmqu/xfHo9uvqmucQ40t+nwA7FPVzc7xjUCWMw3QX1VfBVDVKqdfgHWqesD5fTNGsFY0YduLAT9/3sL3NwuTeBZVLRCRUud4g4tfGGF+zbG7SkT+3kCflhZixS/GUNWdwBC37YghAnd7+Bd9fhPYwBHJwEUlLyb0qCnqt2/uf0EbeF6HM2/uzEcmN9OHJYawE8iWtkRjiz4NoiZxwAERud5pnyIiHVs49m0BP1c7z0swt6wA1wJJzfSxDLNFEmf+sKtzvLHFr5XANSKS6rznqxvo09JCrOdnaTNoI4s+GM+tMT4D/EZE/hezr/iWJto2RVcR2YrxGD/pHHsKeE1EtgD/5HwvtSG+C7woIjswCRs+gKYXv5y4za2YZA/bMHOVljBg9/ZaLDGMiKSrCbLviPEcv6yqm9y2qz1gPT+LJbb5rbMIlgosssIXPqznZ7E4iKmxMbje4f9Wm2q+XWLFz2KxxCV2tddiscQlVvwsFktcYsXPYrHEJVb8LBZLXGLFz2KxxCVW/CwWS1xixc9iscQlVvwsFktcYsXPYrHEJVb8LBZLXGLFz2KxxCVW/CwWS1xixc9iscQl/x+A9f+tRWmJlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dog_preds.join(clean_enhanced_tweets_df['favorite_counts']).groupby(['pred_class']) \\\n",
    "    .sum().sort_values(by='favorite_counts', ascending=False)[0:10]['favorite_counts'].plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Predict breeds from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will setup a model to predict dog breeds from the image associated with each tweet. Whilst we have no way to verify that our predictions are accurate, we can compare our top 3 predictions against the top 3 predictions downloaded earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of downloaded predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyse the predictions which we downloaded earlier. Here are the things we are interested in:\n",
    "\n",
    "* image model and labels used\n",
    "* model evaluation metrics\n",
    "* examine failure cases\n",
    "* establishing a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image model and labels used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most popular and well establish image datasets and models used in image based machine learning is [ImageNet](http://www.image-net.org) so this will be our 1st candidate. Readable labels can be viewed [here](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), and a quick check against the predicted dog breeds we downloaded earlier confirms that the same labels are used, with spaces in between words being replaced by underscores.\n",
    "\n",
    "This version of ImageNet covers 1000 classes, covering animals as well as inanimate objects. Dogs breeds specifically are in the class index range 151 - 280, so 130 breeds are covered. Again, checking the labels downloaded earlier, these match the ImageNet labels.\n",
    "\n",
    "As far as pre-trained models goes, PyTorch provides a model zoo that includes ImageNet models: [PyTorch ](https://pytorch.org/docs/stable/torchvision/models.html). These models have 3 main uses:\n",
    "\n",
    "1. load without weights as an empty model, randomly initialise the weights and then train the model\n",
    "1. load with weights (i.e.: pre-trained) and use as is, to generate predictions against new images\n",
    "1. load with weights, and further train on new labelled instances (the transfer learning use case)\n",
    "\n",
    "Given we don't have any new labelled dog images, we cannot further train, so will use as is (2nd use case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet is a curated set of images, where each image represents one instance of a single class, and no other classes (i.e.: if there are other objects in the image, they do not belong to any of the classes in ImageNet). \n",
    "\n",
    "This is a great if you want to train a multi-class classifier, as the class showing the strongest recognition is the one predicted. In general, for each image prediction, such a classifier will output:\n",
    "\n",
    "1. a predicted class index, corresponding to the label for that class\n",
    "1. optionally a confidence score (or a probability) in the range 0.0 - 1.0 associated with the above prediction\n",
    "\n",
    "The prediction data we have been given includes the top 3 predictions against each image, ordered by decreasing confidence. Lets sum these confidence scores, and see what range they fall in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum_preds = img_preds_df[['p1_conf', 'p2_conf', 'p3_conf']].sum(axis=1)\n",
    "print(len(sum_preds))\n",
    "sum_preds.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above histogram we can see that the majority of predictions add up to close to 1.0 (or 100%), suggesting that the model is strongly confident that one of its top-3 predictions correctly describes the image.\n",
    "\n",
    "However, around 5% of the images have a top-3 aggregate confidence below 0.5, suggesting not one of the prediction can be considered conclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine failure cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pull out the 20 lowests aggregate confidence score, and examine some of these tweets to see what the problems might be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_preds.sort_values()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these, below are some tweet links for low confidence scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Small dog image, undefined location, little else to recognise](https://twitter.com/dog_rates/status/719704490224398336)\n",
    "\n",
    "[Dog hidden inside toy](https://twitter.com/dog_rates/status/668625577880875008)\n",
    "\n",
    "[Not a dog, and not in ImageNet](https://twitter.com/dog_rates/status/670474236058800128)\n",
    "\n",
    "[Dog like inanimate object](https://twitter.com/dog_rates/status/671159727754231808)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another concern is the number of images where all 3 top predictions are coming up with a non-dog label, as in many cases these are erroneous. Let us see what percentage of images are only classified as a non-dog image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "not_dog = (~ img_preds_df[['p1_dog', 'p2_dog', 'p3_dog']]).all(axis=1)\n",
    "not_dog.sum() / len(img_preds_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So over 15% of our dog images have been classified with no recognisable dog in them, based on the top 3 predictions.\n",
    "\n",
    "And here are some more problematic dog images found earlier, when examining more confident but non-dog predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hidden dog classified as an orange, bagel or banana](https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg)\n",
    "\n",
    "[No dog recognised, only jigsaw puzzle](https://pbs.twimg.com/media/CUS9PlUWwAANeAD.jpg)\n",
    "\n",
    "[Packaging recognised as it overwhelms the image, but no dog seen](https://pbs.twimg.com/media/CVQnPMrVAAAzShR.jpg)\n",
    "\n",
    "[Similar to above, furniture recognised, but dog not seen](https://pbs.twimg.com/media/CVL6op1WEAAUFE7.jpg)\n",
    "\n",
    "[Recognised as shopping trolley and shopping basket, but no dog in contents](https://pbs.twimg.com/media/CT5PY90WoAAQGLo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to establish a baseline for model prediction against the tweet images dataset, which we will try and improve upon. \n",
    "\n",
    "Since we don't have labelled images with their true classes (we only have the top 3 **predicted** classes for each image), then we have no way to measure accuracy. This leaves a couple of other possible metrics:\n",
    "\n",
    "1. improved confidence scores, implying that the model's top 3 predictions are now stronger. We will measure mean and standard deviation across the top 3 confidence scores in the downloaded predictions dataset, and the new predictions dataset, and compare those metrics (we want to see a higher mean, and lower standard deviation, see **below** for this metric)\n",
    "1. percentage of non-dog predictions, as some of these should have been classified as dog images. We know that there are plenty of genuine non-dog images, many correctly classified, however some dog images are also getting classified as non-dog. We aim to reduce the overall count of non-dog images in the hope that less of them erroneously include a dog (see **previous section** for this metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean across the 3 prediction confidence columns\n",
    "\n",
    "img_preds_df[['p1_conf', 'p2_conf', 'p3_conf']].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std across the 3 prediction confidence columns\n",
    "\n",
    "img_preds_df[['p1_conf', 'p2_conf', 'p3_conf']].std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous analysis, we will now describe some potential inference improvements. First, lets summaries the main challenges we face with the downloaded tweet image predictions dataset:\n",
    "\n",
    "1. our tweet image may contain objects belonging to multiple ImageNet classes, including dogs, and other objects or animals that are not dogs. Furthermore, those other classes (e.g.: a large piece of furniture) may be more prominent in the image, and may generate recognition scores higher than those associated with any dog class in that same image.\n",
    "  * implicit in the above observation is the fact that the meaning of what the top 3 predictions are, changes: if multi-label classification is now relevant, then 3 labels may rightly be associated with any single image\n",
    "1. images where the dog portion of the image is very small. Maybe the dog is hidden within the background, or the dog is wearing clothing, or it is partially obscured, so that much lower dog predictions are generated, and don't make it into the top 3. This can be true even when the rest of the image is noisy, and those top 3 predictions themselves are not very strong\n",
    "\n",
    "The first challenge is a classification problem, in so much as we need to treat an image with multiple classes as a multi-label (not just multi-class) classification: zero, one, or more than one label may be associated with any single image. Remember, this is not the problem that ImageNet tries to solve, because the ImageNet datasets are curated to ensure that only one class (and always one class) appears in each training image.\n",
    "\n",
    "The second challenge presents a quality problem: we have samples were a large proportion of the image is unrecognisable, and within which the dog part is small, or may be incomplete, or obscured or distorted.\n",
    "\n",
    "Let's look at a sample problem image and discuss some possible improvements we can make:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small dog on furniture](https://pbs.twimg.com/media/CVL6op1WEAAUFE7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image (corresponding to tweet id [671874878652489728](https://twitter.com/dog_rates/status/671874878652489728)) is labelled thus, including associated confidence score:\n",
    "\n",
    "1. `china_cabinet           0.996031`\n",
    "1. `entertainment_center    0.001985`\n",
    "1. `bookcase                0.001652`\n",
    "\n",
    "In other words, it is overwhelmingly (and correctly) described as a china cabinet, with 99% confidence. Furthermore, the 2nd and 3rd predictions (with close to 0.2% confidence) are also furniture related. \n",
    "\n",
    "Of course, as we only see the top 3 predictions, we don't know if the 4th, 5th or 6th ranked prediction might have been for a dog, and if the correct dog breed might have been chosen. But even if they were, they would come in under a 0.0016% confidence score, versus the 99.6% confidence score on the 1st ranked prediction for _china_cabinet_!\n",
    "\n",
    "So what are the challenges that this kind of tweet image creates?\n",
    "\n",
    "1. first and foremost, many such images contain objects belonging to other ImageNet classes that are not dog breeds, in addition to any dogs that may be in them. These non-dog objects may occupy a larger portion of the image, may have better recognised features, and may emerge from the classifier as the primary prediction\n",
    "1. ImageNet based classifiers are multi-class classifiers: they associate every image with one, and only one, class. But in practice our tweet may require a multi-label classifier, which associates each image with zero or more classes, one of which may be a dog breed\n",
    "1. multi-class classifiers tend to feed the final fully connected layer into a softmax layer, which will output a probability distribution across all classes. Each class output is between 0.0 and 1.0, and the sum of all class outputs will be 1, which is the pattern the confidence scores in our data seem to follow. Softmax pushes for one clear winning class, with a higher probability than the others, and therefore doesn't lend itself to multi-label classification\n",
    "1. ImageNet includes some broad categories of classes such as dog breeds, other animals, furniture, etc. Since the classifier is single label, the top 3 predictions tend to relate to the same feature, and predictions for other classes in the image just get lost (as the classifier wasn't trained that way)\n",
    "\n",
    "So lets be explicit about the assumptions we are making, regarding the tweet image predictions data, and how the model that generated this data works:\n",
    "\n",
    "1. the image classes output by the classifier belong to ImageNet, the classifier used is a multi-class (thus single-label) classifier, and the 3 predictions given are the top 3 single-label predictions\n",
    "1. being a single-label classifier, the predictions are output by a softmax layer, and we are taking the top 3 highest values across the probability distribution generated by the softmax\n",
    "1. images may or may not contain a dog, hence the is_dog boolean associated with each prediction, and defined by whether the predicted class is a dog breed or not\n",
    "1. for a given image, the top 3 predictions may be a mix of dog and non-dog classes, as is observed in the data\n",
    "1. for simplicity we will assume that, when an image does include a dog, a single dog breed is associated with that image (some images may break this assumption). We can then apply softmax across the subset of outputs for dog classes to pick that single dog breed\n",
    "\n",
    "How can we address these challenges?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with multi-label images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, the ImageNet image datasets are multi-class but single-label: one, and only one class is associated with each image. Such a classifier usually takes the output of the final fully connected linear layer in the model, and puts it through a softmax layer, which will output a probability distribution across all classes: each output corresponding to each class will be between 0.0 and 1.0, and all 10000 outputs will add up to 1.0. \n",
    "\n",
    "Implicit in this model are a number of assumptions:\n",
    "\n",
    "* the output with the highest probability is assumed to be the strongest class prediction, and is the class label assigned to the image\n",
    "* the set of all output classes represent the known universe of classes, hence their assigned probabilities must all add up to 1.0\n",
    "* each and every image must belong to exactly one class in this universe of classes\n",
    "\n",
    "Whilst these assumptions hold for ImageNet's curated, they rapidly break down in the real world of tweet images. For example, take the image below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know how the model used to generate the downloaded predictions generates its confidence score, although given that the top 3 predictions always add up to a number close to 1.0 (but never higher) we can assume that the top 3 confidence scores are the top 3 highest values output by a softmax layer.\n",
    "\n",
    "As softmax will squish down all the predictions so they add up to 1.0 whilst maintaining the relative value between each, lower ranked predictions end up being quite small numbers. This makes sense for a multi-class classifier, where a single and most relevant label gets assigned to each image. But it doesn't make sense when multiple ImageNet classes can appear within the same tweet image, and this is more of a multi-label classification challenge.\n",
    "\n",
    "Multi-label classifiers usually take the output of the final fully connected liner layer in the model, and put it through a sigmoid layer, which will output a probability distribution across all classes: each output corresponding to each class will be between 0.0 and 1.0, but all outputs are independent of each other, since multiple labels can be associated with the image. There is no constraint about them having to add up to 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However sigmoid alone isn't going to fix our problem. With softmax, we take the index of the highest value output by the softmax, and use that class index to assign a single label to the image. However, with sigmoid we need a cutoff value above which each output is considered a positive indicator, and the relevant label (and potentially multiple or no labels) is assigned to the sample image. Given sigmoid outputs are also treated as probabilities, by convention 0.5 is the chosen cutoff. However for different datasets, and different models, it may make sense to tune this value.\n",
    "\n",
    "We need to decide how we want our classification model to work, and we need to base it on some observed assumptions:\n",
    "\n",
    "1. most images will have dogs in them, in most cases the image will have a single dog, this is the dog named and referred to in the tweet text; we want to classify the image with the class corresponding to that dog's breed\n",
    "  * the above assumption breaks if there is more than one dog in the image, and they are of different breeds\n",
    "1. where there is no dog, there must be another well recognised object in the image; we want to classify the image with the class of that object\n",
    "\n",
    "Where we believe we have a dog, we will take the subset of model outputs corresponding to dog classes, and put that through softmax to obtain the top 3 predicted breeds. In this senario, softmax will make sure that all our 130 dog breed probabilities add up to 1.0, as this is our complete universe of classes.\n",
    "\n",
    "Below we define our classification logic:\n",
    "\n",
    "```\n",
    "* take the dog breed outputs (class indices 151 - 280) and run them through sigmoid\n",
    "* then:\n",
    "  * take the max output value of the sigmoid\n",
    "  * if the max is >= is_dog_cutoff \n",
    "  * then: True -> is_dog\n",
    "  * else: False -> is_dog\n",
    "* if is_dog is True then:\n",
    "  * take dog breed (class indices 151 - 280) final layer outputs, and put through softmax\n",
    "  * take the top 3 highest softmax outputs\n",
    "  * adjust the class indices to the subset start position (offset +151)\n",
    "    * use the class index to assign the class label\n",
    "    * use the class probability as confidence score\n",
    "* else:\n",
    "  * put all outputs through softmax\n",
    "  * take the top 3 highest softmax outputs\n",
    "    * use the class index to assign the class label\n",
    "    * use the class probability as confidence score\n",
    "```\n",
    "\n",
    "In some ways the above logic acts as a binary classifier: we initially predict if a dog is present or not in the image. Both the subsequent classifications are multi-class (and single-label) for each of the top 3 predictions, and we use softmax to obtain a confidence score, which we believe is how the downloaded predictions were made. However, where we believe a dog is present in the image, the model outputs used for breed prediction is limited to those outputs corresponding to dog breeds.\n",
    "\n",
    "Furthermore, given the initial binary classifier nature of this approach, if we decide to make a dog prediction, all top 3 predictions will be for dog breeds. Otherwise, we will make predictions across the full set of classes, and given that in that scenario, the dog predictions were low, its is unlikely the predictions across all classes would include a dog breed (in the top 3) however it is not impossible. So the second scenario could lead to mixed predictions (non-dog objects and dogs in the top 3 prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with small or partial dog images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification logic previously described should improve recognition of small dog features, in the scenario where a larger non-dog feature is also being recognised and assigned a higher probability. But where the dog image is small or partially hidden, or surrounded by a noisy background, the best way to improve classifier performance may be to restrict it to more relevant parts of the image.\n",
    "\n",
    "There are two obvious ways to approach this requirement:\n",
    "\n",
    "1. build a dog image recogniser that can localise the dog within the image (e.g.: framing rectangle), then take that rectangle as a cropped image, and feed it into the dog breed classifier\n",
    "1. use test time augmentation to dice the image into smaller crops, classify each of these crops independently, then pick the strongest result in a manner analogous to a model ensemble \n",
    "\n",
    "Whilst the 1st approach sounds like the most effective, it requires us to build/train an accurate dog recogniser, which is challenging. The downside to the 2nd approach is that the crops taken may or may not land in the best place for any specific image, although using an ensemble type approach can sometimes produce more robust results.\n",
    "\n",
    "For simplicity we will follow the 2nd approach. Each individual crop will be classified using the logic described in the previous section. The logic we then need to apply must select the crop with the strongest predictions, and we will do this by selecting the crop with the highest 1st confidence score. To be clear, once that crop is selected, all top 3 predictions will come from that same crop, for consistency. \n",
    "\n",
    "This is the crop selection logic we will use:\n",
    "\n",
    "```\n",
    "* select crops where is_dog is True\n",
    "* then:\n",
    "  * pick the crop with the highest 1st prediction confidence score (across dog classes)\n",
    "  * use that crop's scores as the overall prediction\n",
    "* otherwise: \n",
    "  * pick the crop with the highest 1st prediction confidence score (across all classes)\n",
    "  * use that crop's scores as the overall prediction\n",
    "```\n",
    "\n",
    "So we prefer dog predictions: if any image crops are classified as a dog, we take the highest prediction amongst those crops (even when there may be higher non-dog predictions). But if no crops is classified as a dog, then we just take the highest prediction amongst all crops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the suggested inference improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will design our classifier so that the two suggested inference improvements can be evaluated independently, and then in combination with each other, using the baseline metrics previously selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we setup the Pytorch data loading classes required to load the test data from each image URL. For convenience this dataset class also handles files in a local directory, and in both cases the list of file ids (and optional labels) is supplied in a dataframe, previously loaded from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "class ImageDataFrameDataset:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 df,  \n",
    "                 img_col,\n",
    "                 lbl_col=None,\n",
    "                 img_dir=None, \n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: a dataframe holding class labels and, either an image Id, the image file, or an image URL\n",
    "            img_col: column holding image file name (either the name without suffix, or the full URL)\n",
    "            lbl_col: optional column holding image label\n",
    "            img_dir: an optional directory in which to find the image files (unless remote)\n",
    "            transfor: optional transform, or chain of transforms\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.img_col = img_col\n",
    "        self.lbl_col = lbl_col\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform       \n",
    "\n",
    "        if self.lbl_col is not None:\n",
    "            self.classes, self.class_to_idx = self._find_classes(self.df[self.lbl_col])\n",
    "            self.labels = [self.class_to_idx[getattr(row, self.lbl_col)] \n",
    "                           for row in self.df.itertuples()]\n",
    "        else:\n",
    "            self.labels = None\n",
    "                \n",
    "        if self.img_dir is None:\n",
    "            self.session = requests.Session()\n",
    "\n",
    "        self.samples = [self._read_image(getattr(row, self.img_col))\n",
    "                        for row in self.df.itertuples()]\n",
    "\n",
    "    def _read_image(self, resource):\n",
    "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "        \n",
    "        if self.img_dir is not None:\n",
    "            file_name = f'{self.img_dir}/{resource}.jpg'\n",
    "            with open(file_name, 'rb') as fd:\n",
    "                image = Image.open(fd)\n",
    "                return image.convert('RGB')\n",
    "        else:\n",
    "            response = self.session.get(resource, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                response.raw.decode_content = True\n",
    "                try:\n",
    "                    image = Image.open(response.raw)\n",
    "                    return image.convert('RGB')\n",
    "                except UnidentifiedImageError as ex:\n",
    "                    print(f'Image open failed for URL {resource}, exception {ex}')\n",
    "            return Image.new('RGB', (224, 224))\n",
    "                    \n",
    "    def _find_classes(self, series):\n",
    "        classes = series.unique()\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        image = self.samples[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            return image, self.labels[index]\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We configure the dataset and dataloader using the standard ImageNet normalisation, and an image size of 392 (along the shortest side, the longer side will be scaled to maintain the aspect ratio). From this image we next take 5 crops (centre, plus 4 corners) size 224 x 224, so at least 2 of the corner crops should overlap. We then double the number of samples by taking the mirror image of each of those crops.\n",
    "\n",
    "For example, if the image is portrait, then the left and right corners will overlap 25%, but the top and bottom corners may or may not overlap, depending on the aspect ratio. Likewise, the centre crop should overlap all 4 corner crops, unless the aspect ratio is less than 7:12. Hopefully, because of this crop overlap, one of the crops will include most any dog present in the larger image. \n",
    "\n",
    "Finally, we use 224 squared as the crop image size because 224 x 224 is the target image size that ImageNet models are trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "import torch\n",
    "\n",
    "batch_size = 96\n",
    "do_use_cuda = True\n",
    "\n",
    "if do_use_cuda:\n",
    "    compute_device = torch.device('cuda')\n",
    "    do_pin_memory = True\n",
    "else:\n",
    "    compute_device = torch.device('cpu')\n",
    "    do_pin_memory = False\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "crop_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=392),\n",
    "    transforms.TenCrop(224),\n",
    "    transforms.Lambda(lambda crops: [transforms.functional.to_tensor(crop) for crop in crops]),\n",
    "    transforms.Lambda(lambda crops: torch.stack(\n",
    "        [transforms.functional.normalize(crop,\n",
    "                                         mean=(0.485, 0.456, 0.406),\n",
    "                                         std=(0.229, 0.224, 0.225)) for crop in crops]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_image_ds = ImageDataFrameDataset(clean_img_preds_df, \n",
    "                                      'jpg_url',\n",
    "                                      transform=image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dl = data.DataLoader(test_image_ds,\n",
    "                                batch_size=batch_size,\n",
    "                                pin_memory=do_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_crop_ds = ImageDataFrameDataset(clean_img_preds_df,\n",
    "                                     'jpg_url',\n",
    "                                     transform=crop_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_crop_dl = data.DataLoader(test_crop_ds,\n",
    "                               batch_size=batch_size,\n",
    "                               pin_memory=do_pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image scoring functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each prediction scoring function takes a batch of size (N, *, 1000) entries holding the outputs from the model's last layer (with an optional dimension representing image crops), and returns a tuple consisting of:\n",
    "\n",
    "* N booleans indicating if it is a dog breed class or not\n",
    "* an (N, 3) `LongTensor` holding class indices for the top 3 predictions\n",
    "* an (N, 3) `FloatTensor` holding the top 3 probabilities (aka confidence scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def score_dog_breed_images(preds, is_dog_cutoff):\n",
    "    \n",
    "    # Which predictions look like dog predictions?\n",
    "    is_dog = torch.sigmoid(preds[:, 151:280]).gt(is_dog_cutoff).any(dim=-1)\n",
    "    \n",
    "    # Generate top 3 softmax scores for the subset of dog breed classes\n",
    "    dog_top_3 = F.softmax(preds[:, 151:280], dim=-1).topk(3, dim=-1)\n",
    "    dog_top_3.indices.add_(151)\n",
    "    \n",
    "    # Generate top 3 softmax scores for all ImageNet classes\n",
    "    all_top_3 = F.softmax(preds, dim=-1).topk(3, dim=-1)\n",
    "\n",
    "\n",
    "    # Pick per-sample class prediction and score from the relevant universe\n",
    "    top_3_class = torch.where(is_dog.unsqueeze(dim=1), dog_top_3.indices, all_top_3.indices)\n",
    "    top_3_scores = torch.where(is_dog.unsqueeze(dim=1), dog_top_3.values, all_top_3.values)\n",
    "    \n",
    "    return is_dog, top_3_class, top_3_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_images(preds):\n",
    "    \n",
    "    # Generate top 3 softmax scores for all ImageNet classes\n",
    "    all_top_3 = F.softmax(preds, dim=-1).topk(3, dim=-1)\n",
    "    is_dog = (all_top_3.indices.ge(151) & all_top_3.indices.le(280))\n",
    "\n",
    "    return is_dog, all_top_3.indices, all_top_3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_image_crops(preds, score_fn=None, *args):\n",
    "    \n",
    "    assert len(preds.shape) == 3, 'Expect tensor shape (N, *, 1000) where * is the number of crops (e.g.: 10)'\n",
    "    assert score_fn is not None, 'You must specify score_fn=...'\n",
    "\n",
    "    \n",
    "    # Score each crop individually, using the supplied image scoring function\n",
    "    are_dogs = []\n",
    "    class_indices = []\n",
    "    class_probas = []\n",
    "    for idx in range(preds.shape[1]):\n",
    "        is_dog, class_idx, cls_proba = score_fn(preds[:, idx], *args)\n",
    "        are_dogs.append(is_dog)\n",
    "        class_indices.append(class_idx)\n",
    "        class_probas.append(cls_proba)\n",
    "    are_dogs = torch.stack(are_dogs, dim=1)\n",
    "    class_indices = torch.stack(class_indices, dim=1)\n",
    "    class_probas = torch.stack(class_probas, dim=1)\n",
    "    print(f'class_probas.shape={class_probas.shape}')\n",
    "\n",
    "    \n",
    "    # Which images have crops classified as dogs, for convenience zero their non-dog\n",
    "    is_dog_crop = are_dogs[:, :, :].any(dim=-1)\n",
    "    \n",
    "    return are_dogs, class_indices, class_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = torch.FloatTensor(batch_size, 10, 1000).normal_(-1.0, 1.0)\n",
    "is_dog_cutoff = 0.80\n",
    "\n",
    "is_dog, top3_classes, top3_scores = score_image_crops(test_preds, \n",
    "                                                      is_dog_cutoff=is_dog_cutoff,\n",
    "                                                      score_fn=score_images)\n",
    "\n",
    "is_dog.shape, top3_classes.shape, top3_scores.shape\n",
    "is_dog, top3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = torch.FloatTensor(batch_size, 1000).normal_(-1.0, 1.0)\n",
    "is_dog_cutoff = 0.80\n",
    "\n",
    "is_dog, top3_classes, top3_scores = score_dog_breed_images(test_preds, is_dog_cutoff)\n",
    "\n",
    "is_dog.shape, top3_classes.shape, top3_scores.shape\n",
    "# is_dog, top3_classes\n",
    "\n",
    "# torch.sigmoid(test_preds[:, 151:280]).gt(is_dog_cutoff).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate image predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the 34 layer version of ResNet pre-trained on the ImageNet dataset with 1000 labelled classes, as our prediction model. By taking the pre-trained model, we will only perform inference here, using the tweet images in the test dataset. We start by loding the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "model = models.resnet34(pretrained=True)\n",
    "model = model.to(compute_device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup hyper-parameters driving our test time augmentation and scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some hyperparameters\n",
    "\n",
    "sigmoid_proba_cutoff = 0.5\n",
    "feature_rank_depth = 3\n",
    "dog_class_idx_from = 151\n",
    "dog_class_idx_to = 280\n",
    "\n",
    "# Set the model to evaluation mode \n",
    "# (changes behaviour of batchnorm and dropout layers)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "num_crops = 10\n",
    "print(f'Using compute device: {compute_device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we iterate through our test dataset, one minibatch at a time, and each batch goes through test time data augmentation iteratively: we use PyTorch's TenCrop transformer to generate 5 crops of the image (the 4 corners plus a center crop) plus another  224 square, which is the target image size that ImageNet is trained on. We will also generate 5 coresponding mirror images (aka horiontal flip). Given a batch size N, each mini-batch will consist of \\[N x 10 x 3 x 224 x 224\\] tensors, where 10 is the 5 crops and again for the flipped versions, and 3 is the channel depth (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for batch_num, data in enumerate(test_dl):\n",
    "    \n",
    "    crop_preds = []\n",
    "\n",
    "#     stats = torch.cuda.memory_summary(compute_device)\n",
    "#     print(f'At loop {batch_num}, stats {stats}')\n",
    "    \n",
    "    # Loop through each stacked crop\n",
    "    for crop_idx in range(10): #(num_crops):\n",
    "        with torch.no_grad():\n",
    "            crop = data[:, crop_idx].clone()\n",
    "            crop = crop.to(compute_device)\n",
    "            crop_pred = model(crop)\n",
    "            print(crop_pred.sort(dim=-1, descending=True))\n",
    "            crop_preds.append(crop_pred)\n",
    "\n",
    "    preds = torch.stack(crop_preds, dim=1)\n",
    "    top_k_preds = preds.topk(feature_rank_depth, dim=-1)\n",
    "#     print(top_k_preds[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate internal report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having cleaned the data, and generated data insights, we can now generate the internal documentation from this notebook's markdown cells.\n",
    "\n",
    "(you probably want to clear all output previous to the data insights output generated in the last section, and then SAVE the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --no-input --to pdf wrangle_act.ipynb\n",
    "# !mv wrangle_act.pdf wrangle_report.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
