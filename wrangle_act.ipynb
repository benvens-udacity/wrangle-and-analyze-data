{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project looks at various data sources for Tweets from the [WeRateDogs](https://twitter.com/dog_rates) Twitter account, specifically:\n",
    "\n",
    "1. the `twitter-archive-enhanced.csv` which contains the tweet text and various related identifiers\n",
    "1. the Twitter API is used to access the original tweets to retrieve missing fields such as the retweet and favorite counts\n",
    "1. an image prediction file containing the top 3 predictions for each of the (up to 4) dog pictures in the tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `twitter-archive-enhanced.csv` is the master source for the set of tweets to be included in this project. However, this dataset will need to be cleaned, and will then be enriched with additional attributes obtained through the [Twitter API](https://developer.twitter.com/en/docs/twitter-api), and finally enriched with data from the breed predictions file, which includes the top 3 predictions based on the dog's images. The data will be mapped into Pandas DataFrames folowing the Tidy Data principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data assets used are listed below. Some are local files, downloaded into the `data` directory, some are remote files on web servers, and some are sourced via an API. Where there is enrichment of existing data, I will add the new attributes to the base DataFrame. Standalone data such as the breed predictions I will load into a separate DataFrame, so as to later reconcile back to the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WE_RATE_DOGS_TWEETS = 'data/twitter-archive-enhanced.csv'\n",
    "DOG_BREED_PREDICTIONS_SNAPSHOT = 'data/image_predictions.tsv'\n",
    "DOG_BREED_PREDICTIONS_SOURCE_URL = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "TWEET_STATISTICS_SNAPSHOT = 'data/tweet_json.txt'\n",
    "TWEET_STATISTICS_API_URL = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that the Pandas `read_csv()` function is quite versatile when uploading data, and can be configured to handle different date formats, numeric data types, not available (NA) value markers, etc. But to benefit from such functionality we need to eyeball the raw data first.\n",
    "\n",
    "Let's look at the first 8 records, and 8 records from near the end of the file:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 11 ./data/twitter-archive-enhanced.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tail -n 1940 ./data/twitter-archive-enhanced.csv | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations:\n",
    "\n",
    "1. the 1st line lists out the colummn names\n",
    "1. tweet Ids are very large integres\n",
    "1. some tweet Ids appear as floating point numbers, e.g.: in_reply_to_status_id, in_reply_to_user_id, as many are NaNs\n",
    "1. time stamps are close to ISO 8601 (they are missing the 'T' separator) and are GMT (+00:00 offset) \n",
    "1. strings are wrapped in double quotes (\") and embeded quotes appear as two contiguous quotes (\"\")\n",
    "1. some strings such as the tweets with links to GoFundMe page have 2 embeded new lines within the double quotes\n",
    "1. dog names and stages (last 5 columns) are extracted where found, otherwise the value _None_ is placed in those columns\n",
    "1. the 'source' column for all rows is an HTML anchor with a link to http://twitter.com/download/iphone which is useless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.config import read_creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the enhanced Twitter archive, using explicit data types for fields, instead of letting Pandas infer them. The [Twitter API](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object) will define the data types for the Twitter fields. To that I will add data types for the \"enhanced\" fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_data_types = {\n",
    "    'tweet_id': np.int64,\n",
    "#     'in_reply_to_status_id': np.int64,\n",
    "#     'in_reply_to_user_id': np.int64,\n",
    "#     'source': str,\n",
    "#     'text': str,\n",
    "#     'retweeted_status_id': np.int64,\n",
    "#     'retweeted_status_user_id': np.int64,\n",
    "#     'expanded_urls': str,\n",
    "#     'rating_numerator': int,\n",
    "#     'rating_denominator': int,\n",
    "#     'name': str,\n",
    "#     'doggo': str,\n",
    "#     'floofer': str,\n",
    "#     'pupper': str,\n",
    "#     'puppo': str \n",
    "}\n",
    "feed_date_cols = ['timestamp', 'retweeted_status_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(WE_RATE_DOGS_TWEETS,\n",
    "                       dtype=feed_data_types,\n",
    "                       parse_dates=feed_date_cols)\n",
    "# tweets_df = pd.read_csv(WE_RATE_DOGS_TWEETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Twitter credentials and authenticate:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = read_creds('./config/private/creds.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = creds['consumer_api']['key']\n",
    "consumer_secret = creds['consumer_api']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = creds['access_token']['token']\n",
    "acess_secret = creds['access_token']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, acess_secret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
