{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project looks at various data sources for Tweets from the [WeRateDogs](https://twitter.com/dog_rates) Twitter account, specifically:\n",
    "\n",
    "1. the `twitter-archive-enhanced.csv` which contains the tweet text and various related identifiers\n",
    "1. the Twitter API is used to access the original tweets to retrieve missing fields such as the retweet and favorite counts\n",
    "1. an image prediction file containing the top 3 predictions for each of the (up to 4) dog pictures in the tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `twitter-archive-enhanced.csv` is the master source for the set of tweets to be included in this project. However, this dataset will need to be cleaned, and will then be enriched with additional attributes obtained through the [Twitter API](https://developer.twitter.com/en/docs/twitter-api), and finally enriched with data from the breed predictions file, which includes the top 3 predictions based on the dog's images. The data will be mapped into Pandas DataFrames folowing the Tidy Data principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data assets used are listed below. Some are local files, downloaded into the `data` directory, some are remote files on web servers, and some are sourced via an API. Where there is enrichment of existing data, I will add the new attributes to the base DataFrame. Standalone data such as the breed predictions I will load into a separate DataFrame, so as to later reconcile back to the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-predictions.tsv        tweet-json.zip\r\n",
      "tweet-json copy              twitter-archive-enhanced.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WE_RATE_DOGS_TWEETS = 'data/twitter-archive-enhanced.csv'\n",
    "DOG_BREED_PREDICTIONS_SNAPSHOT = 'data/image_predictions.tsv'\n",
    "DOG_BREED_PREDICTIONS_SOURCE_URL = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "TWEET_STATISTICS_SNAPSHOT = 'data/tweet_json.txt'\n",
    "TWEET_STATISTICS_API_URL = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that the Pandas `read_csv()` function is quite versatile when uploading data, and can be configured to handle different date formats, numeric data types, not available (NA) value markers, etc. But to benefit from such functionality we need to eyeball the raw data first.\n",
    "\n",
    "Let's look at the first 8 records, and 8 records from near the end of the file:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id,in_reply_to_status_id,in_reply_to_user_id,timestamp,source,text,retweeted_status_id,retweeted_status_user_id,retweeted_status_timestamp,expanded_urls,rating_numerator,rating_denominator,name,doggo,floofer,pupper,puppo\r\n",
      "892420643555336193,,,2017-08-01 16:23:56 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Phineas. He's a mystical boy. Only ever appears in the hole of a donut. 13/10 https://t.co/MgUWQ76dJU,,,,https://twitter.com/dog_rates/status/892420643555336193/photo/1,13,10,Phineas,None,None,None,None\r\n",
      "892177421306343426,,,2017-08-01 00:17:27 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",\"This is Tilly. She's just checking pup on you. Hopes you're doing ok. If not, she's available for pats, snugs, boops, the whole bit. 13/10 https://t.co/0Xxu71qeIV\",,,,https://twitter.com/dog_rates/status/892177421306343426/photo/1,13,10,Tilly,None,None,None,None\r\n",
      "891815181378084864,,,2017-07-31 00:18:03 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Archie. He is a rare Norwegian Pouncing Corgo. Lives in the tall grass. You never know when one may strike. 12/10 https://t.co/wUnZnhtVJB,,,,https://twitter.com/dog_rates/status/891815181378084864/photo/1,12,10,Archie,None,None,None,None\r\n",
      "891689557279858688,,,2017-07-30 15:58:51 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Darla. She commenced a snooze mid meal. 13/10 happens to the best of us https://t.co/tD36da7qLQ,,,,https://twitter.com/dog_rates/status/891689557279858688/photo/1,13,10,Darla,None,None,None,None\r\n",
      "891327558926688256,,,2017-07-29 16:00:24 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",\"This is Franklin. He would like you to stop calling him \"\"cute.\"\" He is a very fierce shark and should be respected as such. 12/10 #BarkWeek https://t.co/AtUZn91f7f\",,,,\"https://twitter.com/dog_rates/status/891327558926688256/photo/1,https://twitter.com/dog_rates/status/891327558926688256/photo/1\",12,10,Franklin,None,None,None,None\r\n",
      "891087950875897856,,,2017-07-29 00:08:17 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",Here we have a majestic great white breaching off South Africa's coast. Absolutely h*ckin breathtaking. 13/10 (IG: tucker_marlo) #BarkWeek https://t.co/kQ04fDDRmh,,,,https://twitter.com/dog_rates/status/891087950875897856/photo/1,13,10,None,None,None,None,None\r\n",
      "890971913173991426,,,2017-07-28 16:27:12 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",\"Meet Jax. He enjoys ice cream so much he gets nervous around it. 13/10 help Jax enjoy more things by clicking below\r\n",
      "\r\n",
      "https://t.co/Zr4hWfAs1H https://t.co/tVJBRMnhxl\",,,,\"https://gofundme.com/ydvmve-surgery-for-jax,https://twitter.com/dog_rates/status/890971913173991426/photo/1\",13,10,Jax,None,None,None,None\r\n",
      "890729181411237888,,,2017-07-28 00:22:40 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",When you watch your owner call another dog a good boy but then they turn back to you and say you're a great boy. 13/10 https://t.co/v0nONBcwxq,,,,\"https://twitter.com/dog_rates/status/890729181411237888/photo/1,https://twitter.com/dog_rates/status/890729181411237888/photo/1\",13,10,None,None,None,None,None\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 11 ./data/twitter-archive-enhanced.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813142292504645637,,,2016-12-25 22:00:04 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",Everybody stop what you're doing and look at this dog with her tiny Santa hat. 13/10 https://t.co/KK4XQK9SPi,,,,\"https://twitter.com/dog_rates/status/813142292504645637/photo/1,https://twitter.com/dog_rates/status/813142292504645637/photo/1,https://twitter.com/dog_rates/status/813142292504645637/photo/1\",13,10,None,None,None,None,None\r\n",
      "813130366689148928,8.13127251579564e+17,4196983835.0,2016-12-25 21:12:41 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",I've been informed by multiple sources that this is actually a dog elf who's tired from helping Santa all night. Pupgraded to 12/10,,,,,12,10,None,None,None,None,None\r\n",
      "813127251579564032,,,2016-12-25 21:00:18 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",Here's an anonymous doggo that appears to be very done with Christmas. 11/10 cheer up pup https://t.co/BzITyGw3JA,,,,\"https://twitter.com/dog_rates/status/813127251579564032/photo/1,https://twitter.com/dog_rates/status/813127251579564032/photo/1\",11,10,None,doggo,None,None,None\r\n",
      "813112105746448384,,,2016-12-25 20:00:07 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",Meet Toby. He's pupset because his hat isn't big enough. Christmas is ruined. 12/10 it'll be ok Toby https://t.co/zfdaGZlweq,,,,https://twitter.com/dog_rates/status/813112105746448384/photo/1,12,10,Toby,None,None,None,None\r\n",
      "813096984823349248,,,2016-12-25 19:00:02 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Rocky. He got triple-doggo-dared. Stuck af. 11/10 someone help him https://t.co/soNL00XWVu,,,,https://twitter.com/dog_rates/status/813096984823349248/photo/1,11,10,Rocky,doggo,None,None,None\r\n",
      "813081950185472002,,,2016-12-25 18:00:17 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Baron. He's officially festive as h*ck. Thinks it's just a fancy scarf. 11/10 would pat head approvingly https://t.co/PjulYEXTvg,,,,\"https://twitter.com/dog_rates/status/813081950185472002/photo/1,https://twitter.com/dog_rates/status/813081950185472002/photo/1\",11,10,Baron,None,None,None,None\r\n",
      "813066809284972545,,,2016-12-25 17:00:08 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Tyr. He is disgusted by holiday traffic. Just trying to get to Christmas brunch on time. 12/10 hurry up pup https://t.co/syuTXARdtN,,,,https://twitter.com/dog_rates/status/813066809284972545/photo/1,12,10,Tyr,None,None,None,None\r\n",
      "813051746834595840,,,2016-12-25 16:00:16 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Bauer. He had nothing to do with the cookies that disappeared. 13/10 very good boy https://t.co/AIMF8ouzvl,,,,https://twitter.com/dog_rates/status/813051746834595840/photo/1,13,10,Bauer,None,None,None,None\r\n",
      "tail: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 1940 ./data/twitter-archive-enhanced.csv | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations:\n",
    "\n",
    "1. the 1st line lists out the colummn names\n",
    "1. tweet Ids are very large integres\n",
    "1. some tweet Ids appear as floating point numbers, e.g.: in_reply_to_status_id, in_reply_to_user_id, as many are NaNs (i.e: nulls or missing values)\n",
    "1. time stamps are almost in ISO 8601 (they are missing the 'T' separator) and are GMT (+00:00 offset) \n",
    "1. strings are wrapped in double quotes (\") and embeded quotes appear as two contiguous quotes (\"\")\n",
    "1. some strings such as the tweets with links to GoFundMe page have 2 embeded new lines within the double quotes\n",
    "1. dog names and stages (last 5 columns) are extracted where found, otherwise the value _None_ is placed in those columns\n",
    "1. whilst the dog name is variable, the stage is predefined, so putting the stage name into a column named after the stage name is redundant information\n",
    "1. the 'source' column for all rows is an HTML anchor with a link to http://twitter.com/download/iphone which has no value, we can drop this column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actions taken to address above observations:\n",
    "\n",
    "* convert floating point tweets Ids to a 64-bit integer, retaining the Not Available representation\n",
    "* specifcally tell Pandas which columns are dates\n",
    "* drop the 'source' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.config import read_creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the enhanced Twitter archive, using explicit data types for fields, instead of letting Pandas infer them. The [Twitter API](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object) will define the data types for the Twitter fields, to which I add the data types for the \"enhanced\" fields.\n",
    "\n",
    "To get around the fact that nullable numeric fields, by default, are interpreted by `read_csv()` as floats (so as to include NaN to represent null or Not Available), I am mapping optional tweet Ids to Pandas nullable integer data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_data_types = {\n",
    "    'tweet_id': np.int64,\n",
    "    'in_reply_to_status_id': 'Int64',\n",
    "    'in_reply_to_user_id': 'Int64',\n",
    "    'retweeted_status_id': 'Int64',\n",
    "    'retweeted_status_user_id': 'Int64',\n",
    "    'text': str,\n",
    "    'expanded_urls': str,\n",
    "    'rating_numerator': np.int32,\n",
    "    'rating_denominator': np.int32,\n",
    "    'name': str,\n",
    "    'doggo': str,\n",
    "    'floofer': str,\n",
    "    'pupper': str,\n",
    "    'puppo': str \n",
    "}\n",
    "\n",
    "feed_date_cols = [\n",
    "    'timestamp', \n",
    "    'retweeted_status_timestamp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(WE_RATE_DOGS_TWEETS,\n",
    "                        index_col=['tweet_id'],\n",
    "                        dtype=feed_data_types,\n",
    "                        parse_dates=feed_date_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.drop(columns=['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can doublecheck the column data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2356 entries, 892420643555336193 to 666020888022790149\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   in_reply_to_status_id       78 non-null     Int64              \n",
      " 1   in_reply_to_user_id         78 non-null     Int64              \n",
      " 2   timestamp                   2356 non-null   datetime64[ns, UTC]\n",
      " 3   text                        2356 non-null   object             \n",
      " 4   retweeted_status_id         181 non-null    Int64              \n",
      " 5   retweeted_status_user_id    181 non-null    Int64              \n",
      " 6   retweeted_status_timestamp  181 non-null    datetime64[ns, UTC]\n",
      " 7   expanded_urls               2297 non-null   object             \n",
      " 8   rating_numerator            2356 non-null   int32              \n",
      " 9   rating_denominator          2356 non-null   int32              \n",
      " 10  name                        2356 non-null   object             \n",
      " 11  doggo                       2356 non-null   object             \n",
      " 12  floofer                     2356 non-null   object             \n",
      " 13  pupper                      2356 non-null   object             \n",
      " 14  puppo                       2356 non-null   object             \n",
      "dtypes: Int64(4), datetime64[ns, UTC](2), int32(2), object(7)\n",
      "memory usage: 285.3+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Twitter credentials and authenticate:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = read_creds('./config/private/creds.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = creds['consumer_api']['key']\n",
    "consumer_secret = creds['consumer_api']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = creds['access_token']['token']\n",
    "acess_secret = creds['access_token']['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, acess_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Twitter API and load the enrichment data in batches, for better performance, as API invocations are subject to significant network latency. Twitter applies rate limiting to their APIs, so it is necessary to throttle the rate at which we make requests, and to retry any failed API invocations. Tgis can be handled automatically by the Tweepy library, by setting the `wait_on_rate_limit_notify` flag when setting up the API connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we are enriching the core enhanced tweets archive, we will initially load the API data into a separate data frame, cleanup as necessary, and then merge from there into the main table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_tweets = len(tweets_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    idxs = []\n",
    "    retweet_counts = []\n",
    "    favorite_counts = []\n",
    "    for status in batch:\n",
    "        tweet = status._json\n",
    "        idxs.append(tweet['id'])\n",
    "        retweet_counts.append(tweet['retweet_count'])\n",
    "        favorite_counts.append(tweet['favorite_count'])\n",
    "    return np.array(idxs, dtype=np.int64), np.array([retweet_counts, favorite_counts], dtype=np.int64).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.empty((0), dtype=np.int64)\n",
    "rows = np.empty((0, 2), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_start in range(0, num_tweets, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, num_tweets)\n",
    "    batch_tweet_ids = tweets_df.iloc[batch_start:batch_end].index.to_numpy().tolist()\n",
    "    statuses = api.statuses_lookup(batch_tweet_ids, include_entities=False, map_=False)\n",
    "    b_indices, b_rows = process_batch(statuses)\n",
    "    indices = np.concatenate((indices, b_indices), axis=0)\n",
    "    rows = np.concatenate((rows, b_rows), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_df = pd.DataFrame(index=indices, data=rows, columns=['retweet_counts', 'favorite_counts'], dtype='Int32')\n",
    "enrich_df.index.name = 'tweet_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_tweets_df = tweets_df.merge(enrich_df, how='left', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
